ğŸ“Œ ëª©ì°¨ (Table of Contents)
---
- [Kafka ìµœì í™”](#kafka-ìµœì í™”)
  - [ì‹¤ìŠµ1](#k-ex-1)
  - [ì‹¤ìŠµ2](#k-ex-2)
  - [ì‹¤ìŠµ3](#k-ex-3)
  - [ì‹¤ìŠµ4](#k-ex-4)
  - [ì‹¤ìŠµ5](#k-ex-5)
  - [ê³¼ì œ1](#k-hw-1)
  - [ê³¼ì œ2](#k-hw-2)

- [Kafka ëª¨ë‹ˆí„°ë§](#kafka-ëª¨ë‹ˆí„°ë§)
  - [ì‹¤ìŠµ1](#m-ex-1)
  - [ì‹¤ìŠµ2](#m-ex-2)
  - [ì‹¤ìŠµ3](#m-ex-3)
  - [ì‹¤ìŠµ4](#m-ex-4)
  - [ì‹¤ìŠµ5](#m-ex-5)
  - [ê³¼ì œ1](#m-hw-1)
  - [ê³¼ì œ2](#m-hw-2)

# Kafka ìµœì í™”
## ì‹¤ìŠµ1 <a id="k-ex-1"></a>
### í•™ìŠµëª©í‘œ
Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ì—¬ batch.size ê°’ì„ ì„¤ì •í•˜ê³ , ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ë©´ì„œ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•œ ë’¤, batch.size ê°’ì„ ë³€ê²½í•˜ë©° ì‹¤í—˜ì„ ìˆ˜í–‰í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

- Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  batch.size ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤.
- ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- batch.size ê°’ì„ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.  

### Step1: batch.sizeë¥¼ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ ì „ì†¡í•˜ê¸°
Kafka Producer ì„¤ì • ì¤‘ `batch.size`ëŠ”
Producerê°€ í•˜ë‚˜ì˜ ë°°ì¹˜ì— ëª¨ì•„ì„œ ì••ì¶•/ì „ì†¡í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ë°”ì´íŠ¸ í¬ê¸°ì„

- ë°°ì¹˜ í¬ê¸°ê°€ í¬ë©´:
    - ë” ë§ì€ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ë¬¶ì–´ ë³´ë‚¼ ìˆ˜ ìˆìŒ â†’ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨â†‘
    - í•˜ì§€ë§Œ ëŒ€ê¸° ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŒ
```python
BATCH_SIZES = [1024, 2048, 4096, 8192]

for batch_size in BATCH_SIZES:
    producer = KafkaProducer(
        bootstrap_servers=BROKER,
        batch_size=batch_size,
        acks=1,
        linger_ms=20
    )
```

### Step2: ë©”ì‹œì§€ í¬ê¸° 100 bytesë¡œ ì„¤ì •
- 100ë°”ì´íŠ¸ì§œë¦¬ ë©”ì‹œì§€ë¥¼ ë§Œë“¤ì–´ì•¼ batch.size íš¨ê³¼ê°€ ëª…í™•í•´ì§
- JSON êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ ë¬¸ìì—´ ê¸¸ì´ë¥¼ ì¡°ì ˆí•˜ì—¬ 100ë°”ì´íŠ¸ ê·¼ì²˜ë¡œ ë§ì¶¤
```python
MESSAGE_SIZE = 100
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode('utf-8')
```

### Step3: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- ê° batch.size ê°’ë³„ë¡œ **ë™ì¼í•œ ë©”ì‹œì§€ ê°œìˆ˜(50,000ê°œ)**ë¥¼ ë³´ë‚´ë©° ì‹œê°„ì„ ì¸¡ì •
```python
start_time = time.time()

for _ in range(NUM_MESSAGES):
    producer.send(TOPIC, MESSAGE_PAYLOAD)

producer.flush()
elapsed_time = time.time() - start_time
```

### Step4: ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ë°°ì¹˜ í¬ê¸°ì˜ ì˜í–¥ì„ ë¶„ì„í•˜ê¸°
- ì‹¤í–‰ ë°©ë²•
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties
```
```python
# batch_test.py ìƒì„±

"""
Kafka í”„ë¡œë“€ì„œì˜ ë°°ì¹˜ í¬ê¸°(`batch.size`) ë³€ê²½ì´ ë©”ì‹œì§€ ì „ì†¡ ì†ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¸¡ì •í•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.

TODO:
1. Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  `batch.size`, `compression.type`, `linger.ms` ê°’ì„ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
2. ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
3. ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ë³´ë‚¼ ë•Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

sudo apt-get update
sudo apt-get install -y g++ make cmake autoconf automake libtool pkg-config libsnappy-dev
pip install --no-binary :all: python-snappy==0.5.4
ë¥¼ ì‹¤í–‰í•´ì•¼ snappy ì••ì¶•ì´ ì •ìƒë™ì‘ í•©ë‹ˆë‹¤.
"""

from kafka import KafkaProducer
import time
import json
# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
BATCH_SIZES = [1024, 2048, 4096, 8192]  # 1KB, 2KB, 4KB, 8KB
NUM_MESSAGES = 50000  # ë©”ì‹œì§€ ê°œìˆ˜ë¥¼ 50,000ê°œë¡œ ìœ ì§€
MESSAGE_SIZE = 100  # ë©”ì‹œì§€ í¬ê¸°ë¥¼ 100ë°”ì´íŠ¸ë¡œ ì„¤ì •

# TODO 1: 100ë°”ì´íŠ¸ í¬ê¸°ì˜ JSON ë©”ì‹œì§€ë¥¼ ìƒì„±
# 20ì •ë„ë¥¼ ë¹¼ì„œ ë³´ì •í•˜ì—¬ ì‹¤ì œ ë©”ì‹œì§€ í¬ê¸°ê°€ 100ë°”ì´íŠ¸ì— ê°€ê¹ê²Œ ë˜ë„ë¡ í•¨
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode('utf-8')  # ë©”ì‹œì§€ í¬ê¸° ì„¤ì •

# TODO 2: ì„œë¡œ ë‹¤ë¥¸ ë°°ì¹˜ í¬ê¸°ì—ì„œ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ë¥¼ ë¹„êµ
for batch_size in BATCH_SIZES:
    print(f"Testing batch.size = {batch_size}...")

    # TODO 3: Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  ì„¤ì • ë³€ê²½
    producer = KafkaProducer(
        bootstrap_servers=BROKER,  # Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ ì„¤ì •
        batch_size=batch_size,  # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        acks=1,  # ë©”ì‹œì§€ ì „ì†¡ í™•ì¸ ì„¤ì •
        linger_ms=20  # ë°°ì¹˜ë¥¼ ì¶©ë¶„íˆ ëª¨ìœ¼ë„ë¡ ì„¤ì • ì¦ê°€
    )

    # TODO 4: ë©”ì‹œì§€ ì „ì†¡ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()

    # TODO 5: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì „ì†¡
    for _ in range(NUM_MESSAGES):  # ë©”ì‹œì§€ ì „ì†¡ ë°˜ë³µ íšŸìˆ˜
        producer.send(TOPIC, MESSAGE_PAYLOAD)  # ë©”ì‹œì§€ ì „ì†¡

    # TODO 6: ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ í›„ ì‹œê°„ ì¸¡ì •
    producer.flush()
    elapsed_time = time.time() - start_time

    # TODO 7: ê²°ê³¼ ì¶œë ¥
    print(f"Batch size: {batch_size}, Time taken: {elapsed_time:.3f} sec\n")

    # TODO 8: í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²© ì¶”ê°€
    time.sleep(2)  # í…ŒìŠ¤íŠ¸ ê°„ 2ì´ˆ ëŒ€ê¸°
```
```sh
python3 batch_test.py
```
- ì‹¤í–‰ ê²°ê³¼
    
    ![alt text](image-148.png)
    - `batch.size`ê°€ ì¦ê°€í• ìˆ˜ë¡ ì†ë„ ê°œì„ ë¨
    - ì´ëŠ” ë” ë§ì€ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ë¬¶ì–´ì„œ ì „ì†¡í•˜ê¸° ë•Œë¬¸
    - í•˜ì§€ë§Œ ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš© ì¦ê°€


## ì‹¤ìŠµ2 <a id="k-ex-2"></a>
### í•™ìŠµëª©í‘œ
Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  compression.typeì„ ì„¤ì •í•œ ë’¤, `none`, `gzip`, `snappy`, `lz4`ë¡œ ë³€ê²½í•˜ë©° ë™ì¼í•œ ê°œìˆ˜(`NUM_MESSAGES = 50000`)ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ë©°, ê° ì••ì¶• ë°©ì‹ì˜ ì „ì†¡ ì†ë„ì™€ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ì„ ë¹„êµÂ·ë¶„ì„í•©ë‹ˆë‹¤.

- Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  `compression.type`ì„ ì„¤ì •í•©ë‹ˆë‹¤.
- `compression.type`ì„ none, gzip, snappy, lz4ë¡œ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
- ë™ì¼í•œ ê°œìˆ˜(`NUM_MESSAGES = 50000`)ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- ê° ì••ì¶• ë°©ì‹ì˜ ì „ì†¡ ì†ë„ ë° ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰ì„ ë¹„êµí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: compression.typeì„ none, gzip, snappy, lz4ë¡œ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ ì „ì†¡
- compression_type ê°’ë§Œ ë°”ê¿”ê°€ë©° KafkaProducer ì„¤ì •ì„ ë°˜ë³µ ì‹¤í–‰
- Kafkaê°€ ê¸°ë³¸ ì œê³µí•˜ëŠ” ì••ì¶• ë°©ì‹ ë¹„êµ
    - None (ì••ì¶• ì—†ìŒ)
    - gzip
    - snappy
    - lz4
```python
COMPRESSION_TYPES = [None, "gzip", "snappy", "lz4"]

for compression_type in COMPRESSION_TYPES:
    producer = KafkaProducer(
        bootstrap_servers=BROKER,
        compression_type=compression_type,
        batch_size=16384,
        linger_ms=5,
        acks=1
    )
```

### Step2: ë©”ì‹œì§€ í¬ê¸° 100 bytesë¡œ ì„¤ì •
Kafka ì „ì†¡ëŸ‰ì„ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ JSON ë©”ì‹œì§€ë¥¼ 100 bytesë¡œ êµ¬ì„±

```python
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode('utf-8')
```
### Step3: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •
ëª¨ë“  ì••ì¶• ë°©ì‹ì—ì„œ 5ë§Œ ê°œ(NUM_MESSAGES) ë©”ì‹œì§€ë¥¼ ë™ì¼í•˜ê²Œ ì „ì†¡í•˜ì—¬ ì‹œê°„ ë¹„êµ

```python
start_time = time.time()

for _ in range(NUM_MESSAGES):
    producer.send(TOPIC, MESSAGE_PAYLOAD)

producer.flush()
elapsed_time = time.time() - start_time
```

### Step4: ê° ì••ì¶• ë°©ì‹ë³„ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë¹„êµí•˜ê³  ë¶„ì„
- ì‹¤í–‰ ë°©ë²•
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties
```
```python
# compression_benchmark.py ìƒì„±

"""
Kafka í”„ë¡œë“€ì„œì—ì„œ Gzip ë° Snappy ì••ì¶•ì„ ì ìš©í•˜ì—¬ ë©”ì‹œì§€ ì „ì†¡ ì†ë„ë¥¼ ë¹„êµí•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.

TODO:
1. Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  `batch.size`, `compression.type`, `linger.ms` ê°’ì„ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
2. ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
3. ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ë³´ë‚¼ ë•Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

sudo apt-get update && sudo apt-get install -y g++ make cmake autoconf automake libtool pkg-config libsnappy-dev liblz4-dev python3-dev build-essential \
&& pip install --no-binary :all: python-snappy==0.5.4 \
&& pip install --no-cache-dir --no-binary :all: lz4==3.1.3
ë¥¼ ì‹¤í–‰í•´ì•¼ snappy ì••ì¶•ì´ ì •ìƒë™ì‘ í•©ë‹ˆë‹¤.
"""

from kafka import KafkaProducer
import time
import json

# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
COMPRESSION_TYPES = [None, "gzip", "snappy", "lz4"]  # ì••ì¶• ì—†ìŒ, Gzip, Snappy, LZ4
NUM_MESSAGES = 50000  # ë©”ì‹œì§€ ê°œìˆ˜
MESSAGE_SIZE = 100  # ë©”ì‹œì§€ í¬ê¸° 100 bytes

# TODO 1: 100ë°”ì´íŠ¸ í¬ê¸°ì˜ JSON ë©”ì‹œì§€ë¥¼ ìƒì„±
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode('utf-8')

# TODO 2: ì••ì¶• ë°©ì‹ë³„ ì„±ëŠ¥ ì¸¡ì •
for compression_type in COMPRESSION_TYPES:
    print(f"Testing compression.type = {compression_type}...")

    # TODO 3: KafkaProducer ìƒì„±
    producer = KafkaProducer(
        bootstrap_servers=BROKER,
        compression_type=compression_type,
        batch_size=16384,      # ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
        linger_ms=5,           # ë°°ì¹˜ë¥¼ ìœ„í•œ ë”œë ˆì´
        acks=1                 # ì „ì†¡ í™•ì¸
    )

    # TODO 4: ë©”ì‹œì§€ ì „ì†¡ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()

    # TODO 5: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì „ì†¡
    for _ in range(NUM_MESSAGES):
        producer.send(TOPIC, MESSAGE_PAYLOAD)

    # TODO 6: flush() í›„ ì‹œê°„ ì¸¡ì •
    producer.flush()
    elapsed_time = time.time() - start_time

    # TODO 7: ê²°ê³¼ ì¶œë ¥
    print(f"Compression: {compression_type}, Time taken: {elapsed_time:.3f} sec\n")

    # TODO 8: í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
    time.sleep(2)
```
```sh
python3 compression_benchmark.py
```

- ì‹¤í–‰ ê²°ê³¼

    ![alt text](image-149.png)
    - ì••ì¶•í•˜ì§€ ì•Šìœ¼ë©´ CPU ë¶€ë‹´ì€ ì ì§€ë§Œ, ì „ì†¡í•´ì•¼ í•  ë°ì´í„° ì–‘ì´ í¬ê¸° ë•Œë¬¸ì— ë„¤íŠ¸ì›Œí¬ ë³‘ëª©ì´ ë°œìƒ â†’ ê°€ì¥ ëŠë¦¼


## ì‹¤ìŠµ3 <a id="k-ex-3"></a>
### í•™ìŠµëª©í‘œ
Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•´ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³ , `fetch.min.bytes`ì™€ `max.poll.records` ê°’ì„ ì¡°ì •í•˜ë©° ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•œ ë’¤, ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ë©´ì„œ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ê³  ê° ì„¤ì •ê°’ì— ë”°ë¥¸ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµÂ·ë¶„ì„í•©ë‹ˆë‹¤.
- Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
- `fetch.min.bytes` ë° `max.poll.records` ê°’ì„ ì¡°ì •í•˜ë©° ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
- ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- ê° ì„¤ì •ê°’ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: `fetch.min.bytes` ê°’ì„ 1KB, 10KB, 50KBë¡œ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ ì†Œë¹„í•˜ê¸°
- `fetch.min.bytes` ëŠ” ì»¨ìŠˆë¨¸ê°€ ìµœì†Œ ì´ë§Œí¼ì˜ ë°ì´í„°ê°€ ëª¨ì¼ ë•Œê¹Œì§€ ê¸°ë‹¤ë ¸ë‹¤ê°€ ê°€ì ¸ì˜¤ë„ë¡ í•˜ëŠ” ì˜µì…˜
- ê°’ì´ í´ìˆ˜ë¡ í•œ ë²ˆì— ë§ì´ ê°€ì ¸ì˜¤ì§€ë§Œ, ì²« ë©”ì‹œì§€ë¥¼ ë°›ê¸°ê¹Œì§€ì˜ ì§€ì—°(latency) ëŠ” ëŠ˜ì–´ë‚  ìˆ˜ ìˆìŒ
```python
FETCH_SIZES = [1024, 10240, 51200]  # 1KB, 10KB, 50KB
...
for fetch_size in FETCH_SIZES:
    ...
    consumer = KafkaConsumer(
        TOPIC,
        bootstrap_servers=BROKER,
        auto_offset_reset="earliest",
        enable_auto_commit=False,
        fetch_min_bytes=fetch_size,
        max_poll_records=poll_records
    )
```

### Step2: `max.poll.records` ê°’ì„ 10, 100, 500ìœ¼ë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- `max.poll.records` ëŠ” í•œ ë²ˆ `poll()` í˜¸ì¶œì—ì„œ ìµœëŒ€ ëª‡ ê°œì˜ ë ˆì½”ë“œë¥¼ ê°€ì ¸ì˜¬ì§€ë¥¼ ì˜ë¯¸í•¨
- ê°’ì´ í´ìˆ˜ë¡ ë£¨í”„/ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ íšŸìˆ˜ê°€ ì¤„ì–´ë“¤ì–´ ì²˜ë¦¬ëŸ‰ì´ ì¢‹ì•„ì§ˆ ìˆ˜ ìˆìŒ
```python
POLL_RECORDS = [10, 100, 500]
...
for fetch_size in FETCH_SIZES:
    for poll_records in POLL_RECORDS:
        ...
        consumer = KafkaConsumer(
            ...,
            fetch_min_bytes=fetch_size,
            max_poll_records=poll_records
        )
```

### Step3: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- ëª¨ë“  ì¡°í•©(`fetch.min.bytes` Ã— `max.poll.records`)ì— ëŒ€í•´ ê°™ì€ ìˆ˜(50,000ê°œ)ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„
- `time.time()` ìœ¼ë¡œ ì‹œì‘/ì¢…ë£Œ ì‹œê°ì„ ê¸°ë¡í•´ì„œ ê²½ê³¼ ì‹œê°„ ë¹„êµ
- ë©”ì‹œì§€ ìƒì‚° ë¶€ë¶„:
    ```python
    MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode("utf-8")

    producer = KafkaProducer(...)
    start_time = time.time()
    for _ in range(NUM_MESSAGES):
        producer.send(TOPIC, MESSAGE_PAYLOAD)
    producer.flush()
    elapsed_time = time.time() - start_time
    print(f"Produced {NUM_MESSAGES} messages in {elapsed_time:.3f} sec\n")
    ```
- ì†Œë¹„ ì¸¡ì • ë¶€ë¶„:
    ```python
    start_time = time.time()

    message_count = 0
    for message in consumer:
        message_count += 1
        if message_count >= NUM_MESSAGES:
            break

    elapsed_time = time.time() - start_time
    print(
        f"Fetch size: {fetch_size}, "
        f"Poll records: {poll_records}, "
        f"Time taken: {elapsed_time:.3f} sec\n"
    )

    ```

### Step4: ê° ì„¤ì •ê°’ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµ ë¶„ì„
- ì‹¤í–‰ ë°©ë²•
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties
```
```python
# consumer_fetch_experiment.py ìƒì„±

"""
Kafka í”„ë¡œë“€ì„œì—ì„œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ê³ , ì»¨ìŠˆë¨¸ì—ì„œ `fetch.min.bytes` ë° `max.poll.records` ê°’ì„ ë³€ê²½í•˜ë©°
ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ì‹¤í—˜í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
"""

from kafka import KafkaProducer, KafkaConsumer
import time
import json

# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
FETCH_SIZES = [1024, 10240, 51200]  # 1KB, 10KB, 50KB
POLL_RECORDS = [10, 100, 500]       # 10ê°œ, 100ê°œ, 500ê°œ
NUM_MESSAGES = 50000                # ì´ ë©”ì‹œì§€ ê°œìˆ˜
MESSAGE_SIZE = 100                  # ë©”ì‹œì§€ í¬ê¸°ë¥¼ 100ë°”ì´íŠ¸ë¡œ ì„¤ì •

# TODO 1: 100ë°”ì´íŠ¸ í¬ê¸°ì˜ JSON ë©”ì‹œì§€ë¥¼ ìƒì„±
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode("utf-8")

# TODO 2: Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  ë©”ì‹œì§€ ë°œí–‰
print("Producing messages...")

producer = KafkaProducer(
    bootstrap_servers=BROKER,  # Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ ì„¤ì •
    batch_size=16384,          # ë°°ì¹˜ í¬ê¸° ì„¤ì •
    linger_ms=5,               # ë°°ì¹˜ë¥¼ ì ì ˆíˆ í™œìš©í•˜ë„ë¡ ì„¤ì •
    acks=1                     # ë©”ì‹œì§€ ì „ì†¡ í™•ì¸ ì„¤ì •
)

# TODO 3: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì „ì†¡
start_time = time.time()  # ë©”ì‹œì§€ ì „ì†¡ ì‹œì‘ ì‹œê°„ ê¸°ë¡
for _ in range(NUM_MESSAGES):
    producer.send(TOPIC, MESSAGE_PAYLOAD)

producer.flush()  # ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ
elapsed_time = time.time() - start_time  # ê²½ê³¼ ì‹œê°„ ì¸¡ì •
print(f"Produced {NUM_MESSAGES} messages in {elapsed_time:.3f} sec\n")

# TODO 4: ì„œë¡œ ë‹¤ë¥¸ Fetch size ë° Poll ê°„ê²© ì„¤ì •ì„ ì¡°í•©í•˜ì—¬ ì»¨ìŠˆë¨¸ í…ŒìŠ¤íŠ¸
for fetch_size in FETCH_SIZES:
    for poll_records in POLL_RECORDS:
        print(f"Testing fetch.min.bytes = {fetch_size}, max.poll.records = {poll_records}...")

        # TODO 5: Kafka ì»¨ìŠˆë¨¸ë¥¼ ìƒì„±í•˜ê³  ì„¤ì • ë³€ê²½
        consumer = KafkaConsumer(
            TOPIC,
            bootstrap_servers=BROKER,   # Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ ì„¤ì •
            auto_offset_reset="earliest",  # ì˜¤í”„ì…‹ ì´ˆê¸°í™” ë°©ì‹ ì„¤ì •
            enable_auto_commit=False,      # ìë™ ì˜¤í”„ì…‹ ì»¤ë°‹ ë¹„í™œì„±í™” (ë§¤ë²ˆ ì²˜ìŒë¶€í„° ì½ë„ë¡)
            fetch_min_bytes=fetch_size,    # ìµœì†Œ Fetch í¬ê¸° ì„¤ì •
            max_poll_records=poll_records  # ìµœëŒ€ Poll ê°œìˆ˜ ì„¤ì •
        )

        # TODO 6: ë©”ì‹œì§€ ì†Œë¹„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # TODO 7: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì†Œë¹„
        message_count = 0
        for message in consumer:
            message_count += 1
            if message_count >= NUM_MESSAGES:  # ì›í•˜ëŠ” ë©”ì‹œì§€ ê°œìˆ˜ ë„ë‹¬ ì‹œ ì¢…ë£Œ
                break

        # TODO 8: ëª¨ë“  ë©”ì‹œì§€ ì†Œë¹„ ì™„ë£Œ í›„ ì‹œê°„ ì¸¡ì •
        elapsed_time = time.time() - start_time

        # TODO 9: ê²°ê³¼ ì¶œë ¥
        print(
            f"Fetch size: {fetch_size}, "
            f"Poll records: {poll_records}, "
            f"Time taken: {elapsed_time:.3f} sec\n"
        )

        # TODO 10: í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²© ì¶”ê°€
        time.sleep(2)  # í…ŒìŠ¤íŠ¸ ê°„ 2ì´ˆ ëŒ€ê¸°
```
```sh
python3 consumer_fetch_experiment.py
```
- ì‹¤í–‰ ê²°ê³¼

    ![alt text](image-150.png)
    - `fetch.min.bytes` ì¦ê°€ â†’ í•œ ë²ˆì— ë” ë§ì€ ë°ì´í„° íŒ¨ì¹˜ â†’ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨â†‘ / latencyâ†‘
    - `max.poll.records` ì¦ê°€ â†’ ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë£¨í”„/ì˜¤ë²„í—¤ë“œ ê°ì†Œ â†’ ì²˜ë¦¬ëŸ‰â†‘
    - ë„ˆë¬´ í¬ê²Œ ì¡ìœ¼ë©´ ì²˜ìŒ ì½ê¸°ê¹Œì§€ ì§€ì—°ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹¤ì‹œê°„ì„± vs ì²˜ë¦¬ëŸ‰ íŠ¸ë ˆì´ë“œì˜¤í”„ ì„¤ëª… ê°€ëŠ¥


## ì‹¤ìŠµ4 <a id="k-ex-4"></a>
### í•™ìŠµëª©í‘œ
Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•´ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³ , fetch.max.bytesì™€ max.poll.interval.ms ê°’ì„ ì¡°ì •í•˜ë©° ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•œ ë’¤, ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ë©´ì„œ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ê³  ê° ì„¤ì •ê°’ì— ë”°ë¥¸ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµÂ·ë¶„ì„í•©ë‹ˆë‹¤.

- Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
- `fetch.max.bytes` ë° `max.poll.interval.ms` ê°’ì„ ì¡°ì •í•˜ë©° ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
- ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- ê° ì„¤ì •ê°’ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: fetch.max.bytes ê°’ì„ 1KB, 10KB, 50KBë¡œ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ ì†Œë¹„í•˜ê¸°
- `fetch.max.bytes`
    - ì»¨ìŠˆë¨¸ê°€ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ìµœëŒ€ ë°ì´í„° í¬ê¸°
    - ê°’ì´ í¬ë©´ í•œ ë²ˆì— ë” ë§ì€ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì™€ì„œ íš¨ìœ¨ â†‘
- ì‹¤í—˜ ê°’:
    | ì„¤ì •    | ì˜ë¯¸               |
    | ----- | ---------------- |
    | 1024  | 1KBë§Œ ê°€ì ¸ì˜´ â†’ ì‘ì€ í˜ì¹˜ |
    | 10240 | 10KB             |
    | 51200 | 50KB â†’ ëŒ€ëŸ‰ í˜ì¹˜     |

```python
FETCH_SIZES = [1024, 10240, 51200]
consumer = KafkaConsumer(..., fetch_max_bytes=fetch_size)
```

### Step2: max.poll.interval.ms ê°’ì„ 500ms, 1000ms, 5000msë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- `max.poll.interval.ms`
    - `poll()` í˜¸ì¶œ ê°„ ìµœì¥ í—ˆìš© ì‹œê°„
    - ê°’ì´ ê¸¸ë©´ ëŠë¦¬ê²Œ ì²˜ë¦¬í•´ë„ ì„¸ì…˜ ë§Œë£Œê°€ ì•ˆë¨
- ì‹¤í—˜ ê°’:
    | ì„¤ì •     | ì˜ë¯¸                  |
    | ------ | ------------------- |
    | 500ms  | ë¹ ë¥´ê²Œ poll() í•´ì•¼ ì„¸ì…˜ ìœ ì§€ |
    | 1000ms | 1ì´ˆë§ˆë‹¤ poll ê°€ëŠ¥        |
    | 5000ms | 5ì´ˆê¹Œì§€ poll ì•ˆ í•´ë„ ìœ ì§€ë¨  |

```python
POLL_INTERVALS = [500, 1000, 5000]
consumer = KafkaConsumer(..., max_poll_interval_ms=poll_interval)
```

### Step3: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- ì´ ì‹¤í—˜ì—ì„œëŠ” 50,000ê°œ ë©”ì‹œì§€ ì²˜ë¦¬ì— ê±¸ë¦° ì‹œê°„ì„ ê¸°ë¡í•´ ë¹„êµ
- Throttling ì„¤ì •ë§ˆë‹¤ ì„±ëŠ¥ ì°¨ì´ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥
```python
start_time = time.time()
for message in consumer:
    message_count += 1
    if message_count >= NUM_MESSAGES:
        break
elapsed_time = time.time() - start_time
```

### Step4: ê° ì„¤ì •ê°’ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµ ë¶„ì„í•˜ê¸°
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties
```
```python
# throttling_consumer_test.py ìƒì„±

"""
Kafka ì»¨ìŠˆë¨¸ì—ì„œ Throttling(ì†ë„ ì œí•œ) ê¸°ëŠ¥ì„ ì ìš©í•˜ì—¬ ì²˜ë¦¬ëŸ‰ì„ ì¡°ì ˆí•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.

TODO:
1. Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤.
2. Kafka ì»¨ìŠˆë¨¸ë¥¼ ìƒì„±í•˜ê³  `fetch.max.bytes` ë° `max.poll.interval.ms` ê°’ì„ ë³€ê²½í•©ë‹ˆë‹¤.
3. ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
4. ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ì†Œë¹„í•  ë•Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
"""

from kafka import KafkaProducer, KafkaConsumer
import time
import json

# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
FETCH_SIZES = [1024, 10240, 51200]  # 1KB, 10KB, 50KB
POLL_INTERVALS = [500, 1000, 5000]  # 500ms, 1ì´ˆ, 5ì´ˆ
NUM_MESSAGES = 50000
MESSAGE_SIZE = 100

# TODO 1: 100ë°”ì´íŠ¸ í¬ê¸°ì˜ JSON ë©”ì‹œì§€ë¥¼ ìƒì„±
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode("utf-8")

# TODO 2: Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  ë©”ì‹œì§€ ë°œí–‰
print("Producing messages...")

producer = KafkaProducer(
    bootstrap_servers=BROKER,
    batch_size=16384,
    linger_ms=5,
    acks=1
)

# TODO 3: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì „ì†¡
start_time = time.time()
for _ in range(NUM_MESSAGES):
    producer.send(TOPIC, MESSAGE_PAYLOAD)

producer.flush()
elapsed_time = time.time() - start_time
print(f"Produced {NUM_MESSAGES} messages in {elapsed_time:.3f} sec\n")

# TODO 4: ì„œë¡œ ë‹¤ë¥¸ Fetch size ë° Poll ê°„ê²© ì„¤ì •ì„ ì¡°í•©í•˜ì—¬ ì»¨ìŠˆë¨¸ í…ŒìŠ¤íŠ¸
for fetch_size in FETCH_SIZES:
    for poll_interval in POLL_INTERVALS:
        print(f"Testing fetch.max.bytes = {fetch_size}, max.poll.interval.ms = {poll_interval}...")

        # TODO 5: Kafka ì»¨ìŠˆë¨¸ ìƒì„±
        consumer = KafkaConsumer(
            TOPIC,
            bootstrap_servers=BROKER,
            auto_offset_reset="earliest",
            enable_auto_commit=False,
            fetch_max_bytes=fetch_size,
            max_poll_interval_ms=poll_interval
        )

        # TODO 6: ë©”ì‹œì§€ ì†Œë¹„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # TODO 7: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì†Œë¹„
        message_count = 0
        for message in consumer:
            message_count += 1
            if message_count >= NUM_MESSAGES:
                break

        # TODO 8: ë©”ì‹œì§€ ì†Œë¹„ ì™„ë£Œ í›„ ì‹œê°„ ì¸¡ì •
        elapsed_time = time.time() - start_time

        # TODO 9: ê²°ê³¼ ì¶œë ¥
        print(
            f"Fetch max bytes: {fetch_size}, "
            f"Poll interval: {poll_interval}, "
            f"Time taken: {elapsed_time:.3f} sec\n"
        )

        # TODO 10: í…ŒìŠ¤íŠ¸ ê°„ 2ì´ˆ ëŒ€ê¸°
        time.sleep(2)
```
```sh
python3 throttling_consumer_test.py
```
- ì‹¤í–‰ ê²°ê³¼

    ![alt text](image-151.png)
    - fetch.max.bytes ì¦ê°€
        - â†’ ë„¤íŠ¸ì›Œí¬ ì™•ë³µ íšŸìˆ˜ ê°ì†Œ â†’ ì†ë„ í–¥ìƒ
    - poll interval í¬ê²Œ ì„¤ì •
        - â†’ ì•ˆì •ì ì¸ ì²˜ë¦¬
        - â†’ ë©”ì‹œì§€ë¥¼ ì²œì²œíˆ ì²˜ë¦¬í•´ë„ ì„¸ì…˜ ìœ ì§€
    - ë‘ ì˜µì…˜ ì¡°í•©ì— ë”°ë¼ ì²˜ë¦¬ëŸ‰ì´ ë‹¬ë¼ì§
        - ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ ì²˜ë¦¬ëŸ‰ vs ì•ˆì •ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ ì‹¤í—˜ ê°€ëŠ¥


## ì‹¤ìŠµ5 <a id="k-ex-5"></a>
### í•™ìŠµëª©í‘œ
Kafka ë¸Œë¡œì»¤ì˜ ì„¤ì •ì„ ë³€ê²½í•˜ê³ , `socket.send.buffer.bytes`, `socket.receive.buffer.bytes`, `num.network.threads`, `num.io.threads` ê°’ì„ ì¡°ì •í•˜ë©° ì‹¤í—˜ì„ ì§„í–‰í•œ ë’¤,ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ì—¬ ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ê³  ì„±ëŠ¥ ê²°ê³¼ë¥¼ ë¹„êµÂ·ë¶„ì„í•´ ìµœì ì˜ ì„¤ì •ì„ ë„ì¶œí•©ë‹ˆë‹¤.
- Kafka ë¸Œë¡œì»¤ì˜ ì„¤ì •ì„ ë³€ê²½í•©ë‹ˆë‹¤.
- `socket.send.buffer.bytes`, `socket.receive.buffer.bytes`, `num.network.threads`, `num.io.threads` ê°’ì„ ë³€ê²½í•˜ë©° ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.
- ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- ì„±ëŠ¥ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìµœì ì˜ ì„¤ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: socket.send.buffer.bytes ê°’ì„ 128KB, 512KB, 1MBë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- Kafka ë¸Œë¡œì»¤ ì„¤ì • íŒŒì¼(`server.properties`)ì˜
`socket.send.buffer.bytes` ê°’ì„ ë‹¤ìŒ 3ê°œë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜
    - 128 KB = 131072
    - 512 KB = 524288
    - 1 MB = 1048576
```python
SEND_BUFFER_SIZES = [131072, 524288, 1048576]

config_updates = [
    f"socket.send.buffer.bytes={send_buffer}",
    ...
]
```

### Step2: socket.receive.buffer.bytes ê°’ì„ 128KB, 512KB, 1MBë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- ìˆ˜ì‹  ë²„í¼ í¬ê¸°(`socket.receive.buffer.bytes`) ë³€ê²½ ì‹¤í—˜ë„ ë™ì¼í•œ ê°’ 3ê°œë¡œ ì§„í–‰
```python
RECEIVE_BUFFER_SIZES = [131072, 524288, 1048576]

config_updates = [
    f"socket.receive.buffer.bytes={receive_buffer}",
    ...
]
```

### Step3: num.network.threads ê°’ì„ 2, 4, 8ë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- Kafka ë¸Œë¡œì»¤ì˜ ë„¤íŠ¸ì›Œí¬ ìŠ¤ë ˆë“œ ê°œìˆ˜ë¥¼ ì¡°ì •
```python
NETWORK_THREADS = [2, 4, 8]

config_updates = [
    f"num.network.threads={net_threads}",
    ...
]
```

### Step4: num.io.threads ê°’ì„ 2, 4, 8ë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- Kafkaì˜ I/O ì²˜ë¦¬ ìŠ¤ë ˆë“œ ê°œìˆ˜ë„ ë‹¤ì–‘í•œ ê°’ìœ¼ë¡œ ì‹¤í—˜
```python
IO_THREADS = [2, 4, 8]

config_updates = [
    f"num.io.threads={io_threads}",
    ...
]
```

### Step5: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì†Œë¹„í•˜ì—¬ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •í•˜ê¸° 
- ê° ì„¤ì • ì¡°í•©ë§ˆë‹¤ Producer â†’ Consumer ìˆœì„œë¡œ ì„±ëŠ¥ ì¸¡ì •
- ë©”ì‹œì§€ ì „ì†¡ ì½”ë“œ
    ```python
    def produce_messages():
        print("Producing messages...")

        producer = KafkaProducer(
            bootstrap_servers=BROKER,
            batch_size=16384,
            linger_ms=5,
            acks=1
        )

        start_time = time.time()
        for _ in range(NUM_MESSAGES):
            producer.send(TOPIC, MESSAGE_PAYLOAD)
        producer.flush()

        elapsed = time.time() - start_time
        print(f"Produced {NUM_MESSAGES} messages in {elapsed:.3f} sec\n")
    ```

- ë©”ì‹œì§€ ì†Œë¹„ ì½”ë“œ
    ```python
    def consume_messages():
        print("Consuming messages...")

        consumer = KafkaConsumer(
            TOPIC,
            bootstrap_servers=BROKER,
            auto_offset_reset="earliest",
            enable_auto_commit=False
        )

        start_time = time.time()
        message_count = 0

        for message in consumer:
            message_count += 1
            if message_count >= NUM_MESSAGES:
                break

        elapsed = time.time() - start_time
        print(f"Consumed {NUM_MESSAGES} messages in {elapsed:.3f} sec\n")
    ```

### Step6: ê° ì„¤ì • ì¡°í•©ì—ì„œ ì„±ëŠ¥ ê²°ê³¼ ë¹„êµ ë¶„ì„
- ì´ ì¡°í•© ìˆ˜:
    - `3(send) Ã— 3(receive) Ã— 3(network) Ã— 3(io) = 81` ì¡°í•©
- ê° ì¡°í•©ë§ˆë‹¤:
    - ë¸Œë¡œì»¤ ì„¤ì • ë³€ê²½
    - ë¸Œë¡œì»¤ ìë™ ì¬ì‹œì‘
    - ë©”ì‹œì§€ 50,000ê°œ ì „ì†¡
    - ë©”ì‹œì§€ 50,000ê°œ ì†Œë¹„
    - ì†Œìš” ì‹œê°„ ê¸°ë¡
    ```python
    for send_buffer in SEND_BUFFER_SIZES:
        for receive_buffer in RECEIVE_BUFFER_SIZES:
            for net_threads in NETWORK_THREADS:
                for io_threads in IO_THREADS:

                    print(f"\n=== Testing send_buffer={send_buffer}, "
                        f"receive_buffer={receive_buffer}, "
                        f"network_threads={net_threads}, io_threads={io_threads} ===")

                    update_broker_config(send_buffer, receive_buffer, net_threads, io_threads)

                    produce_messages()
                    consume_messages()

                    time.sleep(5)
    ```

- ì „ì²´ ì‹¤í–‰
```python

"""
Kafka ë¸Œë¡œì»¤ì˜ ë©”ëª¨ë¦¬ ë° ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ ìµœì í™”í•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.
"""

from kafka import KafkaProducer, KafkaConsumer
import time
import json
import subprocess

# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
SEND_BUFFER_SIZES = [131072, 524288, 1048576]      # 128KB, 512KB, 1MB
RECEIVE_BUFFER_SIZES = [131072, 524288, 1048576]
NETWORK_THREADS = [2, 4, 8]
IO_THREADS = [2, 4, 8]
NUM_MESSAGES = 50000
MESSAGE_SIZE = 100

# TODO 1: 100ë°”ì´íŠ¸ í¬ê¸°ì˜ JSON ë©”ì‹œì§€ë¥¼ ìƒì„±
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode('utf-8')

# TODO 2: Kafka ë¸Œë¡œì»¤ ì„¤ì • ë³€ê²½
def update_broker_config(send_buffer, receive_buffer, net_threads, io_threads):
    config_updates = [
        f"socket.send.buffer.bytes={send_buffer}",
        f"socket.receive.buffer.bytes={receive_buffer}",
        f"num.network.threads={net_threads}",
        f"num.io.threads={io_threads}"
    ]

    config_file = "/home/my/kafka/config/server.properties"

    with open(config_file, "r") as file:
        lines = file.readlines()

    with open(config_file, "w") as file:
        for line in lines:
            if any(param.split("=")[0] in line for param in config_updates):
                continue
            file.write(line)
        for param in config_updates:
            file.write(param + "\n")

    restart_kafka_broker()

# TODO 3: Kafka ë¸Œë¡œì»¤ ì•ˆì „ ì¬ì‹œì‘
def restart_kafka_broker():
    result = subprocess.run(["pgrep", "-f", "kafka.Kafka"], stdout=subprocess.PIPE, text=True)

    if result.stdout.strip():
        print("Stopping Kafka broker...")
        subprocess.run(["/home/my/kafka/bin/kafka-server-stop.sh"], check=False)
        time.sleep(5)

    print("Starting Kafka broker...")
    subprocess.Popen([
        "/home/my/kafka/bin/kafka-server-start.sh",
        "/home/my/kafka/config/server.properties"
    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, close_fds=True)

    time.sleep(5)
    confirm = subprocess.run(["pgrep", "-f", "kafka.Kafka"], stdout=subprocess.PIPE, text=True)
    if not confirm.stdout.strip():
        print("Kafka did not start properly.")
    else:
        print("Kafka successfully started!")

# TODO 4: Producer ë©”ì‹œì§€ ë°œí–‰
def produce_messages():
    print("Producing messages...")

    producer = KafkaProducer(
        bootstrap_servers=BROKER,
        batch_size=16384,
        linger_ms=5,
        acks=1
    )

    start_time = time.time()
    for _ in range(NUM_MESSAGES):
        producer.send(TOPIC, MESSAGE_PAYLOAD)
    producer.flush()
    elapsed = time.time() - start_time
    print(f"Produced {NUM_MESSAGES} messages in {elapsed:.3f} sec\n")

# TODO 5: ì»¨ìŠˆë¨¸ ì†Œë¹„ í…ŒìŠ¤íŠ¸
def consume_messages():
    print("Consuming messages...")

    consumer = KafkaConsumer(
        TOPIC,
        bootstrap_servers=BROKER,
        auto_offset_reset="earliest",
        enable_auto_commit=False
    )

    start_time = time.time()
    count = 0
    for msg in consumer:
        count += 1
        if count >= NUM_MESSAGES:
            break

    elapsed = time.time() - start_time
    print(f"Consumed {NUM_MESSAGES} messages in {elapsed:.3f} sec\n")

# TODO 6: ì„¤ì • ì¡°í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
for send_buffer in SEND_BUFFER_SIZES:
    for receive_buffer in RECEIVE_BUFFER_SIZES:
        for net_threads in NETWORK_THREADS:
            for io_threads in IO_THREADS:

                print(
                    f"\n=== Testing send_buffer={send_buffer}, "
                    f"receive_buffer={receive_buffer}, "
                    f"network_threads={net_threads}, io_threads={io_threads} ==="
                )

                update_broker_config(send_buffer, receive_buffer, net_threads, io_threads)

                produce_messages()
                consume_messages()

                time.sleep(5)
```
- ì‹¤í–‰ ê²°ê³¼

    ![alt text](image-152.png)


## ê³¼ì œ1 <a id="k-hw-1"></a>
### í•™ìŠµëª©í‘œ
Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  `batch.size`, `compression.type`, `linger.ms` ë“±ì˜ ì„¤ì • ê°’ì„ ì¡°ì •í•˜ë©° ì‹¤í—˜ì„ ì§„í–‰í•œ ë’¤, ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ì—¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµÂ·ë¶„ì„í•´ ìµœì ì˜ ì„¤ì • ê°’ì„ ë„ì¶œí•©ë‹ˆë‹¤

- Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ì—¬ ì„¤ì • ê°’ì„ ì¡°ì •í•©ë‹ˆë‹¤.
- `batch.size`, `compression.type`, `linger.ms` ê°’ì„ ë³€ê²½í•˜ë©° ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.
- ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìµœì ì˜ ì„¤ì • ê°’ì„ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: batch.size ê°’ì„ 16KB, 32KB, 64KBë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- Kafka í”„ë¡œë“€ì„œê°€ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ë¬¶ëŠ” ë¬¶ìŒ í¬ê¸°ë¥¼ ì¡°ì •í•¨ìœ¼ë¡œì¨ ì „ì†¡ íš¨ìœ¨ì´ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ ì¸¡ì •
```python
BATCH_SIZES = [16384, 32768, 65536]

producer = KafkaProducer(
    bootstrap_servers=BROKER,
    batch_size=batch_size,
    compression_type=...,
    linger_ms=...,
    acks=1
)
```

### Step2: compression.typeì„ none, gzip, snappyë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- ì••ì¶• ë°©ì‹ë³„ CPU ì‚¬ìš©ëŸ‰ê³¼ ë„¤íŠ¸ì›Œí¬ ì†¡ì‹ ëŸ‰ì´ ë‹¬ë¼ ì „ì†¡ ì†ë„ì— ì˜í–¥ì„ ë¯¸ì¹¨
```py
COMPRESSION_TYPES = ["none", "gzip", "snappy"]

compression_type=compression if compression != "none" else None
```

### Step3: linger.ms ê°’ì„ 0ms, 10ms, 50msë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- linger.msëŠ” ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë°°ì¹˜ë¡œ ë¬¶ëŠ” ì‹œê°„ì„ ì˜ë¯¸í•¨
    - ê°’ì´ ì»¤ì§ˆìˆ˜ë¡ ë°°ì¹˜ ì „ì†¡ íš¨ìœ¨ â†‘, ì§€ì—°ì‹œê°„ â†‘
```py
LINGER_TIMES = [0, 10, 50]

producer = KafkaProducer(
    linger_ms=linger,
    ...
)
```

### Step4: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ê¸°
- ëª¨ë“  ì¡°í•©(batch Ã— compression Ã— linger)ì— ëŒ€í•´
ë©”ì‹œì§€ 100,000ê°œë¥¼ ì „ì†¡í•˜ì—¬ ì‹œê°„ ì¸¡ì •
```py
start_time = time.time()

for _ in range(NUM_MESSAGES):
    producer.send(TOPIC, MESSAGE_PAYLOAD)

producer.flush()
elapsed_time = time.time() - start_time
```

### Step5: ê° ì„¤ì • ì¡°í•©ì—ì„œ ì„±ëŠ¥ ê²°ê³¼ë¥¼ ë¹„êµ, ë¶„ì„
- ì‹¤í–‰ ë°©ë²•
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties

```
```py
# kafka_producer_performance_test.py ìƒì„±

"""
Kafka í”„ë¡œë“€ì„œì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.

TODO:
1. Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  `batch.size`, `compression.type`, `linger.ms` ê°’ì„ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.
2. ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
3. ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ë³´ë‚¼ ë•Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

sudo apt-get update && sudo apt-get install -y g++ make cmake autoconf automake libtool pkg-config libsnappy-dev liblz4-dev python3-dev build-essential \
&& pip install --no-binary :all: python-snappy==0.5.4 \
&& pip install --no-cache-dir --no-binary :all: lz4==3.1.3
"""

from kafka import KafkaProducer
import time
import json

# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
BATCH_SIZES = [16384, 32768, 65536]      # 16KB, 32KB, 64KB
COMPRESSION_TYPES = ["none", "gzip", "snappy"]
LINGER_TIMES = [0, 10, 50]               # 0ms, 10ms, 50ms
NUM_MESSAGES = 100000
MESSAGE_SIZE = 100

# TODO 1: 100ë°”ì´íŠ¸ í¬ê¸°ì˜ JSON ë©”ì‹œì§€ë¥¼ ìƒì„±
MESSAGE_PAYLOAD = json.dumps({"data": "A" * (MESSAGE_SIZE - 20)}).encode('utf-8')

# TODO 2: ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ë¥¼ ë¹„êµ
for batch_size in BATCH_SIZES:
    for compression in COMPRESSION_TYPES:
        for linger in LINGER_TIMES:
            print(f"Testing batch.size = {batch_size}, compression = {compression}, linger.ms = {linger}...")

            # TODO 3: Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ê³  ì„¤ì • ë³€ê²½
            producer = KafkaProducer(
                bootstrap_servers=BROKER,
                batch_size=batch_size,
                compression_type=compression if compression != "none" else None,
                linger_ms=linger,
                acks=1
            )

            # TODO 4: ë©”ì‹œì§€ ì „ì†¡ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.time()

            # TODO 5: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì „ì†¡
            for _ in range(NUM_MESSAGES):
                producer.send(TOPIC, MESSAGE_PAYLOAD)

            # TODO 6: ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ í›„ ì‹œê°„ ì¸¡ì •
            producer.flush()
            elapsed_time = time.time() - start_time

            # TODO 7: ê²°ê³¼ ì¶œë ¥
            print(f"Batch size: {batch_size}, Compression: {compression}, Linger.ms: {linger}, Time taken: {elapsed_time:.3f} sec\n")

            # TODO 8: í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²© ì¶”ê°€
            time.sleep(2)
```
```sh
python3 kafka_producer_performance_test.py 
```
- ì‹¤í–‰ ê²°ê³¼

    ![alt text](image-154.png)
    - ì´ëŸ° ì¶œë ¥ê°’ì„ ë¹„êµí•˜ì—¬
        - ê°€ì¥ ë¹ ë¥¸ ì„¤ì •
        - Cpu ì‚¬ìš©ë¥ ê³¼ íŠ¸ë ˆì´ë“œì˜¤í”„
        - ì••ì¶• ë°©ì‹ì˜ ë„¤íŠ¸ì›Œí¬ ì ˆê° íš¨ê³¼
    - ë“±ì„ ë¶„ì„í•  ìˆ˜ ìˆìŒ


## ê³¼ì œ2 <a id="k-hw-2"></a>
### í•™ìŠµëª©í‘œ
Kafka ì»¨ìŠˆë¨¸ë¥¼ ìƒì„±í•˜ê³  `max.poll.records`, `fetch.min.bytes`, `fetch.max.wait.ms` ë“±ì˜ ì„¤ì • ê°’ì„ ì¡°ì •í•˜ë©° ì‹¤í—˜ì„ ì§„í–‰í•œ ë’¤, ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ì—¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµÂ·ë¶„ì„í•´ ìµœì ì˜ ì„¤ì • ê°’ì„ ë„ì¶œí•©ë‹ˆë‹¤.
- Kafka ì»¨ìŠˆë¨¸ë¥¼ ìƒì„±í•˜ì—¬ ì„¤ì • ê°’ì„ ì¡°ì •í•©ë‹ˆë‹¤.
- `max.poll.records`, `fetch.min.bytes`, `fetch.max.wait.ms` ê°’ì„ ë³€ê²½í•˜ë©° ì‹¤í—˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.
- ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
- ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìµœì ì˜ ì„¤ì • ê°’ì„ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: max.poll.records ê°’ì„ 10, 100, 500ìœ¼ë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- `max.poll.records` ëŠ” í•œ ë²ˆ `poll()` í˜¸ì¶œì—ì„œ ìµœëŒ€ ëª‡ ê°œì˜ ë ˆì½”ë“œë¥¼ ê°€ì ¸ì˜¬ì§€ë¥¼ ì˜ë¯¸í•¨
- ê°’ì´ í´ìˆ˜ë¡ ë£¨í”„/ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œ íšŸìˆ˜ê°€ ì¤„ì–´ë“¤ì–´ ì²˜ë¦¬ëŸ‰ì´ ì¢‹ì•„ì§ˆ ìˆ˜ ìˆìŒ
- ì»¨ìŠˆë¨¸ ìƒì„± ì‹œ ì•„ë˜ ì˜µì…˜ì„ ì¡°ì •í•˜ë©° ì‹¤í–‰
```py
max_poll_records=poll_records
```
- ê°’ ëª©ë¡:
    - 10
    - 100
    - 500

### Step2: fetch.min.bytes ê°’ì„ 1KB, 10KB, 50KBë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- `fetch.min.bytes` ëŠ” ì»¨ìŠˆë¨¸ê°€ ìµœì†Œ ì´ë§Œí¼ì˜ ë°ì´í„°ê°€ ëª¨ì¼ ë•Œê¹Œì§€ ê¸°ë‹¤ë ¸ë‹¤ê°€ ê°€ì ¸ì˜¤ë„ë¡ í•˜ëŠ” ì˜µì…˜
- ê°’ì´ í´ìˆ˜ë¡ í•œ ë²ˆì— ë§ì´ ê°€ì ¸ì˜¤ì§€ë§Œ, ì²« ë©”ì‹œì§€ë¥¼ ë°›ê¸°ê¹Œì§€ì˜ ì§€ì—°(latency) ëŠ” ëŠ˜ì–´ë‚  ìˆ˜ ìˆìŒ
- ì»¨ìŠˆë¨¸ ìƒì„± ì‹œ ì•„ë˜ ì˜µì…˜ì„ ì¡°ì •í•˜ë©° ì‹¤í–‰
```py
fetch_min_bytes=fetch_min
```
- ê°’ ëª©ë¡:
    - 1KB = 1024 bytes  
    - 10KB = 10240 bytes
    - 50KB = 51200 bytes

### Step3: fetch.max.wait.ms ê°’ì„ 100ms, 500ms, 1000msë¡œ ë³€ê²½í•˜ë©° ì‹¤í—˜í•˜ê¸°
- `fetch.max.wait.ms` ëŠ” ì»¨ìŠˆë¨¸ê°€ `fetch.min.bytes` ë§Œí¼ì˜ ë°ì´í„°ë¥¼ ë°›ê¸° ìœ„í•´ ê¸°ë‹¤ë¦´ ìµœëŒ€ ì‹œê°„
- ê°’ì´ í¬ë©´ ë” ì˜¤ë˜ ê¸°ë‹¤ë ¤ì„œ í•œ ë²ˆì— ë” ë§ì€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì§€ë§Œ, ì§€ì—° ì‹œê°„ì´ ëŠ˜ì–´ë‚  ìˆ˜ ìˆìŒ
- ì»¨ìŠˆë¨¸ ìƒì„± ì‹œ ì•„ë˜ ì˜µì…˜ì„ ì¡°ì •í•˜ë©° ì‹¤í–‰
```py
fetch_max_wait_ms=fetch_wait
```
- ê°’ ëª©ë¡:
    - 100ms
    - 500ms
    - 1000ms

### Step4: ë™ì¼í•œ ê°œìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  ì‹¤í–‰ ì‹œê°„ ì¸¡ì •í•˜ê¸°
- ëª¨ë“  ì¡°í•©(`max.poll.records` Ã— `fetch.min.bytes` Ã— `fetch.max.wait.ms`)ì— ëŒ€í•´ ê°™ì€ ìˆ˜(100,000ê°œ)ì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„
- `time.time()` ìœ¼ë¡œ ì‹œì‘/ì¢…ë£Œ ì‹œê°ì„ ê¸°ë¡í•´ì„œ ê²½ê³¼ ì‹œê°„ ë¹„êµ
```py
start_time = time.time()
...
elapsed_time = time.time() - start_time
```

### Step5: ê° ì„¤ì • ì¡°í•©ì—ì„œ ì„±ëŠ¥ ê²°ê³¼ ë¹„êµ, ë¶„ì„í•˜ê¸°
- ì‹¤í–‰ ë°©ë²•
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties
```
```py
# consumer_performance_test.py ìƒì„±

"""
Kafka ì»¨ìŠˆë¨¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ì‹¤ìŠµì…ë‹ˆë‹¤.

TODO:
1. Kafka ì»¨ìŠˆë¨¸ë¥¼ ìƒì„±í•˜ê³  `max.poll.records`, `fetch.min.bytes`, `fetch.max.wait.ms` ê°’ì„ ë³€ê²½í•˜ë©° ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•©ë‹ˆë‹¤.
2. ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
3. ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ì†Œë¹„í•  ë•Œê¹Œì§€ ê±¸ë¦° ì‹œê°„ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

sudo apt-get install libsnappy-devì„ í†µí•´ ì‰˜ì—ì„œ snappyë¥¼ ì„¤ì¹˜í•´ì•¼ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.
"""

from kafka import KafkaConsumer
import time

# ì„¤ì • ê°’
BROKER = "localhost:9092"
TOPIC = "test-topic"
POLL_RECORDS = [10, 100, 500]  # í•œ ë²ˆì˜ í´ë§ì—ì„œ ê°€ì ¸ì˜¬ ìµœëŒ€ ë©”ì‹œì§€ ê°œìˆ˜
FETCH_MIN_BYTES = [1024, 10240, 51200]  # ìµœì†Œ Fetch í¬ê¸° (1KB, 10KB, 50KB)
FETCH_MAX_WAIT = [100, 500, 1000]  # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (100ms, 500ms, 1000ms)
NUM_MESSAGES = 100000  # ì´ ë©”ì‹œì§€ ê°œìˆ˜

# TODO 1: ì„œë¡œ ë‹¤ë¥¸ ì„¤ì •ì—ì„œ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ ë¹„êµ
for poll_records in POLL_RECORDS:
    for fetch_min in FETCH_MIN_BYTES:
        for fetch_wait in FETCH_MAX_WAIT:
            print(f"Testing max.poll.records = {poll_records}, fetch.min.bytes = {fetch_min}, fetch.max.wait.ms = {fetch_wait}...")

            # TODO 2: Kafka ì»¨ìŠˆë¨¸ ìƒì„±
            consumer = KafkaConsumer(
                TOPIC,
                bootstrap_servers=BROKER,      # Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ ì„¤ì •
                auto_offset_reset="earliest",  # ì˜¤í”„ì…‹ ì´ˆê¸°í™” ë°©ì‹ ì„¤ì •
                enable_auto_commit=False,      # ìë™ ì˜¤í”„ì…‹ ì»¤ë°‹ ì—¬ë¶€ ì„¤ì •
                max_poll_records=poll_records, # ìµœëŒ€ Poll ê°œìˆ˜ ì„¤ì •
                fetch_min_bytes=fetch_min,     # ìµœì†Œ Fetch í¬ê¸° ì„¤ì •
                fetch_max_wait_ms=fetch_wait   # ìµœëŒ€ Fetch ëŒ€ê¸° ì‹œê°„ ì„¤ì •
            )

            # TODO 3: ë©”ì‹œì§€ ì†Œë¹„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.time()

            # TODO 4: NUM_MESSAGES ê°œìˆ˜ë§Œí¼ ë©”ì‹œì§€ ì†Œë¹„
            message_count = 0
            for message in consumer:
                message_count += 1
                if message_count >= NUM_MESSAGES:  # ì›í•˜ëŠ” ë©”ì‹œì§€ ê°œìˆ˜ ë„ë‹¬ ì‹œ ì¢…ë£Œ
                    break

            # TODO 5: ëª¨ë“  ë©”ì‹œì§€ ì†Œë¹„ ì™„ë£Œ í›„ ì‹œê°„ ì¸¡ì •
            elapsed_time = time.time() - start_time

            # TODO 6: ê²°ê³¼ ì¶œë ¥
            print(f"Max poll records: {poll_records}, Fetch min bytes: {fetch_min}, "
                  f"Fetch max wait: {fetch_wait}, Time taken: {elapsed_time:.3f} sec\n")

            # TODO 7: í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²© ì¶”ê°€
            time.sleep(2)
```
```sh
python3 consumer_performance_test.py
```
- ì‹¤í–‰ ê²°ê³¼

    ![alt text](image-153.png)
    - max.poll.records ì¦ê°€
        - â†’ ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ë£¨í”„/ì˜¤ë²„í—¤ë“œ ê°ì†Œ â†’ ì²˜ë¦¬ëŸ‰â†‘
    - fetch.min.bytes ì¦ê°€
        - â†’ í•œ ë²ˆì— ë” ë§ì€ ë°ì´í„° íŒ¨ì¹˜ â†’ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨â†‘ / latencyâ†‘
    - fetch.max.wait.ms ì¦ê°€
        - â†’ ë” ì˜¤ë˜ ê¸°ë‹¤ë ¤ì„œ í•œ ë²ˆì— ë” ë§ì€ ë°ì´í„° íŒ¨ì¹˜ â†’ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨â†‘ / latencyâ†‘
    - ê° ì„¤ì • ì¡°í•©ì— ë”°ë¼ ì²˜ë¦¬ëŸ‰ì´ ë‹¬ë¼ì§
        - ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ ì²˜ë¦¬ëŸ‰ vs ì‹¤ì‹œê°„ì„± íŠ¸ë ˆì´ë“œì˜¤í”„ ì‹¤í—˜ ê°€ëŠ¥


# Kafka ëª¨ë‹ˆí„°ë§
## ì‹¤ìŠµ1 <a id="m-ex-1"></a>
### í•™ìŠµëª©í‘œ
Kafka ë¸Œë¡œì»¤ì˜ ìƒíƒœë¥¼ ì¡°íšŒí•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì˜ ì •ìƒ ë™ì‘ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³ , Kafka CLI ëª…ë ¹ì–´ë¥¼ í™œìš©í•´ í† í”½ ë° ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤. ì´í›„ íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ ë©”ì‹œì§€ Lagì„ ë¶„ì„í•´ ë©”ì‹œì§€ ì†Œë¹„ ì†ë„ë¥¼ íŒŒì•…í•˜ê³ , ë¸Œë¡œì»¤ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ì„ ì¡°íšŒí•˜ì—¬ ì„±ëŠ¥ ìƒíƒœë¥¼ í™•ì¸í•˜ë©°, ë§ˆì§€ë§‰ìœ¼ë¡œ ë¸Œë¡œì»¤ ë¡œê·¸ë¥¼ ëª¨ë‹ˆí„°ë§í•´ ì˜¤ë¥˜ ë° ì„±ëŠ¥ ë¬¸ì œë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
- Kafka ë¸Œë¡œì»¤ ìƒíƒœë¥¼ ì¡°íšŒí•˜ì—¬ í´ëŸ¬ìŠ¤í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
- Kafkaì˜ CLI ëª…ë ¹ì–´ë¥¼ í™œìš©í•˜ì—¬ í† í”½ ë° ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.
- íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ ë©”ì‹œì§€ Lagì„ ë¶„ì„í•˜ì—¬ ì†Œë¹„ ì†ë„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
- ë¸Œë¡œì»¤ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ì„ ì¡°íšŒí•˜ì—¬ ì„±ëŠ¥ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
- Kafka ë¸Œë¡œì»¤ì˜ ë¡œê·¸ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì˜¤ë¥˜ ë° ì„±ëŠ¥ ë¬¸ì œë¥¼ ê°ì§€í•©ë‹ˆë‹¤.  

### Step1: Kafka ë¸Œë¡œì»¤ ìƒíƒœ ì¡°íšŒ
- Kafka ì„¤ì¹˜ ë””ë ‰í† ë¦¬ì˜ `bin` í´ë”ë¡œ ì´ë™
```sh
cd ~/kafka/bin
```
- Kafka ë¸Œë¡œì»¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€ ì ê²€
```sh
sh kafka-broker-api-versions.sh --bootstrap-server localhost:9092
```
- í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Kafka ë¸Œë¡œì»¤ ëª©ë¡ê³¼ API ë²„ì „ì„ í™•ì¸

    ![alt text](image-155.png)

### Step2: í† í”½ ë° íŒŒí‹°ì…˜ ìƒíƒœ í™•ì¸
```sh
sh kafka-topics.sh --list --bootstrap-server localhost:9092
sh kafka-topics.sh --describe --topic test-topic --bootstrap-server localhost:9092
```
- í´ëŸ¬ìŠ¤í„° ë‚´ í† í”½ ëª©ë¡ì„ ì¡°íšŒí•˜ê³ , íŠ¹ì • í† í”½ì˜ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸

    ![alt text](image-156.png)

### Step3: ì»¨ìŠˆë¨¸ ê·¸ë£¹ ìƒíƒœ í™•ì¸
```sh
sh kafka-consumer-groups.sh --list --bootstrap-server localhost:9092
sh kafka-consumer-groups.sh --describe --group test-group --bootstrap-server localhost:9092
```
- ì»¨ìŠˆë¨¸ ê·¸ë£¹ ëª©ë¡ì„ ì¡°íšŒí•˜ê³ , íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ ì˜¤í”„ì…‹ ë° Lag ìƒíƒœ ë¶„ì„

    ![alt text](image-157.png)
    - Processed a total of 0 messages
        - `test-topic`ì— ì½ì„ ë©”ì‹œì§€ê°€ ì—†ìŒ
        - ê·¸ë˜ì„œ ì†Œë¹„ëœ ë©”ì‹œì§€ê°€ 0ê°œë¡œ ë‚˜ì˜´
    - Consumer group 'test-group' has no active members
        - í˜„ì¬ ì»¨ìŠˆë¨¸ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë¼ì„œ(active ìƒíƒœê°€ ì•„ë‹ˆë¼ì„œ) ë‚˜ì˜¤ëŠ” ë©”ì‹œì§€
        - ê·¸ë£¹ì€ ì¡´ì¬í•˜ì§€ë§Œ ì‹¤í–‰ ì¤‘ì¸ ì»¨ìŠˆë¨¸ê°€ ì—†ë‹¤ëŠ” ëœ»
    - OFFSET / LAG ìƒíƒœ
        - íŒŒí‹°ì…˜ 0ì˜ ìµœì‹  ì˜¤í”„ì…‹ì´ 6750000
        - ì»¨ìŠˆë¨¸ê°€ ë§ˆì§€ë§‰ìœ¼ë¡œ ì½ì€ ì˜¤í”„ì…‹ë„ 6750000
        - ë”°ë¼ì„œ Lag = 0 â†’ ì½ì„ ë©”ì‹œì§€ê°€ ì—†ìŒ
        - ì¦‰, ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ í† í”½ ë‚´ìš©ì„ ì „ë¶€ ì½ê³  ë‚œ ë’¤ ì •ìƒ ìƒíƒœ

### Step4: Kafka ë¸Œë¡œì»¤ ë¡œê·¸ í™•ì¸
```sh
cd kafka/logs
tail -f server.log
```
- Kafka ë¸Œë¡œì»¤ì˜ ë¡œê·¸ íŒŒì¼ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì˜¤ë¥˜ ë° ì„±ëŠ¥ ë¬¸ì œë¥¼ ê°ì§€í•´ì•¼ í•¨

    ![alt text](image-158.png)
    1. ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ ì²˜ìŒ Empty ìƒíƒœì˜€ìŒ
        ```sql
        Dynamic member with unknown member id joins group test-group in Empty state.
        ```
    2. ìƒˆë¡œìš´ member-idë¡œ ì»¨ìŠˆë¨¸ê°€ ê·¸ë£¹ì— ì°¸ê°€
        ```javascript
        Created a new member id console-consumer-...
        ```
    3. ë¦¬ë°¸ëŸ°ìŠ¤ ì‹œì‘ (PreparingRebalance)
        ```vbnet
        Preparing to rebalance group test-group...
        reason: Adding new member ...
        ```
    4. ê·¸ë£¹ ì•ˆì •í™” (Stabilized)
        ```csharp
        Stabilized group test-group generation 1 with 1 members
        ```
        - 1ê°œì˜ ì»¨ìŠˆë¨¸ê°€ ì •ìƒì ìœ¼ë¡œ test-groupì— ì°¸ì—¬í•´ì„œ íŒŒí‹°ì…˜ì„ ë°°ì •ë°›ìŒ
    5. ì»¨ìŠˆë¨¸ ì¢…ë£Œ (Ctrl+C)
        ```csharp
        LeaveGroup; client reason: the consumer is being closed
        ```
    6. ê·¸ë£¹ì´ ë‹¤ì‹œ Empty ìƒíƒœê°€ ë¨
        ```sql
        Group test-group with generation 2 is now empty
        ```


## ì‹¤ìŠµ2 <a id="m-ex-2"></a>
### í•™ìŠµëª©í‘œ
Kafka ë¸Œë¡œì»¤ì—ì„œ JMX í¬íŠ¸ë¥¼ í™œì„±í™”í•˜ê³ , JMXTermì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ JMXë¥¼ í†µí•´ Kafka ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì´í›„ CLI ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ ë“±ì˜ íŠ¹ì • JMX ë©”íŠ¸ë¦­ì„ í™•ì¸í•˜ê³ , JMXë¥¼ í™œìš©í•´ ë¸Œë¡œì»¤ ì„±ëŠ¥ì„ ë¶„ì„í•˜ë©° ì‹¤í–‰ ê²°ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.

- Kafka ë¸Œë¡œì»¤ì—ì„œ JMX í¬íŠ¸ë¥¼ í™œì„±í™”í•©ë‹ˆë‹¤.
- JMXTermì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , JMXë¥¼ í†µí•´ Kafka ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
- CLI ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • JMX ë©”íŠ¸ë¦­(ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ ë“±)ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
- JMXë¥¼ í™œìš©í•˜ì—¬ ë¸Œë¡œì»¤ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³ , ì‹¤í–‰ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

### Step1: Kafka JMX í¬íŠ¸ í™œì„±í™”
- KAFKA_JMX_OPTS í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ JMX í¬íŠ¸ë¥¼ í™œì„±í™”í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
# kafka ë¸Œë¡œì»¤ì—ê²Œ 9999ë²ˆ í¬íŠ¸ë¡œ JMX ì—´ì–´ì„œ ë‚´ë¶€ìƒíƒœ ë³´ì—¬ì¤˜! ë¼ëŠ” ëª…ë ¹
export KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote \
    -Dcom.sun.management.jmxremote.port=9999 \
    -Dcom.sun.management.jmxremote.rmi.port=9999 \
    -Dcom.sun.management.jmxremote.authenticate=false \
    -Dcom.sun.management.jmxremote.ssl=false \
    -Djava.rmi.server.hostname=127.0.0.1"
```
- Kafka ë¸Œë¡œì»¤ë¥¼ JMXê°€ í™œì„±í™”ëœ ìƒíƒœë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
# ì´ì „ì— ì¼œì ¸ìˆëŠ” Kafka ì¢…ë£Œ
/bin/kafka-server-stop.sh  
# ìƒˆë¡œ ì‹¤í–‰í•˜ë©´ì„œ JMX í™œì„±í™”ëœ ìƒíƒœë¡œ ì‹œì‘     
./bin/kafka-server-start.sh -daemon config/server.properties
```

### Step2: JMXTermì„ ì‚¬ìš©í•˜ì—¬ Kafka ë¸Œë¡œì»¤ ëª¨ë‹ˆí„°ë§
- JMXTerm 1.0.2 ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
wget https://github.com/jiaqi/jmxterm/releases/download/v1.0.2/jmxterm-1.0.2-uber.jar -O jmxterm.jar
java -jar jmxterm.jar -l localhost:9999
```
- Kafka JMX í¬íŠ¸(9999) ì •ìƒ í™œì„±í™”
- JMXTermìœ¼ë¡œ ë¸Œë¡œì»¤ì— ì„±ê³µì ìœ¼ë¡œ ì ‘ì†
- JMX ì½˜ì†”ì´ ì •ìƒì ìœ¼ë¡œ ëœ¸
```
Welcome to JMX terminal. Type "help" for available commands.
```

### Step3: JMXë¥¼ í™œìš©í•˜ì—¬ Kafka ì„±ëŠ¥ ì§€í‘œ í™•ì¸
- CLI ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ Kafka ë¸Œë¡œì»¤ì˜ íŠ¹ì • JMX ë©”íŠ¸ë¦­ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
bean java.lang:type=Memory
get HeapMemoryUsage
bean kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
get OneMinuteRate
bean kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce
get 99thPercentile
```
![alt text](image-160.png)

- HeapMemoryUsage
    ```ini
    committed = 1073741824 (1GB)
    max = 1073741824 (1GB)
    used = 195992384 (ì•½ 187MB)
    ```
    - Kafkaê°€ 1GB í™ì„ í™•ë³´í–ˆê³ , ê·¸ì¤‘ ì•½ 18%ë§Œ ì‚¬ìš© ì¤‘
    - ë¶€í•˜ê°€ ê±°ì˜ ì—†ëŠ” ë¸Œë¡œì»¤

- MessagesInPerSec
    ```ini
    OneMinuteRate = 0.0
    ```
    - ì§€ë‚œ 1ë¶„ ë™ì•ˆ Kafka ë¸Œë¡œì»¤ê°€ ë°›ì€ ë©”ì‹œì§€ê°€ 0ê°œë¼ëŠ” ëœ»
    - ì¦‰, Producerê°€ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì§€ ì•Šì•˜ê±°ë‚˜ ì´ë¯¸ ë©ˆì¶˜ ìƒíƒœë¼ëŠ” ì˜ë¯¸

- Produce 99thPercentile
    ```ini
    99thPercentile = 0.0
    ```
    - ë©”ì‹œì§€ ì „ì†¡(Produce ìš”ì²­)ì´ ì—†ìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ 0ì´ ì°í˜
    - ì§€ê¸ˆ ë¸Œë¡œì»¤ëŠ” ì•„ë¬´ëŸ° ë©”ì‹œì§€ë„ ë°›ê³  ìˆì§€ ì•Šì€ ìƒíƒœ


## ì‹¤ìŠµ3 <a id="m-ex-3"></a>
### í•™ìŠµëª©í‘œ
WSL í™˜ê²½ì— Prometheusë¥¼ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•œ ë’¤, Kafka ë¸Œë¡œì»¤ì—ì„œ JMX Exporterë¥¼ ì„¤ì •í•˜ì—¬ JMX ë°ì´í„°ë¥¼ Prometheus í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ , Prometheusê°€ Kafkaì˜ JMX ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.

- Prometheusë¥¼ WSL í™˜ê²½ì— ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
- Kafka ë¸Œë¡œì»¤ì—ì„œ JMX Exporterë¥¼ ì„¤ì •í•˜ì—¬ JMX ë°ì´í„°ë¥¼ Prometheus í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- Prometheusê°€ Kafkaì˜ JMX ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.  

### Step1: Prometheus ì„¤ì¹˜ & ì‹¤í–‰
- Prometheus 2.47.2 ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
wget https://github.com/prometheus/prometheus/releases/download/v2.47.2/prometheus-2.47.2.linux-amd64.tar.gz
tar -xvzf prometheus-2.47.2.linux-amd64.tar.gz
cd prometheus-2.47.2.linux-amd64
./prometheus --config.file=prometheus.yml
```
- http://localhost:9090 ë“¤ì–´ê°€ë©´ Prometheus UI í™•ì¸ ê°€ëŠ¥

### Step2: Kafka JMX Exporter ì„¤ì • ë° í™•ì¸
- JMX Exporter 0.17.2 ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
```sh 
# ë‹¤ë¥¸ í„°ë¯¸ë„
# cd ~/kafka 
wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.2/jmx_prometheus_javaagent-0.17.2.jar
```
- config.yaml íŒŒì¼ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
cd ~/kafka
nano jmx-config.yaml
```
```yml
lowercaseOutputName: true 
rules:  
- pattern: ".*" 
```
- Kafka ì‹¤í–‰ ì‹œ JMX Exporterë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
export KAFKA_OPTS="-javaagent:$(pwd)/jmx_prometheus_javaagent-0.17.2.jar=9094:$(pwd)/jmx-config.yaml"
```
- Kafkaë¥¼ ì¬ì‹œì‘í•˜ê³  JMX Exporterê°€ ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
# ì¢…ë£Œ
./bin/kafka-server-stop.sh 

# JMX ì˜µì…˜ í„°ë¯¸ë„ì— ë“±ë¡
export KAFKA_OPTS="-javaagent:$(pwd)/jmx_prometheus_javaagent-0.17.2.jar=9094:$(pwd)/jmx-config.yaml"

# ì¬ì‹œì‘
./bin/kafka-server-start.sh -daemon config/server.properties

# JMX Exporterê°€ ë–  ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸
curl http://localhost:9094/metrics
```
![alt text](image-161.png)

### Step3: Prometheusê°€ Kafkaì˜ JMX ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë„ë¡ ì„¤ì • ë° ê²€ì¦
- Prometheus ì„¤ì • íŒŒì¼(prometheus.yml)ì˜ scrape_configsì— kafkaë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    - Prometheusê°€ ì‹¤í–‰ ì¤‘ì´ë¼ë©´ Ctrl + Cë¡œ ë¨¼ì € ì¢…ë£Œ
    - Prometheus í´ë”ë¡œ ì´ë™í•œ ìƒíƒœë¼ë©´ ê·¸ëŒ€ë¡œ ì‹¤í–‰
```sh
cd ~/prometheus-2.47.2.linux-amd64
nano prometheus.yml
```
```yml
scrape_configs:  
    - job_name: 'kafka'    
static_configs:      
    - targets: ['localhost:9094']
```
- Prometheusë¥¼ ì¬ì‹œì‘í•˜ê³  Kafka ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
```sh
./prometheus --config.file=prometheus.yml
```
- Windows ë¸Œë¼ìš°ì €ì—ì„œ Prometheus UIì— ì ‘ì†í•©ë‹ˆë‹¤.
    - http://localhost:9090/targets

        ![alt text](image-162.png)
    - http://localhost:9090 -> `kafka_coordinator_group_groupmetadatamanager_value` ì…ë ¥ í›„ Execute

        ![alt text](image-163.png)

- Prometheus UIì—ì„œ Kafka ë©”íŠ¸ë¦­ì´ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    - http://localhost:9094/metrics ì—ì„œ í™•ì¸ëœ ë©”íŠ¸ë¦­ ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰

        ![alt text](image-164.png)
    - ì˜ˆì‹œ
        - JVM í™ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: `jvm_memory_bytes_used{area="heap"}`

            ![alt text](image-165.png)
        - Direct Buffer ì‚¬ìš©ëŸ‰: `jvm_buffer_pool_used_bytes{pool="direct"}`
        - ì „ì²´ buffer pool used bytes ì¡°íšŒ: `jvm_buffer_pool_used_bytes`
        - heap committed í¬ê¸°: `jvm_memory_bytes_committed{area="heap"}`
        - mapped buffer ì‚¬ìš©ëŸ‰: `jvm_buffer_pool_used_bytes{pool="mapped"}`


## ì‹¤ìŠµ4 <a id="m-ex-4"></a>
### í•™ìŠµëª©í‘œ
Kafka ë¸Œë¡œì»¤ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ì™€ ì´ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ì„ í™•ì¸í•˜ê³ , Prometheus APIë¥¼ í™œìš©í•´ ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì´í›„ Skeleton ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ê³ , ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Kafka ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ì„ ë¶„ì„í•˜ì—¬ ê°œì„ ì ì„ ë„ì¶œí•©ë‹ˆë‹¤.
- Kafka ë¸Œë¡œì»¤ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ ë° ì´ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ì„ í™•ì¸í•©ë‹ˆë‹¤.
- Prometheus APIë¥¼ í™œìš©í•˜ì—¬ Kafka ë¸Œë¡œì»¤ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
- Skeleton ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
- Kafka ë¸Œë¡œì»¤ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ê°œì„ ì ì„ ë„ì¶œí•©ë‹ˆë‹¤.  

### Step1: Kafka ë¸Œë¡œì»¤ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ ë° ì´ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ ì¡°íšŒ
- Prometheusì—ì„œ Kafka ë¸Œë¡œì»¤ì˜ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
```sh
# ./prometheus --config.file=prometheus.yml -> ì‹¤í–‰ ìƒíƒœ ìœ ì§€

# ìƒˆ í„°ë¯¸ë„
# ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ ì¡°íšŒ
curl -G 'http://localhost:9090/api/v1/query' --data-urlencode 'query=kafka_server_brokertopicmetrics_meanrate{name="MessagesInPerSec"}'
```
![alt text](image-166.png)

- Kafka ë¸Œë¡œì»¤ì˜ ì´ ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ì„ í™•ì¸í•©ë‹ˆë‹¤.
```sh
# ëˆ„ì  ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ ì¡°íšŒ
curl -G 'http://localhost:9090/api/v1/query' --data-urlencode 'query=kafka_server_brokertopicmetrics_count{name="MessagesInPerSec"}'
```
![alt text](image-167.png)

### Step2: Skeleton ì½”ë“œ ì‘ì„± ë° ì‹¤í–‰
- ì œê³µëœ Skeleton ì½”ë“œì—ì„œ `get_broker_metrics()` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì—¬ Kafka ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ êµ¬í˜„í•©ë‹ˆë‹¤.
- `analyze_broker_performance()` í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì—¬ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Kafka ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
```py
# kafka_analysis.py ìƒì„±

"""
Kafka ë¸Œë¡œì»¤ì˜ ì£¼ìš” ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

ê¸°ëŠ¥:
1. Prometheus APIë¥¼ í˜¸ì¶œí•˜ì—¬ Kafka ë¸Œë¡œì»¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
2. ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€
"""

import requests

PROMETHEUS_URL = "http://localhost:9090/api/v1/query"  # Prometheus API ì£¼ì†Œ

# ==============================
# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í•¨ìˆ˜
# ==============================
def get_broker_metrics():
    """
    Prometheus APIë¥¼ í˜¸ì¶œí•˜ì—¬ Kafka ë¸Œë¡œì»¤ì˜ ì£¼ìš” ë©”íŠ¸ë¦­(ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨, ëˆ„ì  ë©”ì‹œì§€ ìˆ˜)ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

    Returns:
        dict: {
            "message_rate": float,
            "message_count": float
        }
    """

    # ì‹¤ì œ Prometheusì—ì„œ Kafka JMX Exporterê°€ ë…¸ì¶œí•˜ëŠ” ë©”íŠ¸ë¦­ ì´ë¦„
    queries = {
        "message_rate": 'kafka_server_brokertopicmetrics_meanrate{name="MessagesInPerSec"}',
        "message_count": 'kafka_server_brokertopicmetrics_count{name="MessagesInPerSec"}'
    }

    metrics = {}

    for key, query in queries.items():
        try:
            # Prometheus API í˜¸ì¶œ
            res = requests.get(PROMETHEUS_URL, params={"query": query}, timeout=3)
            data = res.json()

            # ì •ìƒ ì‘ë‹µ + ë°ì´í„° ìˆìŒ
            if len(data["data"]["result"]) > 0:
                value = float(data["data"]["result"][0]["value"][1])
                metrics[key] = value
            else:
                metrics[key] = 0.0

        except Exception as e:
            print(f"[WARN] Prometheus ì¿¼ë¦¬ ì‹¤íŒ¨ ({key}): {e}")
            metrics[key] = None

    return metrics


# ==============================
# ì„±ëŠ¥ ë¶„ì„ í•¨ìˆ˜
# ==============================
def analyze_broker_performance():
    """
    ìˆ˜ì§‘ëœ ë©”íŠ¸ë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ Kafka ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
    """

    metrics = get_broker_metrics()
    rate = metrics.get("message_rate")
    total = metrics.get("message_count")

    # ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ
    if rate is None or total is None:
        print("ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨ - Prometheus ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìš”.")
        return

    print("=== Kafka ë¸Œë¡œì»¤ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼ ===")

    # ì„±ëŠ¥ í‰ê°€ ì¡°ê±´
    if rate > 5000:
        print("ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ ë§¤ìš° ë†’ìŒ â†’ í´ëŸ¬ìŠ¤í„° í™•ì¥ ê³ ë ¤")
    elif rate > 1000:
        print("ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ ì–‘í˜¸í•¨")
    else:
        print("ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ ë‚®ìŒ â†’ íŠ¸ë˜í”½ ì ê²€ í•„ìš”")

    print(f"í˜„ì¬ ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„: {rate:.2f} msgs/sec")
    print(f"ëˆ„ì  ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰: {total:.0f} msgs")


# ==============================
# ì‹¤í–‰ êµ¬ê°„
# ==============================
if __name__ == "__main__":
    analyze_broker_performance()
```

### Step3: Kafka ë¸Œë¡œì»¤ ì„±ëŠ¥ ë¶„ì„
- ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ê°€ 5000 msgs/sec ì´ìƒì´ë©´ "Kafka ë¸Œë¡œì»¤ì˜ ì²˜ë¦¬ ì†ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. í´ëŸ¬ìŠ¤í„° í™•ì¥ì„ ê³ ë ¤í•˜ì„¸ìš”." ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
- ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ê°€ 1000~5000 msgs/secì´ë©´ "Kafka ë¸Œë¡œì»¤ì˜ ì²˜ë¦¬ ì†ë„ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤." ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
- ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ê°€ 1000 msgs/sec ë¯¸ë§Œì´ë©´ "Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì†ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. íŠ¸ë˜í”½ ì¦ê°€ ê°€ëŠ¥ì„±ì„ ì ê²€í•˜ì„¸ìš”." ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
```sh
python3 kafka_analysis.py
```
![alt text](image-168.png)

 
## ì‹¤ìŠµ5 <a id="m-ex-5"></a>
### í•™ìŠµëª©í‘œ
- Kafka Exporterë¥¼ ì„¤ì •í•˜ê³  Prometheusì— ì—°ë™í•©ë‹ˆë‹¤.
- Kafka í† í”½ ìƒì„± í›„ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³ , ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•œ ë’¤ ì¢…ë£Œí•˜ì—¬ Lag ìƒí™©ì„ ìœ ë„í•©ë‹ˆë‹¤.
- Grafanaì—ì„œ ê³µì‹ ëŒ€ì‹œë³´ë“œ(Dashboard ID: 7589)ë¥¼ Importí•˜ê³  ì§€í‘œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
- ì»¨ìŠˆë¨¸ Lagì´ ì–´ë–»ê²Œ ì¦ê°€í•˜ê³ , ë©”ì‹œì§€ê°€ ì–´ë–»ê²Œ ì†Œë¹„ë˜ëŠ”ì§€ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.  

### Step1: Kafka Exporter ì„¤ì¹˜ ë° ì‹¤í–‰
- í„°ë¯¸ë„ êµ¬ì„±
    | í„°ë¯¸ë„ ë²ˆí˜¸    | ì—­í•                     | ì‹¤í–‰í•  ê²ƒ                 |
    | --------- | --------------------- | --------------------- |
    | **í„°ë¯¸ë„ 1** | Prometheus ì‹¤í–‰         | `./prometheus`        |
    | **í„°ë¯¸ë„ 2** | Kafka Exporter ì‹¤í–‰     | `./kafka_exporter`    |
    | **í„°ë¯¸ë„ 3** | Kafka / curl í…ŒìŠ¤íŠ¸ / í™•ì¸ | `curl`, `grep`, ê¸°íƒ€ ëª…ë ¹ |

- Kafka Exporter 1.4.2 ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”. 
```sh
# í„°ë¯¸ë„ 2ì—ì„œ ì‹¤í–‰ (Kafka Exporter ì „ìš©)
# cd ~
wget https://github.com/danielqsj/kafka_exporter/releases/download/v1.4.2/kafka_exporter-1.4.2.linux-amd64.tar.gz
tar -xvzf kafka_exporter-1.4.2.linux-amd64.tar.gz
cd kafka_exporter-1.4.2.linux-amd64
./kafka_exporter --kafka.server=localhost:9092 

# ì´ í„°ë¯¸ë„ì€ ê³„ì† ì¼œë‘¬ì•¼ í•¨
```
- Prometheusë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
```sh
# í„°ë¯¸ë„ 1ì—ì„œ ì‹¤í–‰ (Prometheus ì „ìš©)
# ì´ë¯¸ Prometheusê°€ ì‹¤í–‰ ì¤‘ì´ë©´:
pkill prometheus

# ë‹¤ì‹œ ì‹¤í–‰:
./prometheus --config.file=prometheus.yml 
```
- Kafka Exporterê°€ ì»¨ìŠˆë¨¸ Lagì„ ì •ìƒì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
```sh
curl http://localhost:9308/metrics | grep kafka_consumergroup_lag 
```
- prometheus.yml ì•ˆì— ì•„ë˜ ì„¤ì •ì´ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨
```yaml
scrape_configs:
  - job_name: 'kafka_exporter'
    static_configs:
      - targets: ['localhost:9308']
```

- ë©”íŠ¸ë¦­ í™•ì¸
```sh
curl http://localhost:9308/metrics | grep kafka_consumergroup_lag
```

### Step2: Kafka Exporter ê¸°ë°˜ Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„±
- musl ì„¤ì¹˜
```sh
sudo apt-get update
sudo apt-get install -y musl
```
- Grafana ì„¤ì¹˜
```sh
sudo apt-get install -y adduser libfontconfig1
wget https://dl.grafana.com/enterprise/release/grafana-enterprise_11.2.0_amd64.deb
sudo dpkg -i grafana-enterprise_11.2.0_amd64.deb
```

- Grafana ì‹¤í–‰
```sh
sudo service grafana-server start
```
- ìƒíƒœ í™•ì¸
```sh
sudo service grafana-server status

# Active: active (running) -> ì •ìƒ ì‹¤í–‰
```

- Grafana UIì—ì„œ ëŒ€ì‹œë³´ë“œ(Dashboard ID: 7589)ë¥¼ Importí•©ë‹ˆë‹¤. 
- http://localhost:3000
- ë¡œê·¸ì¸: skip
- Prometheus ë°ì´í„° ì†ŒìŠ¤ ë“±ë¡
    - Settings (Configuration) â†’ Data Sources
    - ì˜¤ë¥¸ìª½ ìœ„ â€œAdd data sourceâ€ í´ë¦­
    - ëª©ë¡ì—ì„œ Prometheus ì„ íƒ
        | í•­ëª©         | ê°’                          |
        | ---------- | -------------------------- |
        | **Name**   | Prometheus                 |
        | **URL**    | `http://localhost:9090`    |
        | **Access** | Browser ë˜ëŠ” Server (ë‘˜ ë‹¤ ê°€ëŠ¥) |
    - "Save & Test" ë²„íŠ¼ í´ë¦­
- Dashboard â†’ Import
- Dashboard ID ì…ë ¥: 7589
- Prometheus ë°ì´í„° ì†ŒìŠ¤ ì—°ê²°
- ë°ì´í„° ë³´ë‚´ê³  Grafana í™•ì¸
    ```sh
    # í„°ë¯¸ë„ 1
    ./bin/kafka-console-producer.sh \
    --topic lecture-test-topic \
    --bootstrap-server localhost:9092

    # í„°ë¯¸ë„ 2
    ./bin/kafka-console-consumer.sh \
    --topic lecture-test-topic \
    --from-beginning \
    --bootstrap-server localhost:9092
    ```

    ![alt text](image-169.png)


### Step3: Kafka ì»¨ìŠˆë¨¸ ê·¸ë£¹ ë° ë©”ì‹œì§€ ì†Œë¹„ëŸ‰ ë¶„ì„
- Grafanaì˜ Metrics Browserë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ Kafka Exporter ë©”íŠ¸ë¦­ì„ ê²€ìƒ‰
    - Grafana Metrics Browser(ë©”íŠ¸ë¦­ íƒìƒ‰ê¸°) ì—´ê¸°
    - Grafana ì™¼ìª½ ë©”ë‰´ â†’ Explore(ë‹ë³´ê¸° ì•„ì´ì½˜) í´ë¦­

        ![alt text](image-170.png)
- í•µì‹¬ Kafka Exporter ë©”íŠ¸ë¦­ ì •ë¦¬
    | ë¶„ì„ ëª©ì                  | Prometheus Metric ì´ë¦„                   |
    | --------------------- | -------------------------------------- |
    | ì»¨ìŠˆë¨¸ Lag               | `kafka_consumergroup_lag`              |
    | ì»¨ìŠˆë¨¸ ê·¸ë£¹ë³„ Lag í•©ê³„        | `kafka_consumergroup_lag_sum`          |
    | ì»¨ìŠˆë¨¸ ì˜¤í”„ì…‹(í˜„ì¬ ì–´ë””ê¹Œì§€ ì½ì—ˆëŠ”ì§€) | `kafka_consumergroup_offset`           |
    | íŒŒí‹°ì…˜ë³„ Producerê°€ ë³´ë‚¸ ì˜¤í”„ì…‹ | `kafka_topic_partition_current_offset` |

- ì»¨ìŠˆë¨¸ ê·¸ë£¹ë³„ ë©”ì‹œì§€ ì†Œë¹„ëŸ‰, Lag ë³€í™”, ë©”ì‹œì§€ ì†Œë¹„ìœ¨ ë“±ì„ ì‹œê°í™”
    - Grafana Exploreì—ì„œ ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ì…ë ¥:
    - `kafka_consumergroup_lag{consumergroup="test-group"}`

        ![alt text](image-172.png)


## ê³¼ì œ1 <a id="m-hw-1"></a>
### í•™ìŠµëª©í‘œ
Kafka Exporterë¥¼ ì„¤ì •í•´ Prometheusê°€ ì»¨ìŠˆë¨¸ Lag ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë„ë¡ êµ¬ì„±í•˜ê³ , Prometheus APIë¥¼ í™œìš©í•´ íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ Lagì„ ì£¼ê¸°ì ìœ¼ë¡œ ì¡°íšŒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ì´í›„ ì¼ì • ì£¼ê¸°(ì˜ˆ: 5ì´ˆ)ë§ˆë‹¤ Lagì„ ì¶œë ¥í•˜ë©°, íŠ¹ì • ì„ê³„ê°’ì„ ì´ˆê³¼í•  ê²½ìš° ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ë„ë¡ êµ¬í˜„í•©ë‹ˆë‹¤. ë˜í•œ CLIì—ì„œ í”„ë¡œë“€ì„œë¥¼ ì‹¤í–‰í•´ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ì—¬ Lag ì¦ê°€ë¥¼ í™•ì¸í•˜ê³ , ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•´ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ë©´ì„œ Lagì´ ê°ì†Œí•˜ëŠ” ê³¼ì •ì„ ê²€ì¦í•©ë‹ˆë‹¤.
- Kafka Exporterë¥¼ ì„¤ì •í•˜ì—¬ Prometheusê°€ ì»¨ìŠˆë¨¸ Lagì„ ìˆ˜ì§‘í•˜ë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤.
- Prometheus APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ Lagì„ ì£¼ê¸°ì ìœ¼ë¡œ ì¡°íšŒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
- ì¼ì • ì£¼ê¸°(ì˜ˆ: 5ì´ˆ)ë§ˆë‹¤ Lagì„ ì¶œë ¥í•˜ê³ , íŠ¹ì • ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ë©´ ê²½ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
- CLIì—ì„œ í”„ë¡œë“€ì„œë¥¼ ì‹¤í–‰í•˜ê³  ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ì—¬ Lag ì¦ê°€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
- ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  Lagì´ ê°ì†Œí•˜ëŠ” ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤.  

### Step0: Step1 ì‹¤í–‰ ì „ ì„¸íŒ…
- ëª¨ë“  í”„ë¡œì„¸ìŠ¤ í¬íŠ¸ ì¶©ëŒ ì²´í¬ í›„ ì •ë¦¬ (ì¤‘ë³µ ì‹¤í–‰ ì˜ˆë°©)
```sh
ps aux | grep kafka
ps aux | grep zookeeper

# ì¤‘ë³µ ìˆìœ¼ë©´ ì¢…ë£Œ
pkill -f kafka
pkill -f zookeeper

# íŠ¹ì • PIDë§Œ ì£½ì´ë ¤ë©´
kill -9 <PID>
```

- í¬íŠ¸ ì ê²€
    | ì„œë¹„ìŠ¤            | í¬íŠ¸   |
    | -------------- | ---- |
    | Zookeeper      | 2181 |
    | Kafka          | 9092 |
    | Kafka Exporter | 9308 |
    | Prometheus     | 9090 |
    | Grafana        | 3000 |

- Zookeeper ì‹œì‘
```sh
# ì£¼í‚¤í¼ ì‹¤í–‰
./bin/zookeeper-server-start.sh config/zookeeper.properties

# í™•ì¸
ps aux | grep zookeeper
```
- Kafka ë¸Œë¡œì»¤ ì‹œì‘
```sh
# ì¹´í”„ì¹´ ì‹¤í–‰
./bin/kafka-server-start.sh config/server.properties

# í™•ì¸
ps aux | grep kafka
```

- Kafka Topic ìƒì„±
```sh
# test-topic ìƒˆë¡œ ë§Œë“¤ê¸°
cd ~/kafka/bin
./kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# í† í”½ í™•ì¸
./kafka-topics.sh --list --bootstrap-server localhost:9092
```

- Consumer Group ìƒì„±
```sh
# ì»¨ìŠˆë¨¸ ê·¸ë£¹ì€ â€œìƒì„±â€í•˜ëŠ” ëª…ë ¹ì´ ì—†ìŒ
# ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•˜ë©´ ìë™ ìƒì„±ë¨

./kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --group test-group

# í™•ì¸
./kafka-consumer-groups.sh --list --bootstrap-server localhost:9092
```

- Producer ì‹¤í–‰
```sh
# ìƒˆ í„°ë¯¸ë„

cd ~/kafka/bin
./kafka-console-producer.sh --broker-list localhost:9092 --topic test-topic

# ë©”ì‹œì§€ ì…ë ¥
# hello
# world
# test
```
- Lag ë°œìƒì‹œí‚¤ëŠ” ë°©ë²•
    - Lagì„ ì¦ê°€ì‹œí‚¤ê³  ì‹¶ìœ¼ë©´:
        1. ì»¨ìŠˆë¨¸ ì¢…ë£Œ
        2. í”„ë¡œë“€ì„œë¡œ ë©”ì‹œì§€ ê³„ì† ì…ë ¥


### Step1: Kafka Exporterë¥¼ í™œìš©í•œ ì»¨ìŠˆë¨¸ Lag ë°ì´í„° ìˆ˜ì§‘
```sh
cd kafka_exporter-1.4.2.linux-amd64
./kafka_exporter --kafka.server=localhost:9092
```
- ì´ í„°ë¯¸ë„ì€ ê³„ì† ì—´ì–´ë‘ 
- 9308 í¬íŠ¸ì—ì„œ `/metrics` ì œê³µ

### Step2: Kafka Exporterê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
```sh
# Kafka Exporter ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
curl http://localhost:9308/metrics | grep kafka_consumergroup_lag
```

### Step3: íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ Lag ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” API í˜¸ì¶œ
```sh
curl -s http://localhost:9308/metrics | grep 'kafka_consumergroup_lag{consumergroup="test-group"}'
```

### Step4: Skeleton ì½”ë“œ ì‘ì„± ë° ì‹¤í–‰
- ì œê³µëœ Skeleton ì½”ë“œì—ì„œ `get_consumer_lag()` í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ê³ , ì¼ì • ì£¼ê¸°ë§ˆë‹¤ Lagì„ ì¶œë ¥í•˜ë„ë¡ êµ¬í˜„í•©ë‹ˆë‹¤.
```py
# consumer_lag_monitor.py

"""
Kafka Exporterë¥¼ í™œìš©í•˜ì—¬ íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ Lagì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

TODO:
1. Kafka Exporter(9308 í¬íŠ¸)ì˜ /metrics ë°ì´í„°ë¥¼ í˜¸ì¶œí•˜ì—¬ íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ Lagì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. ì¼ì • ì£¼ê¸°(ì˜ˆ: 5ì´ˆ)ë§ˆë‹¤ Lagì„ ì¶œë ¥í•©ë‹ˆë‹¤.
3. Lag ê°’ì´ íŠ¹ì • ì„ê³„ê°’(ì˜ˆ: 100 ì´ìƒ)ì„ ì´ˆê³¼í•˜ë©´ ê²½ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
"""

import time
import requests

# ì„¤ì • ê°’
PROMETHEUS_URL = "http://localhost:9308/metrics"  # Kafka Exporter ì£¼ì†Œ
CONSUMER_GROUP = "test-group"  # ëª¨ë‹ˆí„°ë§í•  ì»¨ìŠˆë¨¸ ê·¸ë£¹ëª…
LAG_THRESHOLD = 100            # Lag ì„ê³„ê°’
CHECK_INTERVAL = 5             # ì²´í¬ ì£¼ê¸° (ì´ˆ)

# -----------------------------------------
# 1. íŠ¹ì • ì»¨ìŠˆë¨¸ ê·¸ë£¹ì˜ Lag í•©ê³„ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
# -----------------------------------------
def get_consumer_lag():
    try:
        response = requests.get(PROMETHEUS_URL)
        lines = response.text.split('\n')
        total_lag = 0

        for line in lines:
            if f'kafka_consumergroup_lag{{consumergroup="{CONSUMER_GROUP}"' in line:
                try:
                    lag_value = float(line.split()[-1])
                    total_lag += lag_value
                except:
                    continue

        return total_lag

    except Exception as e:
        print(f"ERROR: Kafka Exporter ì ‘ê·¼ ì‹¤íŒ¨ â†’ {e}")
        return None


# -----------------------------------------
# 2. ì¼ì • ì£¼ê¸°ë§ˆë‹¤ Lag ëª¨ë‹ˆí„°ë§
# -----------------------------------------
print(f"â–¶ Monitoring Kafka Consumer Group Lag: {CONSUMER_GROUP}")

while True:
    lag = get_consumer_lag()

    if lag is None:
        print("Lag ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Kafka Exporter ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        print(f"Current Lag for {CONSUMER_GROUP}: {lag}")

        if lag >= LAG_THRESHOLD:
            print("âš  WARNING: Consumer Lag is too high!")

    time.sleep(CHECK_INTERVAL)
```

### Step5: CLIë¥¼ ì‚¬ìš©í•˜ì—¬ Lag ë³€í™” í™•ì¸
- ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ ì‹¤í–‰ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ í”„ë¡œë“€ì„œë¥¼ ì‹¤í–‰í•˜ì—¬ Lagì´ ì¦ê°€í•˜ëŠ” ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤.
    - Kafka Exporter ì‹¤í–‰ì€ ì´ë¯¸ í•˜ê³  ìˆì–´ì•¼í•¨(í„°ë¯¸ë„ A)

- ì»¨ìŠˆë¨¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì†Œë¹„í•˜ê³  Lagì´ ê°ì†Œí•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    - Lag ëª¨ë‹ˆí„°ë§ Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (í„°ë¯¸ë„ B)
```sh
python3 consumer_lag_monitor.py
```

- ì»¨ìŠˆë¨¸ëŠ” ì ì‹œ ë„ê³  Lag ì¦ê°€ì‹œí‚¤ê¸° (í„°ë¯¸ë„ C) 
    - Lagì„ ì¦ê°€ì‹œí‚¤ë ¤ë©´ ì»¨ìŠˆë¨¸ê°€ ë©”ì‹œì§€ë¥¼ ì½ì§€ ì•Šê³  ìˆì–´ì•¼ í•¨
    - ì»¨ìŠˆë¨¸ê°€ ì‹¤í–‰ì¤‘ì¸ í„°ë¯¸ë„ì—ì„œ `Ctrl + C` ë¡œ ì¢…ë£Œ

- í”„ë¡œë“€ì„œ ì‹¤í–‰í•´ì„œ Lag ì¦ê°€ì‹œí‚¤ê¸° (í„°ë¯¸ë„ C)
```sh
cd ~/kafka/bin
./kafka-console-producer.sh --broker-list localhost:9092 --topic test-topic

# ë©”ì‹œì§€ ì…ë ¥
# hello
# msg1
# msg2
# msg3
# msg4
```

- Lag ì¦ê°€ í™•ì¸ (í„°ë¯¸ë„ B, Python ëª¨ë‹ˆí„°ë§)
    - Python ëª¨ë‹ˆí„°ë§ í„°ë¯¸ë„ì—ì„œ ê°’ì´ ì¦ê°€í•˜ëŠ”ì§€ í™•ì¸:


- ì»¨ìŠˆë¨¸ ì‹¤í–‰í•´ì„œ Lag ê°ì†Œ í™•ì¸ (í„°ë¯¸ë„ D)
```sh
cd ~/kafka/bin
./kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --group test-group

# ì»¨ìŠˆë¨¸ê°€ ë©”ì‹œì§€ë¥¼ ì½ìœ¼ë©´ Lagì´ ì¤„ì–´ë“ ë‹¤
```


## ê³¼ì œ2 <a id="m-hw-2"></a>
### í•™ìŠµëª©í‘œ
Grafanaë¥¼ ì„¤ì¹˜í•˜ê³  ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•œ ë’¤, Prometheusë¥¼ Grafanaì˜ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì—°ê²°í•˜ì—¬ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ì´í›„ Kafkaì˜ ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ(CPU ì‚¬ìš©ëŸ‰, JVM ë©”ëª¨ë¦¬, GC ì‹œê°„, ë©”ì‹œì§€ ìˆ˜ì‹ ëŸ‰, ë°”ì´íŠ¸ ì…ì¶œë ¥ ë“±)ë¥¼ ì‹œê°í™”í•˜ëŠ” ê³µì‹ ëŒ€ì‹œë³´ë“œë¥¼ Importí•˜ê³ , êµ¬ì„±ëœ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ Kafka ë¸Œë¡œì»¤ì˜ ì„±ëŠ¥ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
- Grafanaë¥¼ ì„¤ì¹˜í•˜ê³  ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.
- Prometheusë¥¼ Grafanaì˜ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì—°ê²°í•˜ì—¬ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
- Kafkaì˜ ì„±ëŠ¥ ì§€í‘œ(CPU ì‚¬ìš©ëŸ‰, JVM ë©”ëª¨ë¦¬, GC ì‹œê°„, ë©”ì‹œì§€ ìˆ˜ì‹ ëŸ‰, ë°”ì´íŠ¸ ì…ì¶œë ¥ ë“±)ë¥¼ ì‹œê°í™”í•˜ëŠ” ê³µì‹ ëŒ€ì‹œë³´ë“œë¥¼ Importí•©ë‹ˆë‹¤.
- êµ¬ì„±ëœ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ Kafka ë¸Œë¡œì»¤ì˜ ì£¼ìš” ì„±ëŠ¥ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.  

### Step1: Grafana ì„¤ì¹˜ ë° ì‹¤í–‰
- í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ Grafana 10.2.2ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. 
```bash
wget https://dl.grafana.com/oss/release/grafana-10.2.2.linux-amd64.tar.gz
tar -xvzf grafana-10.2.2.linux-amd64.tar.gz
cd grafana-10.2.2
./bin/grafana-server
``` 
- Windows ë¸Œë¼ìš°ì €ì—ì„œ Grafana UI ì ‘ì†
    - ì£¼ì†Œ: http://localhost:3000
    - ë¡œê·¸ì¸ ì •ë³´: admin / admin

- Prometheus ì‹¤í–‰
```sh
cd ~/prometheus
./prometheus --config.file=prometheus.yml
```

### Step2: Prometheus ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
- Grafana UIì—ì„œ Connections â†’ Data Sourcesë¡œ ì´ë™í•©ë‹ˆë‹¤.
- "Add data source" ë²„íŠ¼ì„ í´ë¦­í•˜ê³  Prometheusë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
- URLì„ http://localhost:9090ìœ¼ë¡œ ì„¤ì •í•œ í›„ Save & Testë¥¼ í´ë¦­í•˜ì—¬ ì—°ê²°ì„ í™•ì¸í•©ë‹ˆë‹¤. 

### Step3: Kafka ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ Import
- Grafana UI ìƒë‹¨ ë©”ë‰´ì—ì„œ + â†’ Importë¡œ ì´ë™í•©ë‹ˆë‹¤.
- Dashboard ID: 721ì„ ì…ë ¥í•˜ê³  Load ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤. 
    - (ë§í¬ : https://grafana.com/grafana/dashboards/721-kafka/)
- ë°ì´í„° ì†ŒìŠ¤ë¡œ Prometheusë¥¼ ì„ íƒí•˜ê³  Importë¥¼ í´ë¦­í•©ë‹ˆë‹¤.

### Step4: ì£¼ìš” ë©”íŠ¸ë¦­ í™•ì¸ ë° ë¶„ì„
- Importëœ ëŒ€ì‹œë³´ë“œì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ Kafka ì£¼ìš” ë©”íŠ¸ë¦­ì´ ì‹œê°í™”ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. 
    - CPU Usage
    - JVM Memory Used
    - Time spent in GC
    - Messages In per Topic
    - Bytes In per Topic
    - Bytes Out per Topic 

### Step5: ì‹¤ìŠµ ê²°ê³¼ ì œì¶œ
- ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì„±í•œ í›„, ì£¼ìš” íŒ¨ë„ì˜ ì‹œê°í™”í•˜ì„¸ìš”

### Step6: ì§„í–‰ì‹œ ìœ ì˜ì‚¬í•­
- â‘  ë©”ì‹œì§€ ì „ì†¡ í•„ìˆ˜ 
    - ë‹¤ìŒ ë©”íŠ¸ë¦­ì€ Kafkaì— ë©”ì‹œì§€ê°€ ì‹¤ì œë¡œ ì „ì†¡ë˜ì–´ì•¼ë§Œ ì‹œê°í™” íŒ¨ë„ì— ë°ì´í„°ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. 
        - Messages In per Topic
        - Bytes In per Topic
        - Bytes Out per Topic 
    - ë”°ë¼ì„œ ì‹¤ìŠµ ì¤‘ì—ëŠ” `kafka-console-producer.sh`ë¥¼ í™œìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ë°˜ë“œì‹œ ì „ì†¡í•´ ë³´ì„¸ìš”. 
- â‘¡ ì¿¼ë¦¬ ìˆ˜ì • í•„ìš”ì„± 
    - ê³µì‹ ëŒ€ì‹œë³´ë“œê°€ ì—…ë°ì´íŠ¸ëœ ì§€ ë‹¤ì†Œ ì‹œê°„ì´ ì§€ë‚˜, ì¼ë¶€ íŒ¨ë„ì—ì„œëŠ” ë©”íŠ¸ë¦­ì´ ë¹„ì •ìƒì ìœ¼ë¡œ í‘œì‹œë˜ê±°ë‚˜ ì‚¬ë¼ì§€ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. 
    - ì´ëŸ´ ê²½ìš°, ë‹¤ìŒê³¼ ê°™ì€ ì¿¼ë¦¬ë¡œ ìˆ˜ì •í•˜ë©´ ë³´ë‹¤ ì•ˆì •ì ìœ¼ë¡œ ë©”íŠ¸ë¦­ì´ í‘œì‹œë©ë‹ˆë‹¤: 
        - `sum by(topic) (kafka_server_BrokerTopicMetrics_OneMinuteRate{name="MessagesInPerSec"})`
        - `sum by(topic) (kafka_server_BrokerTopicMetrics_OneMinuteRate{name="BytesInPerSec"})` 
        - `sum by(topic) (kafka_server_BrokerTopicMetrics_OneMinuteRate{name="BytesOutPerSec"})` 
    - ìˆ˜ì •ëœ ì¿¼ë¦¬ëŠ” í† í”½ë³„ í•©ê³„(sum by topic) ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤.
    - ì™œ ì´ ë°©ì‹ì´ì–´ì•¼ ì§„í–‰ì´ ë˜ëŠ”ì§€, ì–´ë–¤ ë³€í™”ê°€ ìˆì—ˆëŠ”ì§€ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”.
