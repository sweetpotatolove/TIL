{"cells":[{"cell_type":"markdown","id":"1f4b6a34","metadata":{"id":"1f4b6a34"},"source":["### **Content License Agreement**\n","\n","<font color='red'><b>**WARNING**</b></font> : 본 자료는 삼성청년SW·AI아카데미의 컨텐츠 자산으로, 보안서약서에 의거하여 어떠한 사유로도 임의로 복사, 촬영, 녹음, 복제, 보관, 전송하거나 허가 받지 않은 저장매체를 이용한 보관, 제3자에게 누설, 공개 또는 사용하는 등의 무단 사용 및 불법 배포 시 법적 조치를 받을 수 있습니다."]},{"cell_type":"markdown","id":"add5dacf","metadata":{"id":"add5dacf"},"source":["### **Objectives**\n","\n","1. 실습명: 토큰화/임베딩 실습\n","2. 핵심 주제\n","    1) tokenizer를 이용하여 단어들을 토큰으로 변환하는 과정을 이해\n","    2) 토큰화된 토큰들을 임베딩 벡터로 변환하는 과정을 이해\n","    3) RNN부터 트랜스포머까지 모델의 발전사를 직접 체험하고 각 요소 기술의 역할을 이해\n","3. 학습 목표\n","    1) 토크나이저가 무엇이고 토큰화가 무엇인지에 대해서 설명할 수 있다.\n","    2) 토큰화를 왜 하는지에 대해서 설명할 수 있다.\n","    3) 토큰화된 토큰들을 임베딩 벡터로 변환하는 과정을 이해할 수 있다.\n","    4) 임베딩 벡터를 이용하여 어떤 식으로 활용할 수 있는지 설명할 수 있다.\n","    5) 다양한 모델의 발전사에 대해 직접 체험하고 각 아키텍쳐가 가지는 특징을 설명할 수 있다.\n","\n","4. 학습 개념\n","    1) 토큰화:\n","    2) 임베딩 벡터:\n","    3) 인코더/디코더:\n","  \n","5. 학습 방향\n","    - 실습은 아래 내용들을 직접 체험하고 각 아키텍쳐가 가지는 특징을 이해하는 것이 목표입니다.\n","      - 토큰화\n","      - 임베딩\n","      - RNN\n","      - LSTM\n","      - 어텐션 메커니즘\n","      - 인코더\n","      - 디코더\n","    - 실습 코드는 조교가 직접 구현한 코드를 참고하며 학습합니다.\n","    - 자연스럽게 코드를 구현하면서 아키텍쳐의 발전사를 체험합니다.\n","\n","6. 데이터셋 개요 및 저작권 정보\n","    - 데이터셋 명 : NSMC(Naver Sentiment Movie Corpus)\n","    - 데이터셋 개요 : 네이버 영화 감정분석 데이터셋\n","    - 데이터셋 저작권 : CC0 1.0"]},{"cell_type":"markdown","id":"73e73769","metadata":{"id":"73e73769"},"source":["### **Prerequisites**\n","```\n","numpy==2.0.2\n","pandas==2.2.2\n","tokenizers==0.21.4\n","transformers==4.55.2\n","torch==2.8.0+cu126\n","```\n","\n","- 만약, 기본 코랩과 버전이 다르다면 아래 명령어를 복사해서 실행시켜주세요.\n","```\n","%pip install numpy==2.0.2 pandas==2.2.2 tokenizers==0.21.4 transformers==4.55.2 torch==2.8.0+cu126 --index-url https://download.pytorch.org/whl\n","```"]},{"cell_type":"code","execution_count":1,"id":"b1260a59","metadata":{"id":"b1260a59","executionInfo":{"status":"ok","timestamp":1760525507925,"user_tz":-540,"elapsed":9772,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from typing import (\n","    Generic,\n","    Tuple,\n","    TypeVar,\n","    List,\n","    Union,    get_args\n",")\n","# 시드 설정\n","np.random.seed(1234)\n","torch.manual_seed(1234)\n","torch.cuda.manual_seed(1234)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","Batch = TypeVar(\"Batch\", bound=int)\n","Token = TypeVar(\"Token\", bound=int)\n","Sequence = TypeVar(\"Sequence\", bound=int)\n","Layers = TypeVar(\"Layers\", bound=int)\n","HiddenStates = TypeVar(\"HiddenStates\", bound=int)\n","VocabSize = TypeVar(\"VocabSize\", bound=int)\n","EmbeddingSize = TypeVar(\"EmbeddingSize\", bound=int)\n","MaxLength = TypeVar(\"MaxLength\", bound=int)\n","\n","_1D = TypeVar(\"_1D\")\n","_2D = TypeVar(\"_2D\")\n","_3D = TypeVar(\"_3D\")\n","\n","def _label_str(self) -> str:\n","    \"\"\"인스턴스의 제네릭 라벨 이름을 예쁘게 표시 (e.g., [Sequence])\"\"\"\n","    oc = getattr(self, \"__orig_class__\", None)\n","    if oc is None:\n","        return \"[]\"\n","    args = get_args(oc)\n","    names = [getattr(a, \"__name__\", str(a)) for a in args]\n","    return \"[\" + \", \".join(names) + \"]\"\n","\n","\n","class Tensor1D(Generic[_1D]):\n","    def __init__(self, tensor: torch.Tensor):\n","        assert tensor.dim() == 1, ValueError(\"Tensor must be 1-dimensional\")\n","        self.tensor = tensor\n","        self.s: _1D = tensor.size(0)  # sequence length\n","\n","    def size(self) -> Tuple[int, int]:\n","        return self.tensor.size()\n","\n","    def __repr__(self) -> str:\n","        return f\"Tensor(shape=({self.s}))\"\n","\n","class Tensor2D(Generic[_1D, _2D]):\n","    def __init__(self, tensor: torch.Tensor):\n","        assert tensor.dim() == 2, ValueError(\"Tensor must be 2-dimensional\")\n","        self.tensor = tensor\n","        self.b: _1D = tensor.size(0)  # batch size\n","        self.s: _2D = tensor.size(1)  # sequence length\n","        assert self.b == tensor.size(0), ValueError(\n","            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n","        )\n","        assert self.s == tensor.size(1), ValueError(\n","            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n","        )\n","\n","    def size(self) -> Tuple[int, int]:\n","        return self.tensor.size()\n","\n","    def __repr__(self) -> str:\n","        return f\"Tensor(shape=({self.b}, {self.s}))\"\n","\n","\n","class Tensor3D(Generic[_1D, _2D, _3D]):\n","    def __init__(self, tensor: torch.Tensor):\n","        assert tensor.dim() == 3, ValueError(\"Tensor must be 3-dimensional\")\n","        self.tensor = tensor\n","        self.b: _1D = tensor.size(0)  # batch size\n","        self.s: _2D = tensor.size(1)  # sequence length\n","        self.h: _3D = tensor.size(2)  # hidden state size\n","        assert self.b == tensor.size(0), ValueError(\n","            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n","        )\n","        assert self.s == tensor.size(1), ValueError(\n","            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n","        )\n","        assert self.h == tensor.size(2), ValueError(\n","            f\"Expected Hidden State {self.h}, but got {tensor.size(2)}\"\n","        )\n","\n","    def size(self) -> Tuple[int, int]:\n","        return self.tensor.size()\n","\n","    def __repr__(self) -> str:\n","        return f\"Tensor(shape=({self.b}, {self.s}, {self.h}))\"\n"]},{"cell_type":"markdown","id":"d55eb901","metadata":{"id":"d55eb901"},"source":["# 1. 토크나이저 / 워드 임베딩\n","\n","- 학습 목표\n","  1. 토크나이저를 학습할 수 있다.\n","  2. 토크나이저를 사용하여 텍스트를 토큰 ID 시퀀스로 변환하는 방법을 이해하고 구현할 수 있ㅏ.\n","- 학습 개념\n","  1. 토크나이저\n","  2. 토큰화\n","  3. 임베딩\n","- 진행하는 실습 요약\n","  1. 제공된 말뭉치로 WordPiece 토크나이저를 훈련시키는 코드 한 줄을 완성\n","  2. 훈련된 토크나이저를 사용해 특정 문장을 토큰 ID 시퀀스로 변환하는 코드\n","  3. nn.Embedding 레이어(혹은 간단한 dict lookup)를 사용하여 주어진 토큰 ID에 해당하는 임베딩 벡터를 조회하는 코드"]},{"cell_type":"markdown","id":"c42fdfec","metadata":{"id":"c42fdfec"},"source":["### 1.1. Tokenizer 학습\n","\n","<blockquote>\n","<b>🧠 토크나이저 학습</b><br>\n","언어 모델에서 토크나이저는 텍스트를 토큰으로 변환하는 역할을 합니다. 토크나이저를 학습하는 방법에 대해 알아봅니다.\n","</blockquote>\n","\n","토크나이저를 학습하기 위해서는 다음 두가지가 필요합니다.\n","1. 토크나이저 객체(클래스)\n","2. 학습 데이터\n"]},{"cell_type":"markdown","id":"9cc62bac","metadata":{"id":"9cc62bac"},"source":["그러면 우선 학습 데이터를 준비해보겠습니다.\n","\n","학습할 텍스트 데이터가 들어있는 파일을 준비합니다.\n","\n","여기서는 NSMC(Naver Sentiment Movie Corpus) 데이터셋을 사용하겠습니다.\n","\n","아래 명령어를 실행하여 데이터셋을 다운로드 받습니다."]},{"cell_type":"code","execution_count":2,"id":"97b7effd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97b7effd","executionInfo":{"status":"ok","timestamp":1760525508891,"user_tz":-540,"elapsed":959,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"82603053-74e2-4019-aca3-2f870e1a2930"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-10-15 10:51:48--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n","--2025-10-15 10:51:48--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19515078 (19M) [text/plain]\n","Saving to: ‘ratings.txt’\n","\n","ratings.txt         100%[===================>]  18.61M  --.-KB/s    in 0.1s    \n","\n","2025-10-15 10:51:49 (145 MB/s) - ‘ratings.txt’ saved [19515078/19515078]\n","\n"]}],"source":["!wget https://github.com/e9t/nsmc/raw/master/ratings.txt"]},{"cell_type":"markdown","id":"facaabde","metadata":{"id":"facaabde"},"source":["데이터셋을 확인해봅니다."]},{"cell_type":"code","execution_count":3,"id":"dd94219a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"id":"dd94219a","executionInfo":{"status":"ok","timestamp":1760525519311,"user_tz":-540,"elapsed":2391,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"ef2c238a-b40c-469e-c0f9-908e77623cc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["학습에 필요한 파일이 존재합니다! ratings.txt\n","리뷰 갯수 : 199992\n"]},{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n","1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n","2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n","3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n","4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"],"text/html":["\n","  <div id=\"df-aac26580-81a8-4533-b7e0-d380141b23a2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8112052</td>\n","      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8132799</td>\n","      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4655635</td>\n","      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9251303</td>\n","      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10067386</td>\n","      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aac26580-81a8-4533-b7e0-d380141b23a2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-aac26580-81a8-4533-b7e0-d380141b23a2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-aac26580-81a8-4533-b7e0-d380141b23a2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f76ddcd9-838c-4d13-8584-9b0d168d9d10\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f76ddcd9-838c-4d13-8584-9b0d168d9d10')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f76ddcd9-838c-4d13-8584-9b0d168d9d10 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":3}],"source":["import pandas as pd\n","import os\n","\n","file_list = os.listdir()\n","for file in file_list:\n","    if \"ratings.txt\" == file:\n","        print('학습에 필요한 파일이 존재합니다!', file)\n","        df = pd.read_table( (os.getcwd() + '/' + file), encoding='utf-8') # 데이터 프레임으로 보기 편하게 바꿔줍시다!\n","        df = df.dropna(how = 'any') # 널값을 없애줍니다!\n","        print('리뷰 갯수 :', len(df))\n","df.head()"]},{"cell_type":"markdown","id":"ed3146be","metadata":{"id":"ed3146be"},"source":["텍스트 데이터가 있는 'document'열만을 가져오고\n","\n","해당 데이터를 txt 파일로 저장합니다."]},{"cell_type":"code","execution_count":4,"id":"c0224daf","metadata":{"id":"c0224daf","executionInfo":{"status":"ok","timestamp":1760525519624,"user_tz":-540,"elapsed":300,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"outputs":[],"source":["with open((os.getcwd() + '/' + 'naver_review.txt'), 'w', encoding='utf8') as f:\n","    # TODO: document 열만 가져와서 저장하는 코드를 구현합니다.\n","    f.write('\\n'.join(df['document']))"]},{"cell_type":"markdown","id":"252458b8","metadata":{"id":"252458b8"},"source":["학습이 되어 있지 않은 빈 tokenizer를 생성합니다.\n","\n","여기서는 BertWordPieceTokenizer를 불러옵니다.\n","\n","이 토크나이저는 BERT라는 사전학습 모델이 사용하는 WordPiece 알고리즘 기반으로,  \n","문장을 subword 단위로 분리하는 방식입니다.  \n","\n","- Subword 단위 분리란 단어 조각(subword)들을 어휘(vocabulary)에 포함시키고, 나머지 희귀 단어들은 그 subword들의 조합으로 표현\n","- 이렇게 해서 적당한 크기의 어휘집(Vocab) 을 만든다는 개념\n","- Wordpiece: 모델 확률이 가장 높아지는 쌍\n","- BPE(Byte Pair Encoding): 가장 자주 등장하는 문자 쌍\n","\n","##### 파라미터:\n","- `strip_accents` : 입력 텍스트의 악센트(액센트)를 제거할지 여부를 결정하는 옵션입니다. 한국어를 학습할때에는 `False`로 설정합니다.\n","- `lowercase` : 영어를 모두 소문자로 바꿉니다. `False`로 설정하면 영어를 대문자로 유지합니다.\n","\n"]},{"cell_type":"code","execution_count":5,"id":"9d919be5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d919be5","executionInfo":{"status":"ok","timestamp":1760525520890,"user_tz":-540,"elapsed":136,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"6170e3ec-4a72-45fb-c753-a429942bd93e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer(vocabulary_size=0, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=False, lowercase=False, wordpieces_prefix=##)"]},"metadata":{},"execution_count":5}],"source":["from tokenizers import BertWordPieceTokenizer\n","\n","# 빈 tokenizer 생성 : vocabulary_size = 0 인 것을 확인하실 수 있습니다.\n","tokenizer = BertWordPieceTokenizer(\n","    lowercase=False,     # 입력 문장을 소문자로 변환하지 않음\n","    strip_accents=False, # 발음기호를 제거하지 않음\n",")\n","tokenizer"]},{"cell_type":"markdown","id":"3a4e500b","metadata":{"id":"3a4e500b"},"source":["아래 코드를 실행하여 토크나이저를 학습합니다.\n","#### 파라미터 설명:\n","- `data_file` : 데이터 경로를 지정해줍니다. list 형태로 여러개의 파일을 지정해줄수도 있습니다.\n","- `vocab_size (default: 30000)` : 단어사전 크기를 지정할 수 있습니다. 어떠한 값이 가장 좋다는 것은 없지만, 값이 클수록 많은 단어의 의미를 담을 수 있습니다.\n","- `initial_alphabet` : 꼭 포함됐으면 하는 initial alphabet을 학습 전에 추가해줍니다.\n","    - initial은 학습하기 이전에 미리 단어를 vocab에 넣는 것을 의미합니다.\n","    - special token들도 initial에 vocab에 추가됩니다.\n","- `limit_alphabet (default: 1000)` : initial tokens의 갯수를 제한합니다.\n","- `min_frequency (default: 2)` : 최소 빈도수를 의미합니다. 만약 어떤 단어가 1번 나오면 vocab에 추가하지 않습니다.\n","- `special_tokens` : 특수 토큰을 넣을 수 있습니다.. BERT에는 다음과 같은 토큰이 들어가야 합니다.\n","    - `[PAD]` : 패딩을 위한 토큰\n","    - `[UNK]` : OOV 단어를 위한 토큰\n","    - `[CLS]` : 문장의 시작을 알리고 분류 문제에 사용되는 토큰\n","    - `[SEP]` : 문장 사이사이를 구별해주는 토큰\n","    - `[MASK]` : MLM 태스크를 위한 마스크 토큰\n","- `wordpiece_prefix(default: '##')` : sub-word라는 것을 알려주는 표시입니다.\n","    - BERT는 기본적으로 '##'을 씁니다.\n","    - 예를 들어, `SS, ##AF, ##Y` 처럼 sub-word를 구분하기 위해 '##'을 사용합니다.\n","- `show_progress` : 학습 과정을 보여줍니다."]},{"cell_type":"code","execution_count":9,"id":"82aa578c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82aa578c","executionInfo":{"status":"ok","timestamp":1760526316497,"user_tz":-540,"elapsed":13215,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"f0c60336-4873-4fe7-d7d2-919f4b6726f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["vocab size :  30000\n","['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']\n"]}],"source":["data_file = 'naver_review.txt'         # 학습할 텍스트 파일 경로\n","vocab_size = 30000                     # 최종 어휘 사전(vocab)의 최대 크기\n","min_frequency = 2                      # 최소 등장 빈도 (2회 미만 단어는 무시)\n","initial_alphabet = []                  # 초기 알파벳 세트 (비워두면 자동추출)\n","limit_alphabet = 6000                  # 알파벳(문자) 개수 제한\n","special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n","wordpieces_prefix = \"##\"               # subword 결합 시 앞에 붙는 접두사 (예: \"##ing\")\n","show_progress = True                   # 학습 진행 상황을 출력할지 여부\n","\n","\n","# - tokenizer.train() 메서드를 통해 지정한 파일을 학습합니다.\n","# - 내부적으로 다음을 수행:\n","#   1) 말뭉치(corpus)를 읽어 토큰 빈도 계산\n","#   2) 자주 등장하는 subword 조합을 병합\n","#   3) 어휘(vocabulary)를 구성 (max vocab_size까지)\n","tokenizer.train(\n","    files = data_file,\n","    vocab_size = vocab_size,\n","    min_frequency = min_frequency,\n","    initial_alphabet = initial_alphabet,\n","    limit_alphabet = limit_alphabet,\n","    special_tokens = special_tokens,\n","    wordpieces_prefix = wordpieces_prefix,\n","    show_progress = True,\n",")\n","\n","vocab = tokenizer.get_vocab()\n","print(\"vocab size : \", len(vocab))\n","print(sorted(vocab, key=lambda x: vocab[x])[:20])"]},{"cell_type":"code","source":["print(sorted(vocab, key=lambda x: vocab[x])[5000:5020])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APnNfN3Viy3L","executionInfo":{"status":"ok","timestamp":1760526316513,"user_tz":-540,"elapsed":13,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"d61a90a1-5648-46b4-e8d6-70dcf518c478"},"id":"APnNfN3Viy3L","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['##갉', '##귯', '##↗', '##싢', '##쥑', '##돔', '##믈', '##룔', '##샙', '##쨋', '##왘', '##뱍', '##궐', '##돤', '##갚', '##쭁', '##솟', '##흫', '##슛', '##낱', '##～', '##캇', '##햅', '##곷', '##딛', '##쏜', '##냣', '##꺽', '##뉜', '##앟', '##륫', '##꼳', '##｀', '##릐', '##눔', '##읮', '##곅', '##튐', '##쨱', '##↖', '##넫', '##귱', '##퐛', '##짊', '##ㅄ', '##덱', '##앱', '##■', '##챌', '##냬', '##덟', '##쌕', '##븜', '##뺐', '##싴', '##엲', '##롄', '##샣', '##풕', '##멩', '##껭', '##픕', '##꿎', '##냑', '##숩', '##♬', '##♪', '##셥', '##넵', '##웜', '##끋', '##렙', '##폄', '##줏', '##땋', '##쉰', '##깬', '##콬', '##튠', '##븨', '##몀', '##웁', '##쬐', '##흨', '##붉', '##툭', '##좝', '##퐉', '##캉', '##늄', '##훓', '##헸', '##뱃', '##팁', '##쫒', '##팟', '##맠', '##줜', '##●', '##춧', '##쭐', '##잌', '##즉', '##땍', '##겡', '##삳', '##땃', '##즙', '##텍', '##갇', '##쥘', '##욘', '##탯', '##す', '##セ', '##ッ', '##ク', '##ス', '##삿', '##ㄵ', '##줸', '##좡', '##빴', '##핥', '##깽', '##뉨', '##훔', '##졀', '##찟', '##탸', '##휼', '##촘', '##굯', '##쁀', '##댰', '##잴', '##컼', '##핶', '##샾', '##봔', '##긁', '##돵', '##쨔', '##맜', '##낔', '##좔', '##쩖', '##륺', '##햫', '##넖', '##쓹', '##뭄', '##퐁', '##삑', '##겤', '##햏', '##춌', '##옙', '##귤', '##♂', '##옄', '##퉷', '##삥', '##춸', '##삔', '##젅', '##붸', '##융', '##쉥', '##짂', '##웄', '##츳', '##꼰', '##갠', '##죨', '##톼', '##씸', '##뽜', '##ㅢ', '##뇰', '##꽄', '##팰', '##챈', '##펫', '##찹', '##쓱', '##ㅒ', '##랔', '##쨈', '##놕', '##봨', '##ら', '##け', '##＾', '##젹', '##묭', '##깠', '##썁', '##젇', '##꿰']\n"]}]},{"cell_type":"markdown","id":"83244f41","metadata":{"id":"83244f41"},"source":["### 1.2. 토크나이저를 이용한 토큰 ID 시퀀스 반환\n","\n","<blockquote>\n","<b>🧠 토크나이저를 이용한 토큰 ID 시퀀스 반환</b><br>\n","모델이 토큰을 이해하기 위해서는 정수값으로 반환하는 과정이 필요합니다. 토크나이저를 이용하여 텍스트 토큰을 ID 시퀀스로 변환합니다.\n","</blockquote>\n","\n","아래 코드를 실행하여 토크나이저를 이용하여 텍스트 토큰을 ID 시퀀스로 변환합니다."]},{"cell_type":"code","execution_count":11,"id":"a26d8b6b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a26d8b6b","executionInfo":{"status":"ok","timestamp":1760526351271,"user_tz":-540,"elapsed":10,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"6167e160-a0f5-4f63-fd31-c22c84f8df82"},"outputs":[{"output_type":"stream","name":"stdout","text":["🌱토큰화 결과 : ['I', \"'\", 'm', 'a', 'st', '##ud', '##ent', 'of', 'S', '##S', '##A', '##F', '##Y', '!']\n","🌱정수 인코딩 : [45, 11, 81, 69, 15444, 24835, 16071, 10280, 55, 3824, 4015, 3793, 3368, 5]\n","🌈디코딩 : I ' m a student of SSAFY!\n"]}],"source":["text = \"I'm a student of SSAFY!\"\n","\n","encoded = tokenizer.encode(text)\n","print('🌱토큰화 결과 :',encoded.tokens)\n","print('🌱정수 인코딩 :',encoded.ids)\n","print('🌈디코딩 :',tokenizer.decode(encoded.ids))"]},{"cell_type":"markdown","id":"884cec1b","metadata":{"id":"884cec1b"},"source":["<blockquote>\n","<b>🧠 토크나이저를 이용한 모델 입력 만들기</b><br>\n","그렇다면 모델의 입력으로 넣기 위해서는 어떤 방식으로 토크나이징을 해야 할까요?\n","</blockquote>\n","\n","위에 대한 답변은 앞으로 실습 코드를 진행하면서 나오기 때문에 이 점을 잊지 말고 계속 따라가시기 바랍니다."]},{"cell_type":"markdown","id":"7a906dbd","metadata":{"id":"7a906dbd"},"source":["### 1.3. 임베딩 벡터\n","\n","<blockquote>\n","<b>🧠 토큰 ID에 따라 어떤 방식으로 벡터화가 될까요?</b><br>\n","토큰 ID에 해당하는 임베딩 벡터를 확인해보겠습니다.\n","</blockquote>\n","\n","아래 코드를 실행하여 특정 토큰 ID에 따른 임베딩 벡터를 확인해보겠습니다.\n","\n","임베딩 벡터는 torch의 nn.Embedding 모듈을 사용하여 생성됩니다. 해당 임베딩 벡터는 모두 임의의 값으로 초기화됩니다."]},{"cell_type":"code","execution_count":null,"id":"db1e9b06","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"db1e9b06","executionInfo":{"status":"error","timestamp":1760495417240,"user_tz":-540,"elapsed":9,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"2adb2cb6-2e31-43ef-c4f8-4698c16477a2"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"Embedding.__init__() missing 2 required positional arguments: 'num_embeddings' and 'embedding_dim'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-166009310.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: Embedding.__init__() missing 2 required positional arguments: 'num_embeddings' and 'embedding_dim'"]}],"source":["embedding_vector = nn.Embedding()"]},{"cell_type":"markdown","id":"e7e6473c","metadata":{"id":"e7e6473c"},"source":["임베딩 벡터를 초기화하려고 하니 다음 두가지 파라미터를 반드시 넣으라고 합니다.\n","\n","1. `num_embeddings`: 임베딩 사전의 크기 (size of the dictionary of embeddings)\n","2. `embedding_dim`: 각 임베딩 벡터의 차원 (the size of each embedding vector)\n","\n","<blockquote>\n","<b>🧠 num_embeddings </b><br>\n","임베딩 사전의 크기는 무슨 의미일까요?\n","</blockquote>\n","\n","여기서 `num_embeddings`는 고유한 토큰(단어, 문자 등)의 총 개수를 의미합니다. 즉, 어떤 `인덱스 → 벡터` 매핑 테이블을 만들 건데, 그 테이블에 몇 개의 항목이 들어가야 하는지를 정의하는 값입니다. tokenizer를 만들때 `vocab_size`와 동일한 값을 의미합니다.\n","\n","<blockquote>\n","<b>🧠 embedding_dim </b><br>\n","각 임베딩 벡터의 차원은 무슨 의미일까요?\n","</blockquote>\n","\n","`embedding_dim`은 각 단어(또는 토큰)가 표현되는 벡터의 길이입니다. 즉, 하나의 단어를 어떤 숫자 벡터로 나타낼 때 그 벡터가 몇 차원인지 정하는 값입니다. 보통의 embedding은 `768`, `1024` 등 2의 제곱수 차원을 사용합니다. (\"어떤 값이 정답이다\" 하는 값이 있는 건 아닙니다.)\n","\n","여기서는 vocab_size와 embedding_dim을 768로 정의해보겠습니다."]},{"cell_type":"code","execution_count":12,"id":"d9723eee","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9723eee","executionInfo":{"status":"ok","timestamp":1760526375362,"user_tz":-540,"elapsed":249,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"efcbeeb7-1766-4959-cc94-6f359e52d00b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([30000, 768])"]},"metadata":{},"execution_count":12}],"source":["embedding_vector: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768) # 실제 타입은 Tensor2D가 아님. nn.Embedding의 내부 weight가 2D임을 의미적으로 표시한 것\n","embedding_vector.weight.shape"]},{"cell_type":"code","source":["type(embedding_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"uFCytgTjpPow","executionInfo":{"status":"ok","timestamp":1760526376220,"user_tz":-540,"elapsed":18,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"ae4c96f3-23ce-4859-8075-d7c8d857c3ac"},"id":"uFCytgTjpPow","execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.nn.modules.sparse.Embedding"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.sparse.Embedding</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py</a>A simple lookup table that stores embeddings of a fixed dictionary and size.\n","\n","This module is often used to store word embeddings and retrieve them using indices.\n","The input to the module is a list of indices, and the output is the corresponding\n","word embeddings.\n","\n","Args:\n","    num_embeddings (int): size of the dictionary of embeddings\n","    embedding_dim (int): the size of each embedding vector\n","    padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n","                                 therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n","                                 i.e. it remains as a fixed &quot;pad&quot;. For a newly constructed Embedding,\n","                                 the embedding vector at :attr:`padding_idx` will default to all zeros,\n","                                 but can be updated to another value to be used as the padding vector.\n","    max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n","                                is renormalized to have norm :attr:`max_norm`.\n","    norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n","    scale_grad_by_freq (bool, optional): If given, this will scale gradients by the inverse of frequency of\n","                                            the words in the mini-batch. Default ``False``.\n","    sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n","                             See Notes for more details regarding sparse gradients.\n","\n","Attributes:\n","    weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n","                     initialized from :math:`\\mathcal{N}(0, 1)`\n","\n","Shape:\n","    - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\n","    - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n","\n",".. note::\n","    Keep in mind that only a limited number of optimizers support\n","    sparse gradients: currently it&#x27;s :class:`optim.SGD` (`CUDA` and `CPU`),\n","    :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n","\n",".. note::\n","    When :attr:`max_norm` is not ``None``, :class:`Embedding`&#x27;s forward method will modify the\n","    :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\n","    modified in-place, performing a differentiable operation on ``Embedding.weight`` before\n","    calling :class:`Embedding`&#x27;s forward method requires cloning ``Embedding.weight`` when\n","    :attr:`max_norm` is not ``None``. For example::\n","\n","        n, d, m = 3, 5, 7\n","        embedding = nn.Embedding(n, d, max_norm=1.0)\n","        W = torch.randn((m, d), requires_grad=True)\n","        idx = torch.tensor([1, 2])\n","        a = (\n","            embedding.weight.clone() @ W.t()\n","        )  # weight must be cloned for this to be differentiable\n","        b = embedding(idx) @ W.t()  # modifies weight in-place\n","        out = a.unsqueeze(0) + b.unsqueeze(1)\n","        loss = out.sigmoid().prod()\n","        loss.backward()\n","\n","Examples::\n","\n","    &gt;&gt;&gt; # an Embedding module containing 10 tensors of size 3\n","    &gt;&gt;&gt; embedding = nn.Embedding(10, 3)\n","    &gt;&gt;&gt; # a batch of 2 samples of 4 indices each\n","    &gt;&gt;&gt; input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n","    &gt;&gt;&gt; # xdoctest: +IGNORE_WANT(&quot;non-deterministic&quot;)\n","    &gt;&gt;&gt; embedding(input)\n","    tensor([[[-0.0251, -1.6902,  0.7172],\n","             [-0.6431,  0.0748,  0.6969],\n","             [ 1.4970,  1.3448, -0.9685],\n","             [-0.3677, -2.7265, -0.1685]],\n","\n","            [[ 1.4970,  1.3448, -0.9685],\n","             [ 0.4362, -0.4004,  0.9400],\n","             [-0.6431,  0.0748,  0.6969],\n","             [ 0.9124, -2.3616,  1.1151]]])\n","\n","\n","    &gt;&gt;&gt; # example with padding_idx\n","    &gt;&gt;&gt; embedding = nn.Embedding(10, 3, padding_idx=0)\n","    &gt;&gt;&gt; input = torch.LongTensor([[0, 2, 0, 5]])\n","    &gt;&gt;&gt; embedding(input)\n","    tensor([[[ 0.0000,  0.0000,  0.0000],\n","             [ 0.1535, -2.0309,  0.9315],\n","             [ 0.0000,  0.0000,  0.0000],\n","             [-0.1655,  0.9897,  0.0635]]])\n","\n","    &gt;&gt;&gt; # example of changing `pad` vector\n","    &gt;&gt;&gt; padding_idx = 0\n","    &gt;&gt;&gt; embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n","    &gt;&gt;&gt; embedding.weight\n","    Parameter containing:\n","    tensor([[ 0.0000,  0.0000,  0.0000],\n","            [-0.7895, -0.7089, -0.0364],\n","            [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n","    &gt;&gt;&gt; with torch.no_grad():\n","    ...     embedding.weight[padding_idx] = torch.ones(3)\n","    &gt;&gt;&gt; embedding.weight\n","    Parameter containing:\n","    tensor([[ 1.0000,  1.0000,  1.0000],\n","            [-0.7895, -0.7089, -0.0364],\n","            [ 0.6778,  0.5803,  0.2678]], requires_grad=True)</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 15);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","id":"98a9214e","metadata":{"id":"98a9214e"},"source":["그러면 특정 토큰의 임베딩 벡터를 확인해보겠습니다."]},{"cell_type":"code","execution_count":14,"id":"8b4c3059","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8b4c3059","executionInfo":{"status":"ok","timestamp":1760526748853,"user_tz":-540,"elapsed":149,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"31383549-11db-4f97-d9c8-e4fc69963c4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["token_id: 45\n","input_id 차원: torch.Size([1])\n","vector 차원: torch.Size([1, 768])\n","vector: tensor([[-5.8641e-01, -1.1327e+00,  2.6612e-02, -3.6936e-01, -4.5574e-01,\n","          1.4395e+00, -2.7049e-01, -2.3921e-02,  4.3165e-01,  6.3602e-01,\n","         -4.0117e-01, -1.0804e+00, -6.4650e-01, -6.8504e-02,  2.4397e-01,\n","         -2.0591e-01, -1.8770e-01,  4.2026e-01,  7.1682e-01, -5.9828e-01,\n","          3.1360e-01,  1.8200e+00,  2.8490e+00,  1.3980e+00,  1.0531e+00,\n","          2.0170e+00,  6.0673e-01, -1.5876e+00,  1.1668e+00, -3.1769e-01,\n","         -5.3360e-01, -4.7004e-01, -9.2409e-01,  1.3773e+00, -1.3743e-01,\n","          4.2839e-02, -4.8446e-01, -9.6651e-01, -1.5018e+00, -4.8411e-01,\n","          1.3622e+00, -1.7072e+00, -7.3317e-01,  2.9438e-01, -1.0314e+00,\n","          1.7281e+00,  1.4170e+00,  1.2014e-01, -1.5709e+00, -3.1901e-01,\n","         -2.0575e-02,  6.4082e-02, -1.9547e-01, -4.9615e-01,  4.1448e-01,\n","         -2.1306e-01, -8.5294e-02,  5.7862e-01,  9.8439e-02,  7.3975e-01,\n","          2.4581e-02,  9.2886e-02, -3.3140e-01, -1.3073e-01,  1.6888e+00,\n","         -1.6246e-01,  3.6534e-01,  1.8052e+00, -5.4247e-01,  1.1382e+00,\n","         -1.1691e-02, -6.5054e-01, -2.9788e+00, -1.7490e+00, -5.2741e-01,\n","         -8.1005e-01,  3.9198e-01,  1.4487e-01,  4.4438e-01, -9.0061e-01,\n","          2.6250e-01, -2.9051e-01,  2.2310e-01, -1.2519e+00,  1.2721e+00,\n","          6.2651e-01,  1.5596e+00, -8.3331e-02, -4.1976e-01,  1.7190e+00,\n","         -8.3126e-01,  1.6253e+00, -2.3224e-01,  8.6379e-01,  6.8156e-01,\n","         -1.7146e+00, -1.4344e-01,  5.6220e-02, -1.8790e+00, -9.5746e-01,\n","          6.4773e-01,  1.7119e-01, -5.1799e-01, -2.9002e-01, -1.4499e+00,\n","         -2.2011e+00, -1.9358e+00,  1.7292e+00,  3.2779e-01,  9.1354e-01,\n","         -1.8337e-01, -1.0150e+00,  6.1067e-02, -1.6252e-01, -1.8904e-01,\n","         -3.1064e-01,  6.4264e-01,  2.4448e+00, -8.2296e-01,  2.3123e-01,\n","          5.2089e-01,  2.2307e-01,  8.9294e-01, -3.4659e-01, -2.2180e+00,\n","         -2.9681e-01,  1.9733e-01,  1.0184e+00, -5.8794e-01,  1.0451e+00,\n","          1.6000e+00,  1.0269e-01, -6.3995e-01,  2.5967e-01, -1.2352e-01,\n","          6.0335e-01, -1.0959e-01,  1.3712e+00,  2.6667e-01, -1.0211e+00,\n","          2.7895e-01, -1.2074e+00, -9.0694e-01,  8.2587e-01,  2.1134e-01,\n","          4.1955e-01, -2.6536e-01, -1.1998e+00,  5.6761e-01,  1.3631e+00,\n","         -1.1470e+00,  2.3841e-01, -1.0672e+00,  1.2854e+00, -2.5034e+00,\n","          1.0756e+00,  7.8051e-02, -1.1610e+00,  2.3808e+00,  5.8393e-03,\n","          1.2712e+00,  6.9454e-01, -2.0363e+00,  4.2008e-01,  1.4959e+00,\n","         -2.6621e+00, -1.1025e+00, -8.7692e-01,  2.7085e-01, -3.6835e-01,\n","         -4.5597e-01,  1.6099e-01,  2.2385e+00,  7.7596e-01,  6.9936e-01,\n","          1.2859e-02, -1.0188e+00,  2.0262e-01,  1.0505e-01, -5.3979e-01,\n","         -1.1471e+00,  1.0325e+00,  2.2522e-01,  1.7243e-01,  8.4644e-01,\n","         -3.9182e-01, -1.3194e+00,  1.9120e+00,  1.1990e+00, -7.1338e-01,\n","         -2.9062e-01, -1.9692e+00, -1.2352e+00,  3.4469e-01,  3.7266e-01,\n","          7.4043e-03,  1.7676e-01,  4.4155e-01, -2.8602e-01,  1.1501e+00,\n","         -4.9747e-01, -2.1877e+00,  1.2597e+00, -4.6811e-01, -1.9778e+00,\n","          9.2266e-02,  8.3967e-01, -1.2875e+00, -4.5443e-01,  8.2618e-01,\n","          1.3657e+00, -1.6183e-01,  2.7951e+00,  5.9410e-01, -8.6167e-01,\n","         -2.4812e+00,  5.2129e-01,  1.0565e+00,  8.2845e-01, -3.9922e-01,\n","          1.6755e+00,  2.2296e+00,  1.4605e+00, -1.3790e+00,  8.9979e-02,\n","         -8.4355e-01, -6.2137e-01,  8.8655e-01, -7.5264e-01,  4.5718e-02,\n","         -8.8061e-01, -1.3311e+00,  2.6024e+00, -8.8568e-02,  3.6131e-01,\n","         -9.6495e-01,  2.5996e-01, -4.8475e-01, -1.1931e+00, -3.5965e-03,\n","          4.5652e-01,  1.1003e+00,  6.0825e-01,  5.0255e-01,  6.4847e-02,\n","         -2.0972e-01, -8.1905e-01,  6.3713e-01,  5.5610e-01, -3.7969e-01,\n","         -8.2476e-01,  3.0568e-01,  1.3790e+00,  1.0315e+00, -1.1049e+00,\n","         -1.2539e+00,  7.8217e-01,  4.2802e-01,  5.2194e-01, -4.2326e-01,\n","          6.9081e-01, -1.1530e+00,  1.0535e+00,  8.4309e-01, -1.5127e+00,\n","          1.5953e+00,  1.5544e+00, -3.3269e-01,  1.8270e+00,  2.3450e-01,\n","         -2.6720e-01, -4.8002e-01, -7.2525e-01, -6.9044e-02,  1.8810e-02,\n","          1.4364e-01, -2.2373e+00,  4.0876e-01, -3.7807e-02, -8.5370e-01,\n","         -1.4437e+00, -1.5806e+00,  1.6538e+00,  6.1369e-01,  5.1194e-01,\n","         -1.4412e+00,  6.9254e-01,  1.6215e+00, -8.9781e-01, -2.6808e-01,\n","          6.8007e-01, -2.5736e+00,  3.0228e-01, -2.1020e-01,  4.0738e-01,\n","         -1.2795e+00, -2.1194e+00, -2.3627e-01,  6.4997e-01,  2.0307e-01,\n","         -4.0661e-01, -9.2588e-01, -6.6186e-01, -9.7114e-01, -1.2413e+00,\n","          1.6439e-01,  1.1636e+00,  3.6198e-01, -1.1532e+00, -1.0988e+00,\n","          5.3209e-01, -8.9032e-01,  1.1218e+00,  5.7064e-01,  7.5646e-01,\n","          1.3166e+00,  1.2176e+00, -5.0478e-01, -6.4268e-01,  2.3216e+00,\n","          1.1027e+00,  2.3127e-01,  4.6957e-01, -6.8633e-01, -1.4759e+00,\n","          1.4607e-01, -8.5485e-01,  5.1082e-01,  2.7225e-01, -1.0504e+00,\n","         -1.8880e+00,  8.0767e-01, -1.0015e+00, -2.9965e-01, -6.4340e-01,\n","         -1.1795e+00,  1.2514e+00, -1.1169e+00, -6.2890e-03, -2.4045e+00,\n","         -1.5852e-01,  7.9345e-01, -2.9591e-01,  8.2604e-01, -3.5559e-01,\n","          1.7587e-01,  1.5028e-01, -2.7314e-01,  3.9683e-02, -1.1727e+00,\n","         -1.7857e+00, -1.6997e+00,  9.1090e-01,  6.2496e-01,  7.2536e-02,\n","         -2.5993e-01, -7.4421e-01, -1.4108e+00,  1.1926e-01,  9.8203e-01,\n","          5.4706e-01,  1.0072e-01, -7.9624e-02,  7.1058e-02,  1.7737e-01,\n","          7.5613e-01, -1.2531e+00,  6.6835e-01, -1.0337e+00, -9.1633e-01,\n","          4.8913e-01, -4.7103e-01, -4.2296e-01, -8.8159e-01, -1.6258e+00,\n","          8.6559e-01,  8.9447e-01,  1.0847e+00,  2.9223e-01,  1.3801e+00,\n","          5.5510e-01,  2.3797e-01,  1.6000e-01, -2.7714e-01, -1.3358e+00,\n","         -1.5762e-01, -1.0363e+00,  9.8573e-01, -1.1911e+00,  2.4253e-01,\n","          5.4839e-01,  1.3786e+00,  1.5118e+00,  2.5880e-01,  1.1013e+00,\n","          1.4151e+00, -1.2057e-01,  1.3439e-01, -1.5628e+00, -6.1287e-01,\n","         -1.1348e+00, -9.6102e-01,  1.7011e+00,  5.0617e-01, -1.9768e+00,\n","         -5.6951e-01,  1.5390e+00,  6.3183e-02, -1.6705e+00,  1.4659e+00,\n","          1.1269e+00, -3.0730e+00, -1.1650e+00,  1.1070e+00,  2.4070e-01,\n","          2.7651e-01, -1.2080e+00,  4.8507e-01,  7.9149e-02,  5.4360e-01,\n","         -8.3520e-01,  9.3864e-01, -8.5778e-01,  3.6294e-01,  1.0618e+00,\n","          1.3808e-01, -3.9061e-02, -3.5348e-01,  2.1225e+00, -7.2674e-01,\n","         -1.7458e+00,  1.0003e+00,  2.8215e-02,  1.1499e+00,  4.2818e-01,\n","          1.5518e+00, -8.6611e-01,  1.4710e+00, -8.2705e-01,  9.8005e-02,\n","          2.6920e+00,  1.3048e+00,  6.0844e-01, -1.2385e+00,  4.6886e-01,\n","         -8.6682e-01,  1.0413e+00, -2.7178e-01,  1.4223e+00,  2.9257e+00,\n","          9.2931e-02,  5.7789e-01, -1.5264e+00,  3.8429e-01,  3.2746e-01,\n","         -1.1850e+00,  1.0487e+00, -1.0260e-01,  5.1305e-01, -4.3763e-01,\n","         -1.1442e+00,  1.6211e-01,  1.0189e-01, -8.6003e-01,  3.7350e-01,\n","         -2.0934e+00,  9.4786e-01,  8.0349e-01,  9.0876e-02, -7.2433e-01,\n","          8.9107e-01,  2.8971e-01,  1.4685e+00, -9.0758e-01,  1.0190e+00,\n","         -1.1583e+00, -1.5949e+00, -2.5171e-01,  2.0537e-01, -1.7279e+00,\n","          2.3990e-01, -2.2937e+00,  6.8148e-01,  1.5945e+00,  4.0917e-01,\n","         -7.5195e-01,  1.1046e-01, -1.5076e+00, -8.0238e-01,  2.2897e-01,\n","          6.2368e-01, -3.0776e-01, -1.5446e-01,  9.0203e-01,  2.1589e+00,\n","          1.4359e-02, -2.0427e-01,  4.5405e-01,  1.6242e+00,  2.4179e+00,\n","          1.9296e-02, -1.0937e+00, -4.3272e-01, -8.0123e-01,  1.6898e-01,\n","         -7.9126e-01, -3.3747e-01, -2.6263e-01,  6.3985e-01,  1.9795e+00,\n","          5.0256e-01,  4.2781e-01,  9.2407e-01, -1.1289e+00,  1.6008e+00,\n","          2.7487e-01,  2.4097e-01,  6.6713e-01, -5.3765e-01, -3.8973e-01,\n","          5.5697e-01,  5.1861e-02, -1.0619e+00, -1.9407e+00, -1.1581e+00,\n","          3.4482e-01, -7.0241e-01,  1.4376e+00, -1.1725e+00, -3.8754e-01,\n","          6.0148e-01, -4.2554e-01, -1.6213e-01,  6.2803e-02,  5.8063e-01,\n","         -3.4327e-01, -4.5692e-01,  9.6038e-01,  6.9764e-01,  1.0929e+00,\n","          1.7693e+00, -3.1421e-02, -1.0884e+00, -1.0127e-01, -1.9810e-01,\n","          4.4012e-02, -1.2764e+00, -1.0442e+00,  4.5751e-01,  3.7497e-01,\n","         -8.9870e-01, -8.6049e-03,  1.6212e+00,  2.1729e-01, -1.3368e+00,\n","         -4.6538e-04,  5.7354e-01, -1.4653e+00,  1.1711e+00,  2.9986e-01,\n","          2.3952e-01, -6.4066e-01,  3.2257e-01, -1.0702e+00, -4.5255e-01,\n","          8.4570e-01,  8.7082e-01, -1.2804e+00, -8.0807e-01, -1.0393e+00,\n","          1.8883e-01,  2.9374e-01,  1.8074e-02,  1.1724e+00, -5.2455e-01,\n","         -4.1127e-01,  6.3151e-01, -3.2293e-01,  1.1213e+00,  8.8539e-01,\n","         -7.4528e-01,  2.5474e+00,  4.3508e-01,  1.5564e-01, -2.8813e-01,\n","         -1.4950e+00,  1.9958e+00, -4.4929e-01,  5.7363e-01,  1.3688e+00,\n","          9.8464e-01, -1.5622e+00,  2.9645e-01,  7.9629e-02, -1.0188e+00,\n","         -2.8821e-01,  6.5786e-01, -9.4752e-01, -6.8457e-02,  5.4615e-01,\n","          3.1922e-01, -9.3858e-01,  2.0790e+00,  2.0641e-01,  1.3692e+00,\n","          3.6679e-01,  1.2206e-01,  3.4521e-01,  2.1476e-01,  9.4113e-01,\n","          9.7986e-01, -1.2927e+00, -4.6423e-01, -2.4949e-01,  1.5714e+00,\n","          6.6313e-01,  4.8623e-01,  7.1229e-02, -1.1668e-01,  1.0935e+00,\n","         -4.1720e-01,  1.2234e-01,  2.5845e-01, -5.0578e-01,  1.6090e+00,\n","          4.8093e-02,  2.7948e-01,  4.5103e-01, -5.2214e-01, -1.2607e+00,\n","         -5.7107e-01, -5.7751e-01,  6.6488e-01, -1.7756e+00,  6.5838e-01,\n","         -2.7618e-01, -1.5014e+00,  5.9242e-01,  1.7892e+00,  1.5430e+00,\n","          2.9727e-01,  1.8970e+00,  2.3541e-01,  7.3836e-01, -2.1829e-01,\n","         -5.6520e-01, -5.2170e-01, -2.8841e-01,  1.7133e+00,  1.3969e-01,\n","         -4.4374e-01, -1.5180e+00,  5.8020e-01, -1.4620e-01, -1.8151e+00,\n","          1.8509e+00, -5.7693e-01,  6.2626e-01, -7.9069e-01, -1.7662e+00,\n","         -7.7322e-01, -1.0780e-01,  8.9673e-01,  2.0367e+00,  6.2815e-01,\n","         -5.8681e-01, -1.0963e+00,  5.1416e-01, -1.6618e+00, -2.3677e-01,\n","          5.0208e-01, -3.8207e-01,  4.7563e-01, -7.4501e-01, -1.4155e-01,\n","         -2.1625e-01, -1.9711e+00, -1.2997e+00,  6.5497e-01, -2.1389e-01,\n","         -1.5022e-01, -4.7207e-01,  1.0380e+00,  1.0139e+00, -1.5492e+00,\n","         -9.2274e-01, -3.6818e-03, -1.9299e+00, -3.1747e-01,  4.3391e-01,\n","          6.2427e-01,  9.4415e-01, -1.2236e+00, -1.2878e-01,  3.8714e-01,\n","          9.4548e-01, -8.0918e-01, -2.0064e+00,  4.8596e-02, -9.9246e-01,\n","          4.3346e-01,  1.9962e-01, -1.0281e+00,  1.2949e+00, -9.7883e-01,\n","          7.2204e-01,  1.6217e-01,  1.1873e+00, -1.6302e+00, -1.6191e-01,\n","          7.4264e-01,  1.2234e-01,  5.3141e-02, -1.7858e+00,  9.8436e-02,\n","         -5.4184e-01,  4.1263e-01,  8.8509e-01, -3.8275e-01, -5.5372e-01,\n","         -1.0093e+00, -1.8745e+00, -3.1291e-02, -6.5305e-01,  9.3340e-01,\n","         -8.9972e-01,  1.0360e+00, -8.8613e-01, -3.8863e-01,  2.2449e-01,\n","         -1.0740e+00,  5.8647e-01, -8.3409e-01, -2.4781e+00, -1.6360e+00,\n","         -1.2667e+00,  1.0647e+00,  6.0862e-01,  1.0411e+00,  4.9001e-01,\n","         -5.6568e-01, -7.7290e-02,  1.6889e+00, -5.3592e-01,  3.0126e-01,\n","         -9.3709e-01, -1.0054e+00,  6.8849e-02,  6.9186e-01, -1.2959e+00,\n","          8.7209e-01,  2.7381e-01,  1.6178e+00,  3.3304e-01,  2.3623e+00,\n","          4.5610e-01, -7.9843e-02, -2.8436e-01, -1.5437e+00, -1.1984e+00,\n","         -7.8466e-01,  1.1022e+00,  1.5757e-01, -1.2095e+00,  2.2163e-01,\n","          6.4150e-01,  1.0414e+00,  8.6908e-01]], grad_fn=<EmbeddingBackward0>)\n"]}],"source":["token_id = tokenizer.token_to_id(\"I\")\n","print(\"token_id:\", token_id)\n","input_id = torch.tensor([token_id], dtype=torch.long)\n","print(\"input_id 차원:\", input_id.shape)\n","\n","vector = embedding_vector(input_id)\n","print(\"vector 차원:\", vector.shape)\n","print(\"vector:\", vector)"]},{"cell_type":"markdown","id":"7f47d8d6","metadata":{"id":"7f47d8d6"},"source":["# 2. RNN/LSTM\n","\n","- 학습 목표\n","  1. RNN/LSTM을 이용하여 문장 전체의 정보를 압축한 문맥 벡터에 대한 이해를 할 수 있다.\n","  2. Encoder Decoder 구조를 통해 문맥 벡터를 이용하여 특정 task를 수행할 수 있다.\n","- 학습 개념\n","  1. RNN/LSTM\n","  2. Encoder/Decoder\n","- 진행하는 실습 요약\n","  1. 간단한 RNN/LSTM을 구현한다.\n","  2. 번역 task와 관련된 encoder decoder 구조를 구현한다.\n"]},{"cell_type":"markdown","id":"d6cfb8ca","metadata":{"id":"d6cfb8ca"},"source":["<blockquote>\n","<b>🧠 Recurrent Neural Network(RNN)이란? </b><br>\n","순차적(Sequential) 이전의 정보를 기억하여 현재의 정보를 처리하는 신경망 구조를 의미합니다.\n","</blockquote>\n","\n","RNN이 갖는 특징은 다음과 같습니다.\n","\n","- 입력을 순차적으로 처리합니다.\n","- RNN은 같은 가중치를 반복적으로 사용합니다.\n","- 재귀적인 구조를 가집니다."]},{"cell_type":"markdown","id":"ec4dfc5c","metadata":{"id":"ec4dfc5c"},"source":["그러면 이제부터 입력 텍스트를 RNN에 입력으로 넣어서 출력층의 결과값을 받아봅시다!\n","\n","텍스트를 입력으로 넣기 위해서는 위에서 보았듯, 워드 임베딩으로 변환해야 합니다.\n","워드 임베딩을 만듭니다."]},{"cell_type":"code","execution_count":15,"id":"2b720ce0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b720ce0","executionInfo":{"status":"ok","timestamp":1760526850974,"user_tz":-540,"elapsed":344,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"f79d7ce4-f6ba-4f03-fb4c-49bdec7578bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["워드 임베딩 차원 : torch.Size([30000, 768])\n"]}],"source":["word_embeddings: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n","print(\"워드 임베딩 차원 :\", word_embeddings.weight.shape)"]},{"cell_type":"markdown","id":"6f9be639","metadata":{"id":"6f9be639"},"source":["워드 임베딩 차원에 맞게 RNN을 구현합니다."]},{"cell_type":"code","execution_count":16,"id":"d6cf6ed2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6cf6ed2","executionInfo":{"status":"ok","timestamp":1760526852646,"user_tz":-540,"elapsed":24,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"d2729503-7662-4f87-83dd-494b9549d45a"},"outputs":[{"output_type":"stream","name":"stdout","text":["h_0의 차원 : torch.Size([1, 1024])\n"]}],"source":["input_size: int = word_embeddings.weight.size()[1] # RNN의 input size는 임베딩 벡터의 차원과 일치해야 합니다.\n","hidden_size: int = 1024  # RNN의 hidden size\n","num_layers: int = 1  # 쌓을 RNN layer의 개수\n","bidirectional: bool = False  # 단방향 RNN -> 양방향 RNN도 존재함\n","\n","rnn = nn.RNN(\n","    input_size=input_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=bidirectional\n",")\n","\n","# 초기 hidden state 초기화\n","# RNN은 첫 입력을 받을 때 이전 hidden state(h_{t-1})가 없기 때문에\n","# 모든 값을 0으로 채운 초기 hidden state(h_0)를 만들어줍니다.\n","hidden_state_shape: int = (num_layers * (2 if bidirectional else 1), hidden_size)\n","\n","h_0: Tensor2D[Sequence, HiddenStates] = torch.zeros(hidden_state_shape)  # (num_layers * num_dirs, hidden_size)\n","print(\"h_0의 차원 :\",h_0.shape)"]},{"cell_type":"markdown","id":"cbb4f18e","metadata":{"id":"cbb4f18e"},"source":["입력 텍스트 데이터를 토크나이저를 사용하여 토큰화한 후, ids만 꺼냅니다."]},{"cell_type":"code","execution_count":17,"id":"bcf10c34","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcf10c34","executionInfo":{"status":"ok","timestamp":1760526897730,"user_tz":-540,"elapsed":9,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"64e83ae5-028d-4124-b4c6-a2191ebed366"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6227, 7125, 3321, 9046,   18])"]},"metadata":{},"execution_count":17}],"source":["text: str = \"나는 학교에 간다.\"\n","\n","# 토큰화를 진행합니다.\n","encoded = tokenizer.encode(text)\n","# 토큰의 ids만 꺼냅니다.\n","input_ids: List[int] = encoded.ids\n","\n","# 텐서화를 합니다.\n","input_ids: Tensor1D[Sequence] = torch.tensor(input_ids, dtype=torch.long)\n","input_ids"]},{"cell_type":"markdown","id":"13935ca0","metadata":{"id":"13935ca0"},"source":["변환된 input_ids를 워드 임베딩으로 넣고\n","워드 임베딩을 RNN의 입력으로 넣어 두 output을 얻습니다.\n","\n","1. `hidden_states`: 각 time step에 해당하는 hidden state들의 묶음.\n","2. `h_n`: 모든 sequence를 거치고 나온 마지막 hidden state(`last hidden state`). hidden_states의 마지막과 동일."]},{"cell_type":"code","execution_count":18,"id":"97d65561","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97d65561","executionInfo":{"status":"ok","timestamp":1760526960447,"user_tz":-540,"elapsed":95,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"39aa2087-3cf6-4981-cfde-630f55150c10"},"outputs":[{"output_type":"stream","name":"stdout","text":["워드 임베딩 차원 :  torch.Size([5, 768])\n","(tensor([[ 0.6084, -0.0489,  0.0071,  ...,  0.1492, -0.1975,  0.7012],\n","        [ 0.6386, -0.3881,  0.5423,  ...,  0.4250,  0.2783, -0.8625],\n","        [ 0.5214, -0.3231, -0.1121,  ...,  0.7427, -0.6443, -0.3942],\n","        [ 0.5815,  0.1487,  0.3087,  ..., -0.9138,  0.3690,  0.1909],\n","        [ 0.1274,  0.3584,  0.6517,  ..., -0.8670, -0.5661, -0.2296]],\n","       grad_fn=<SqueezeBackward1>), tensor([[ 0.1274,  0.3584,  0.6517,  ..., -0.8670, -0.5661, -0.2296]],\n","       grad_fn=<SqueezeBackward1>))\n","2\n","hidden_states 차원 :  torch.Size([5, 1024])\n","hidden_states[-1]의 차원 :  torch.Size([1024])\n","h_n 차원 :  torch.Size([1, 1024])\n","hidden_states의 마지막과 h_n이 같습니다.\n"]}],"source":["input_embeds: Tensor2D[Sequence, EmbeddingSize] = word_embeddings(input_ids)\n","print(\"워드 임베딩 차원 : \", input_embeds.shape)  # (vocab_size, embedding_dim)\n","outputs = rnn(input_embeds, h_0)\n","print(outputs)\n","print(len(outputs))\n","hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0] # 전체 시퀀스의 hidden state 출력\n","h_n: Tensor2D[Layers, HiddenStates] = outputs[1] # 마지막 시점의 hidden state\n","\n","# sequence_length: input_token의 길이(length), hidden size: hidden state 차원 수, num_layers: layer 개수, num_dirs: 방향의 개수\n","print(\"hidden_states 차원 : \", hidden_states.shape)  # (sequence_length, d_h)\n","print('hidden_states[-1]의 차원 : ', hidden_states[-1].shape)\n","print(\"h_n 차원 : \", h_n.shape)  # (num_layers * num_dirs, d_h) = (1, d_h)\n","\n","if torch.equal(hidden_states[-1].unsqueeze(0), h_n): # → 차원을 하나 추가해서 shape이 같아지게 하기 위한 unsqueeze\n","    print(\"hidden_states의 마지막과 h_n이 같습니다.\")"]},{"cell_type":"markdown","id":"7ecc103e","metadata":{"id":"7ecc103e"},"source":["그러면 이러한 은닉 상태(hidden state)를 얻어서 어떠한 작업을 할 수 있을까요?\n","\n","<blockquote>\n","<b>🧠 은닉 상태(hidden state)는 문장의 정보들을 압축적으로 저장합니다.</b><br>\n","RNN layer를 통과하면서 문장 전체의 정보를 압축하게 되고 이러한 정보들은 hidden state에 담기게 됩니다.\n","이러한 hidden state는 문맥 벡터(context vector)로 사용됩니다.\n","</blockquote>\n","\n","문맥 벡터(context vector)는 입력 문장의 정보들을 벡터상에 압축하여 저장한 것으로, 이를 통해 다양한 task를 수행할 수 있게 됩니다.\n","\n","여기서는 번역(translation) task를 수행하기 위해 hidden state를 사용하겠습니다.\n","\n","번역을 하기 위해서는 last hidden state를 다시 저희의 입력 데이터와 유사한 형태인 텍스트(토큰) id로 변환하는 layer가 필요합니다. 이를 저희는 Decoder라고 부릅니다.\n","\n","![image](https://raw.githubusercontent.com/Ssunbell/TIL/refs/heads/master/assets/Seq2SeqRNN.png)\n","\n","그러면 아래에서 Encoder와 Decoder를 연결하여 번역을 수행하는 모델을 구현하겠습니다.\n","\n","먼저 인코더를 구현하겠습니다. 위에서 구현한 rnn을 그대로 이용하여 클래스화를 진행하는 것과 동일합니다."]},{"cell_type":"code","execution_count":19,"id":"f35ff084","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f35ff084","executionInfo":{"status":"ok","timestamp":1760527632219,"user_tz":-540,"elapsed":239,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"25b4be57-3f5b-454f-f913-5f83833a3da2"},"outputs":[{"output_type":"stream","name":"stdout","text":["hidden_states 차원 :  torch.Size([5, 1024])\n","h_n 차원 :  torch.Size([1, 1024])\n"]}],"source":["from abc import ABC, abstractmethod\n","\n","# 인코더 모델은 RNN을 사용합니다. 아래는 추상화 클래스입니다.\n","class Encoder(nn.Module, ABC): # nn.Module과 ABC(추상 클래스) 상속\n","    def __init__(self: \"Encoder\") -> None:\n","        super().__init__()\n","        pass\n","\n","    @abstractmethod\n","    def forward(self: \"Encoder\", input_ids: torch.Tensor) -> torch.Tensor:\n","        # forward에서 실제로 인코딩을 수행하기 위한 레이어를 쌓습니다. (forward를 반드시 구현하도록 강제)\n","        pass\n","\n","class RNNEncoder(Encoder):\n","    def __init__(\n","        self: \"RNNEncoder\",\n","        vocab_size: int,\n","        embedding_dim: int,\n","        hidden_size: int,\n","        num_layers: int,\n","        bidirectional: bool,\n","    ) -> None:\n","        super().__init__()\n","        # word embedding layer\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)  # 단어 임베딩 층\n","        self.rnn = nn.RNN(                                            # RNN 층 정의\n","            input_size=embedding_dim,                                 # 입력 차원\n","            hidden_size=hidden_size,                                  # hidden 차원\n","            num_layers=num_layers,                                    # layer 개수\n","            bidirectional=bidirectional                               # 양방향 여부\n","        )\n","\n","    def forward(\n","        self: \"RNNEncoder\",\n","        input_ids: Tensor1D[Sequence]\n","    ) -> Tuple[Tensor2D[Sequence, HiddenStates], Tensor2D[Layers, HiddenStates]]:\n","        \"\"\"입력 토큰을 워드 임베딩을 통해 임베딩 변환을 합니다.\"\"\"\n","        input_embeds = self.word_embeddings(input_ids)\n","\n","        \"\"\"RNN을 통해 입력 임베딩을 문맥 벡터(context vector)화 합니다.\"\"\"\n","        outputs = self.rnn(input_embeds)\n","        # TODO: 직접 구현해보세요!\n","        hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0] # 모든 시점의 hidden state\n","        h_n: Tensor2D[Layers, HiddenStates] = outputs[1] # 마지막 hidden state\n","\n","        return hidden_states, h_n\n","\n","vocab_size = 30000\n","embedding_dim = 768\n","hidden_size = 1024  # RNN의 hidden size\n","num_layers = 1  # 쌓을 RNN layer의 개수\n","bidirectional = False  # 단방향 RNN\n","\n","rnn_encoder = RNNEncoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=bidirectional\n",")\n","\n","outputs = rnn_encoder(input_ids)\n","hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n","h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n","\n","# L: sequence_length\n","# B: batch_size\n","# d_h: hidden_size\n","# - hidden_states: (L, d_h)\n","# - h_n: (num_layers * num_dirs, d_h)\n","print(\"hidden_states 차원 : \", hidden_states.shape)  # (L, d_h)\n","print(\"h_n 차원 : \", h_n.shape)  # (num_layers*num_dirs, d_h) = (1, d_h) # num_dirs는 단방향(1)인가 양방향(2)인가\n"]},{"cell_type":"markdown","id":"61b15bc9","metadata":{"id":"61b15bc9"},"source":["다음 디코더 부분을 구현하겠습니다."]},{"cell_type":"code","execution_count":24,"id":"a5a3b846","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5a3b846","executionInfo":{"status":"ok","timestamp":1760527781352,"user_tz":-540,"elapsed":2549,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"606f0608-6274-4c14-d48d-19b80ca79144"},"outputs":[{"output_type":"stream","name":"stdout","text":["##チ아서기나쮸 뚜 남기고 끝났다 기대할게요 늴 언제적\n","10\n"]}],"source":["# 디코더 모델 또한 RNN을 사용합니다.\n","class Decoder(nn.Module, ABC):\n","    def __init__(self: \"Decoder\") -> None:\n","        super().__init__()\n","\n","    @abstractmethod\n","    def forward(self, input_ids: torch.Tensor, init_hidden_state: torch.Tensor) -> torch.Tensor:\n","        pass\n","\n","class RNNDecoder(Decoder):\n","    def __init__(\n","        self: \"RNNDecoder\",\n","        vocab_size: int,\n","        embedding_dim: int,\n","        hidden_size: int,\n","        num_layers: int,\n","        bidirectional: bool,\n","        start_token_id: int,\n","        end_token_id: int,\n","    ) -> None:\n","        super().__init__()\n","        self.start_token_id = start_token_id\n","        self.end_token_id = end_token_id\n","        # word embedding layer\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        # rnn layer\n","        self.rnn = nn.RNN(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            bidirectional=bidirectional,\n","        )\n","        # fully connected layer\n","        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(\n","        self: \"RNNDecoder\",\n","        init_hidden_state: Tensor2D[Layers, HiddenStates],\n","        max_len: int = 10\n","    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n","        logits: List[Tensor1D[VocabSize]] = []\n","        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n","        output_token_ids: List[int] = [input_token.item()] # tensor에서 item()을 사용하여 int로 변환합니다.\n","        h_n = init_hidden_state # h_n은 encoder의 h_0와 동일한 역할을 합니다.\n","\n","        for _ in range(max_len):\n","            if input_token == self.end_token_id:\n","                # 문장의 종료를 의미하는 special token([SEP])이 나왔다면 추론(생성)을 종료합니다.\n","                break\n","\n","            \"\"\"직전 토큰만 입력으로 넣고 생성한 context vector는 logits에 저장합니다.\"\"\"\n","            # TODO: 직접 구현해보세요!\n","            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # 직전 입력 토큰만 사용 [1, embedding_dim]\n","            outputs = self.rnn(embedded, h_n)\n","            h_n: Tensor2D[Layers, HiddenStates] = outputs[1] # [1, hidden_size]\n","            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # 스칼라값을 1차원 벡터로 변환\n","            # 여기서는 layer 갯수가 1이고, bidirectional이 False이므로 squeeze를 사용해도 무방합니다. (원래는 torch.cat으로 h_n을 합치는 작업이 필요합니다.)\n","\n","            \"\"\"fully connected layer를 통해 [VocabSize]의 logit을 생성합니다.\"\"\"\n","            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n","            logits.append(logit)\n","\n","            \"\"\"logit 내에서 가장 높은 점수값을 가진 토큰을 선택합니다.\"\"\"\n","            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0) # 스칼라값을 1차원 벡터로 변환\n","            output_token_ids.append(input_token.item())\n","\n","        \"\"\"리스트의 logits를 torch의 Tensor로 변경합니다.\"\"\"\n","        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n","\n","        return logits, output_token_ids\n","\n","start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n","end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n","\n","vocab_size: int = 30000\n","embedding_dim: int = 768\n","hidden_size: int = 1024  # RNN의 hidden size\n","num_layers: int = 1  # 쌓을 RNN layer의 개수\n","bidirectional: bool = False  # 단방향 RNN\n","\n","rnn_decoder = RNNDecoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=bidirectional,\n","    start_token_id=start_token_id,\n","    end_token_id=end_token_id,\n",")\n","logits, output_token_ids = rnn_decoder(h_n)\n","output_texts = tokenizer.decode(output_token_ids)\n","print(output_texts)\n"]},{"cell_type":"code","source":["logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nxysc0Hfohoj","executionInfo":{"status":"ok","timestamp":1760527795517,"user_tz":-540,"elapsed":23,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"89b46b3c-ec47-4cb6-82f5-87e8ba3dc874"},"id":"Nxysc0Hfohoj","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["10\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 30000])"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","id":"2a43d683","metadata":{"id":"2a43d683"},"source":["이제 구현한 encoder와 decoder를 연결하여 seq2seq 모델을 구현해보겠습니다."]},{"cell_type":"code","execution_count":21,"id":"55b85dfe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55b85dfe","executionInfo":{"status":"ok","timestamp":1760527636185,"user_tz":-540,"elapsed":165,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"d73a3419-fda7-4f1e-d80a-46f85d6c5b40"},"outputs":[{"output_type":"stream","name":"stdout","text":["합더블랑스터하균 감동받았다 나서도 짯 아파 대사들\n"]}],"source":["class RNNSeq2Seq(nn.Module):\n","    def __init__(self: \"RNNSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self: \"RNNSeq2Seq\", input_ids: Tensor1D[Sequence]):\n","        hidden_states, context_vector = self.encoder(input_ids) # encoder에서 생성한 context_vector(h_n)을 decoder layer로 전달\n","        logits, output_tokens = self.decoder(context_vector)\n","\n","        return logits, output_tokens\n","\n","seq2seq = RNNSeq2Seq(rnn_encoder, rnn_decoder)\n","logits, output_tokens = seq2seq(input_ids)\n","output_token_ids = logits.argmax(dim=-1)\n","output_texts = tokenizer.decode(output_token_ids.tolist())\n","print(output_texts)"]},{"cell_type":"markdown","id":"36e7487e","metadata":{"id":"36e7487e"},"source":["<blockquote>\n","<b>🤔 결과값이 이상해요</b><br>\n","데이터로 충분히 학습을 하지 않아서 그렇습니다. 여기서는 모델의 구조에 대해서 집중하고 추후에 모델을 학습하는 과정을 경험해보겠습니다.\n","</blockquote>\n","\n","저희는 Sequence to Sequence(Encoder - Decoder) 구조를 이용하여 텍스트를 생성해보았습니다.\n","\n","Seq2Seq 구조 내에서 실제 워드 임베딩을 컨텍스트 벡터로 변환하고, 그 변환된 컨텍스트 벡터를 텍스트(토큰)으로 변환하는 과정에서 쓰인 모델은 RNN이였습니다.\n","\n","RNN뿐만 아니라 LSTM, 어텐션 등을 사용하여 Seq2Seq 구조를 구현할 수 있습니다.\n","\n","전체적인 큰 틀은 그대로 유지한 채, RNN 모듈만 바꿔주기만 하면 됩니다.\n","\n","그러면 이제부터 LSTM으로 다시 한번 구현해보겠습니다."]},{"cell_type":"markdown","id":"8758c710","metadata":{"id":"8758c710"},"source":["RNN과 LSTM의 가장 큰 차이점은 LSTM에는 cell state가 추가된다는 점입니다.\n","\n","장기 기억을 담당하는 cell state를 통해 좀더 성능을 높일 수 있습니다.\n","\n","<blockquote>\n","<b>🧠 Key point!</b><br>\n","모델의 아키텍쳐마다 모델의 입출력이 달라집니다. 모델의 입력과 출력이 어떻게 나오는지에 대해서 이해하는 것이 중요합니다.\n","</blockquote>\n","\n","그러면 Encoder에서 LSTM을 적용해보겠습니다."]},{"cell_type":"code","execution_count":22,"id":"bf861480","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bf861480","executionInfo":{"status":"ok","timestamp":1760527638475,"user_tz":-540,"elapsed":512,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"9cbeb503-3899-4d02-f447-c52d35b98eb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["hidden_states 차원 :  torch.Size([5, 1024])\n","h_n 차원 :  torch.Size([1, 1024])\n","c_n 차원 :  torch.Size([1, 1024])\n"]}],"source":["class LSTMEncoder(Encoder):\n","    def __init__(\n","        self,\n","        vocab_size: int,\n","        embedding_dim: int,\n","        hidden_size: int,\n","        num_layers: int,\n","        bidirectional: bool,\n","    ) -> None:\n","        super().__init__()\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            bidirectional=bidirectional,\n","        )\n","\n","    def forward(\n","        self: \"LSTMEncoder\",\n","        input_ids: Tensor1D[Sequence]\n","    )-> Tuple[\n","        Tensor2D[Sequence, HiddenStates], # hidden states\n","        Tuple[\n","            Tensor2D[Layers, HiddenStates], # h_n\n","            Tensor2D[Layers, HiddenStates] # c_n\n","        ]\n","    ]:\n","        # Embed -> same leading dims + embedding_dim\n","        input_embeds = self.word_embeddings(input_ids)  # [S,B,E] or [B,S,E]\n","        outputs = self.lstm(input_embeds)   # outputs: [S,B,D*H] or [B,S,D*H]\n","        # TODO: 직접 구현해보세요!\n","        hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n","        h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n","        c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n","\n","        return hidden_states, (h_n, c_n)\n","\n","vocab_size = 30000\n","embedding_dim = 768\n","hidden_size = 1024  # RNN의 hidden size\n","num_layers = 1  # 쌓을 RNN layer의 개수\n","bidirectional = False  # 단방향 RNN\n","\n","lstm_encoder = LSTMEncoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=bidirectional\n",")\n","\n","outputs = lstm_encoder(input_ids)\n","hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n","h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n","c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n","print(\"hidden_states 차원 : \", hidden_states.shape)  # (L, B, d_h)\n","print(\"h_n 차원 : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n","print(\"c_n 차원 : \", c_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n","\n"]},{"cell_type":"markdown","id":"40d7ab4d","metadata":{"id":"40d7ab4d"},"source":["이번에는 LSTM을 사용하여 Decoder Layer를 구현해보겠습니다."]},{"cell_type":"code","execution_count":null,"id":"77ba9e94","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77ba9e94","executionInfo":{"status":"ok","timestamp":1760271674658,"user_tz":-540,"elapsed":852,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"bbddc776-dafe-480c-f7f2-5c2d48806ae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["##것같아요 21세기별이 두근두근 오덕볼까 고맙하더라 많은걸했다가\n"]}],"source":["class LSTMDecoder(Decoder):\n","    def __init__(\n","        self: \"LSTMDecoder\",\n","        vocab_size: int,\n","        embedding_dim: int,\n","        hidden_size: int,\n","        num_layers: int,\n","        bidirectional: bool,\n","        start_token_id: int,\n","        end_token_id: int,\n","    ) -> None:\n","        super().__init__()\n","        self.start_token_id = start_token_id\n","        self.end_token_id = end_token_id\n","        # word embedding layer\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        # rnn layer\n","        self.lstm = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            bidirectional=bidirectional,\n","        )\n","        # fully connected layer\n","        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(\n","        self: \"LSTMDecoder\",\n","        init_hidden_state: Tensor2D[Layers, HiddenStates],\n","        init_cell_state: Tensor2D[Layers, HiddenStates],\n","        max_len: int = 10\n","    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n","        logits: List[Tensor1D[VocabSize]] = []\n","        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n","        output_token_ids: List[int] = [input_token.item()] # tensor에서 item()을 사용하여 int로 변환합니다.\n","        h_n = init_hidden_state # h_n은 encoder의 h_0와 동일한 역할을 합니다.\n","        c_n = init_cell_state\n","\n","        for _ in range(max_len):\n","            if input_token == self.end_token_id:\n","                # 문장의 종료를 의미하는 special token([SEP])이 나왔다면 추론(생성)을 종료합니다.\n","                break\n","\n","            \"\"\"직전 토큰만 입력으로 넣고 생성한 context vector는 logits에 저장합니다.\"\"\"\n","            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # 직전 입력 토큰만 사용 [1, embedding_dim]\n","            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [Sequence Length,Batch,Direction*Hidden_size] or [B,S,D*H]\n","            # outputs = (\n","            #     output_seq,    # 모든 시점의 hidden states\n","            #     (h_n, c_n)     # 마지막 시점의 hidden state와 cell state\n","            # )\n","            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n","            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n","\n","            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # 여기서는 layer 갯수가 1이고, bidirectional이 False이므로 squeeze를 사용해도 무방합니다. (원래는 torch.cat으로 h_n을 합치는 작업이 필요합니다.)\n","\n","            \"\"\"fully connected layer를 통해 [VocabSize]의 logit을 생성합니다.\"\"\"\n","            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n","            logits.append(logit)\n","\n","            \"\"\"가장 높은 점수값을 가진 토큰을 선택합니다.\"\"\"\n","            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n","            output_token_ids.append(input_token.item())\n","\n","        \"\"\"리스트의 logits를 torch의 Tensor로 변경합니다.\"\"\"\n","        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n","\n","        return logits, output_token_ids\n","\n","\n","start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n","end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n","\n","vocab_size: int = 30000\n","embedding_dim: int = 768\n","hidden_size: int = 1024 # RNN의 hidden size\n","num_layers: int = 1 # 쌓을 RNN layer의 개수\n","bidirectional: bool = False # 단방향 RNN\n","\n","lstm_decoder = LSTMDecoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=bidirectional,\n","    start_token_id=start_token_id,\n","    end_token_id=end_token_id,\n",")\n","\n","logits, output_tokens = lstm_decoder(h_n, c_n)\n","output_token_ids = logits.argmax(dim=-1)\n","output_texts = tokenizer.decode(output_token_ids.tolist())\n","print(output_texts)"]},{"cell_type":"markdown","id":"8c8db0e2","metadata":{"id":"8c8db0e2"},"source":["Encoder와 Decoder를 사용하여 Seq2Seq 모델을 구현해보겠습니다."]},{"cell_type":"code","execution_count":null,"id":"fddfe053","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fddfe053","executionInfo":{"status":"ok","timestamp":1760271675606,"user_tz":-540,"elapsed":324,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"fd15a3ea-6332-489a-c672-bceff4dc742c"},"outputs":[{"output_type":"stream","name":"stdout","text":["##것같아요 21세기별이 두근두근 오덕볼까 고맙하더라 많은걸했다가\n"]}],"source":["class LSTMSeq2Seq(nn.Module):\n","    def __init__(self: \"LSTMSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self: \"LSTMSeq2Seq\", input_ids: Tensor1D[Sequence]):\n","        hidden_states, (context_vector, cell_states) = self.encoder(input_ids) # encoder에서 생성한 context_vector(h_n)을 decoder layer로 전달\n","        logits, output_tokens = self.decoder(context_vector, cell_states)\n","\n","        return logits, output_tokens\n","\n","seq2seq = LSTMSeq2Seq(lstm_encoder, lstm_decoder)\n","logits, output_tokens = seq2seq(input_ids)\n","output_token_ids = logits.argmax(dim=-1)\n","output_texts = tokenizer.decode(output_token_ids.tolist())\n","print(output_texts)"]},{"cell_type":"markdown","id":"0391cd8a","metadata":{"id":"0391cd8a"},"source":["# 3. Attention Mechanism\n","\n","- 학습 목표\n","  1. Luong Attention(Dot Attention)을 구현할 수 있다.\n","  2. Attention을 이용하여 Decoder를 구현할 수 있다.\n","- 학습 개념\n","  1. Luong Attention: 복잡한 네트워크 말고, 선형 변환과 내적만으로 충분하다고 주장한 attention 형태\n","- 진행하는 실습 요약\n","  1. Luong Attention을 구현한다.\n","  2. Seq2Seq 구조에 들어갈 Decoder를 구현한다.\n","\n","\n","이번에는 Attention을 사용한 seq2seq 모델을 구현해보겠습니다.\n","\n","<blockquote>\n","<b>🧠 Attention Mechanism</b><br>\n","현재 구현할 seq2seq 모델에서의 Attention은 최근 사용하는 attention은 아닙니다. 최근의 Transformers 모델들은 Multi-Head Scaled Dot-Product Attention을 사용합니다. 해당 내용은 과제에서 다룰 예정입니다.\n","</blockquote>\n","\n","1. 전체적인 Seq2Seq 모델의 구조는 동일합니다.\n","2. Encoder에서 context vector를 얻을 때, LSTM을 사용하는 Encoder 모듈을 그대로 사용합니다.\n","3. Decoder에서 output token을 생성할 때, attention mechanism을 추가합니다."]},{"cell_type":"markdown","id":"ad3807ee","metadata":{"id":"ad3807ee"},"source":["그러면 우선 Dot Attention(Luong attention)을 먼저 구현합니다."]},{"cell_type":"code","execution_count":null,"id":"70059257","metadata":{"id":"70059257"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class LuongAttention(nn.Module):\n","    def __init__(self: \"LuongAttention\", hidden_size: int):\n","        super().__init__()\n","        self.W_a = nn.Linear(hidden_size, hidden_size, bias=False)\n","\n","    @torch.no_grad()  # 학습 시 제거하세요\n","    def forward(\n","        self:\"LuongAttention\",\n","        h_t: Tensor1D[HiddenStates],\n","        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n","    ) -> Tuple[Tensor1D[HiddenStates], Tensor1D[Sequence]]:\n","        # h_t를 W_a로 변환 → Wa_ht\n","        # encoder_outputs와 Wa_ht 간 내적 → attention score (유사도)\n","        # softmax → attention weights (확률 분포)\n","        # attention weights와 encoder_outputs의 가중합 → context vector\n","\n","        \"\"\"hidden state를 W_a에 projection하여 Wa_ht를 구합니다.\"\"\"\n","        # 내적을 통해 의미 있는 유사도를 계산할 수 있도록 하기 위한 선형변환\n","        Wa_ht: Tensor1D[HiddenStates] = self.W_a(h_t)\n","\n","        \"\"\"encoder_outputs와 Wa_ht를 내적하여 attention score를 구합니다.\"\"\"\n","        # TODO: 직접 구현해보세요!\n","        attention_score: Tensor1D[Sequence] = encoder_outputs @ Wa_ht\n","\n","        \"\"\"attention score를 softmax layer에 통과시켜 attention weights(attention distribution)을 구합니다.\"\"\"\n","        # TODO: 직접 구현해보세요!\n","        attention_weights: Tensor1D[Sequence] = F.softmax(attention_score, dim=-1)\n","\n","        \"\"\"각 encoder의 attention weights와 encoder의 hidden state를 내적하여 context vector(attention value)를 구합니다.\"\"\"\n","        # TODO: 직접 구현해보세요!\n","        context_vector: Tensor1D[HiddenStates] = attention_weights @ encoder_outputs\n","\n","        return context_vector, attention_weights\n"]},{"cell_type":"markdown","id":"df83103d","metadata":{"id":"df83103d"},"source":["<blockquote>\n","<b>🤔 엇 여기서도 context vector가 나오네요?</b><br>\n","네 그렇습니다. 과거에는 encoder의 마지막 hidden state(h_n)을 context vector라고 불렀습니다. 하지만, attention이 나오면서 context vector는 각 디코딩 시점마다 인코더의 모든 hidden states에 대한 어텐션 가중합이라고 생각해주시면 됩니다.\n","</blockquote>\n","\n","구현한 attention mechanism을 이용하여 Decoder layer에 적용합니다."]},{"cell_type":"code","execution_count":null,"id":"e2abb3bc","metadata":{"id":"e2abb3bc"},"outputs":[],"source":["class AttentionDecoder(nn.Module):\n","    def __init__(\n","        self: \"AttentionDecoder\",\n","        vocab_size: int,\n","        embedding_dim: int,\n","        hidden_size: int,\n","        num_layers: int,\n","        bidirectional: bool,\n","        start_token_id: int,\n","        end_token_id: int,\n","    ):\n","        super().__init__()\n","        self.start_token_id = start_token_id\n","        self.end_token_id = end_token_id\n","        # word embedding layer\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        # rnn layer\n","        self.lstm = nn.LSTM(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            bidirectional=bidirectional,\n","        )\n","\n","        \"\"\"attention을 추가합니다.\"\"\"\n","        self.attn = LuongAttention(hidden_size)\n","        \"\"\"context vector을 입력으로 받는 trainable weights\"\"\"\n","        self.W_c = nn.Linear(hidden_size * 2, hidden_size)\n","        # fully connected layer\n","        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n","\n","    @torch.no_grad()  # 학습 시 제거\n","    def forward(\n","        self:\"AttentionDecoder\",\n","        init_hidden_state: Tensor1D[HiddenStates],\n","        init_cell_state: Tensor1D[HiddenStates],\n","        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n","        max_len: int = 10,\n","    ):\n","        logits: List[Tensor1D[VocabSize]] = []\n","        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n","        output_token_ids: List[int] = [input_token.item()] # tensor에서 item()을 사용하여 int로 변환합니다.\n","        h_n = init_hidden_state # h_n은 encoder의 h_0와 동일한 역할을 합니다.\n","        c_n = init_cell_state\n","\n","        for _ in range(max_len):\n","            if input_token == self.end_token_id:\n","                # 문장의 종료를 의미하는 special token([SEP])이 나왔다면 추론(생성)을 종료합니다.\n","                break\n","\n","            \"\"\"직전 토큰만 입력으로 넣고 생성한 context vector는 logits에 저장합니다.\"\"\"\n","            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # 직전 입력 토큰만 사용 [1, embedding_dim]\n","            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n","            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n","            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n","\n","            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # 여기서는 layer 갯수가 1이고, bidirectional이 False이므로 squeeze를 사용해도 무방합니다. (원래는 torch.cat으로 h_n을 합치는 작업이 필요합니다.)\n","\n","            # 어텐션\n","            context_vector, attention_weights = self.attn(concat_h_n, encoder_outputs)\n","\n","            \"\"\"h_n(은닉 상태)와 context_vector를 연결합니다. (Concatenate)\"\"\"\n","            v_t: Tensor1D[HiddenStates * 2] = torch.cat([concat_h_n, context_vector], dim=-1)\n","\n","            \"\"\"v_t를 trainable weights를 통과시키고 tanh를 적용합니다.\"\"\"\n","            # TODO: 직접 구현해보세요!\n","            attentional_hidden_state: Tensor1D[HiddenStates] = torch.tanh(self.W_c(v_t))\n","\n","            \"\"\"fully connected layer를 통해 [VocabSize]의 logit을 생성합니다.\"\"\"\n","            logit: Tensor1D[VocabSize] = self.fully_connected_layer(attentional_hidden_state)\n","            logits.append(logit)\n","\n","            \"\"\"가장 높은 점수값을 가진 토큰을 선택합니다.\"\"\"\n","            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n","            output_token_ids.append(input_token.item())\n","\n","        logits = torch.stack(logits, dim=0) if logits else torch.empty(0, self.out.out_features)\n","\n","        return logits, output_token_ids\n","\n","start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n","end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n","\n","vocab_size: int = 30000\n","embedding_dim: int = 768\n","hidden_size: int = 1024 # RNN의 hidden size\n","num_layers: int = 1 # 쌓을 RNN layer의 개수\n","bidirectional: bool = False # 단방향 RNN\n","\n","attention_decoder = AttentionDecoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=bidirectional,\n","    start_token_id=start_token_id,\n","    end_token_id=end_token_id,\n",")\n","\n","logits, output_tokens = attention_decoder(h_n, c_n, hidden_states)\n","output_token_ids = logits.argmax(dim=-1)\n","output_texts = tokenizer.decode(output_token_ids.tolist())\n","print(output_texts)"]},{"cell_type":"markdown","id":"bd266f15","metadata":{"id":"bd266f15"},"source":["Decoder layer를 구현했으니 이제 Seq2Seq 모델에 적용해봅니다."]},{"cell_type":"code","execution_count":null,"id":"036db196","metadata":{"id":"036db196"},"outputs":[],"source":["class AttentionSeq2Seq(nn.Module):\n","    def __init__(self: \"AttentionSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self: \"AttentionSeq2Seq\", input_ids: Tensor1D[Sequence]):\n","        hidden_states, (last_hidden_state, cell_states) = self.encoder(input_ids) # encoder에서 생성한 h_n을 decoder layer로 전달\n","        logits, output_tokens = self.decoder(last_hidden_state, cell_states, hidden_states)\n","\n","        return logits, output_tokens\n","\n","seq2seq = AttentionSeq2Seq(lstm_encoder, attention_decoder)\n","logits, output_tokens = seq2seq(input_ids)\n","output_token_ids = logits.argmax(dim=-1)\n","output_texts = tokenizer.decode(output_token_ids.tolist())\n","print(output_texts)"]},{"cell_type":"markdown","id":"a7438c86","metadata":{"id":"a7438c86"},"source":["# 4. Huggingface 라이브러리 활용\n","\n","- 학습 목표\n","  1. huggingface 라이브러리를 이용하여 기학습된 모델을 불러올 수 있다.\n","  2. 기학습된 모델을 이용하여 추론을 할 수 있다.\n","- 학습 개념\n","  1. huggingface\n","- 진행하는 실습 요약\n","  1. HuggingFace Hub에서 한국어-영어 번역을 위해 사전학습된 모델과 토크나이저를 불러오는 코드(from_pretrained)를 완성\n","  2. 불러온 토크나이저로 입력 문장을 인코딩하고, model.generate() 함수를 사용해 번역 결과를 생성하는 코드를 완성\n","  3. 과제 2에서 사용한 번역 모델이 실제로 인코더와 디코더를 모두 가지고 있는지 코드로 확인\n","\n","huggingface는 글로벌 최대 AI 모델 오픈소스 커뮤니티입니다. 과거에는 자연어처리 모델만 있었지만, 최근에는 비전, 로봇 등 다양한 오픈소스 모델들을 지원합니다.\n","\n","여기서 Seq2Seq 아키텍쳐 구조에서 미리 학습한 모델을 불러와서 추론을 해보겠습니다.\n","\n","huggingface documentation:\n","https://huggingface.co/docs/transformers/index"]},{"cell_type":"markdown","id":"87698cfe","metadata":{"id":"87698cfe"},"source":["아래 코드를 실행하여 모델과 토크나이저를 불러옵니다."]},{"cell_type":"code","execution_count":26,"id":"28f35c6a","metadata":{"id":"28f35c6a","colab":{"base_uri":"https://localhost:8080/","height":441,"referenced_widgets":["2d91177077c74da6b47a8fd00582be36","86290d993a724801b9a22f489173fa1d","c7e63bdc13d548eb855b9795f881ee07","84544fc0c3ef4bb18323b99cc989732f","822fa46a63c444bd8c886ed62e36e19b","cb8c9fc8adbf41c28d212906ecbecbc9","8b76c673cea94aada833909e8443eccb","725e290ed24f458188c320cfb366cf06","13b1c68a8705448689a2a3c1de64246d","4ab81c180fef4118a893aed55d74aed2","cdc619ad0823409a94dbeaca0fb219ff","b039adefb63d4113bd6319df72c72188","7e92bd0fbe8a4fb6ae2d1a362017cf0f","3196835aeb7f4840873da61f1f0997ac","7ff9fcfeac9e47b7a76c9cf462ba9c54","225a7253c8424ef7b57b1110a34bfaad","ae86a732a3764512abbb74d260593774","4c0fbfb7a2b84cc4be4504d256e0fe2b","c50231ef40424046ad469840665c83ee","82dd73810ab94a4e97b6bd0dc4f79a25","11d40298f4624c488d0fa23aa17efa0f","0f4f9a3e103441fb8034329ceb7e6172","b938c9b0c5d14d7f97ba9cce12924cf6","9738484887794ab9850b0b8ab1d49339","71ae5874716547b281cdbcaa131efc62","704754f41f38429fab42a938d4bf621d","85e5d7d8756547278f9153d9b184e20b","ce75ce06ed8b4d47ada0027d76062f74","4bfb3b71f3f540d6839045ebd7fcce1e","25d4529c92844ce7b062fef04cc457c3","9317bae597d74afd800408705c752092","58fd8ea2630d418485f9caed46445225","7c997357da654e9d9ac1e37906f3cc51","06ba36d6278e4c788190394b97a5789f","5fb42a0b1d084da787f2327667a06823","4d962eb8c34e475199c1e61db0bd6b02","b50cc2fb20c94aa39e3df40cad007e48","147e9d340b454263b1bbe74ef660f7ce","bfbdb41b57d54f82bb7183049f900b87","b00e72fef8d146daba8ecd8602bbac70","a5848cdde28d44f7ad6c3fe2e7b4a57d","9f13a6226b984d008c466dc9c2e8cd1a","ab3dbfd35f5842bd8d2379f453d11961","13f3f93521414ae38d108a2907b363d0","b44576d32f3f48068f5c8286344e5ef8","23a8d0af827c4ccf99bc6a107db1d1c4","e0c30443d3a849a3ab497087319d3979","713dd3e240a9433ebaff5bc664912ba6","94268a1f7a6f40b4b2b26eafb2d13681","b2131eeab6ed4aa9b7f888832e464a6a","be692f662a1c4bc7b123f74c242c21b1","afb4ee10c8e344568bb94e1117659fa1","c73afaebd57c4c02baa17d212c93cb92","3c31d06024704f60bbdcaba807e98640","d97acfac0da14966bc7bdd14f2024f87","7636b6d6c3574bebb12ac4987211c942","92eeb1d6e2454fdbafc2321b46588d59","d608bb6604444a1ba96088e81c99ec38","39c5c2a4ab394c1da9162f96baf15c55","20f502404666441fa4ff57c3934b0007","15cd24fe2031421f900b50417c41323e","56f97c1ee12a4e0881a83f08500202fa","26602be166594e41b7452c540814727e","fe8a4aa828944726a68e7b23457722b9","d42d45aa2df842008e2015caf79df645","6319b2e3da954ed48debf0ab7a13d11d","5056c729d3cc429baacd794277799017","456ca95d99224593b198045a1265215e","d113cfcba729475faa06907924f344e3","c412631fd2544afeb7aac88cb0b5f96b","e1e4b170635240cc88ff3ea6bd7ca675","65ae5f9c870e4c4ca1b3884461da1438","5083e06dc1fb41b48f0f5d7eb5fe5a7b","7992d3813b02437ebef2a13a8bd276c8","b1aa66451fe347e290729839566731c0","20112b67eef24e698498315cbe8d25d9","e28cfcade16f4124bec1666c2effbb73","29d6de9929db4dc4a073b0c1e06ec167","fda337d1e91a49e1aabfb92dd23c9506","185d01fce8284757a4ff052c2f749c34","e0db1507177947babe99ba95722efe96","1cd2f2433708400c9770b72bc5448bae","853f270a87394f5d9e92d725fa0ad75f","53432ac4ff964f4fb3079b99d8262bb9","d819de163bc548eb8ccd0b5470b1312d","17695ec598a14326abf5ebc60c71afdf","2bfea2a25da342d18c2d5c569a343ecf","74ac86050aa845c7a3772d0a879483d0"]},"executionInfo":{"status":"ok","timestamp":1760532871745,"user_tz":-540,"elapsed":44831,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"556c6570-3aab-467d-e908-c84d40fcb7e2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d91177077c74da6b47a8fd00582be36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b039adefb63d4113bd6319df72c72188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b938c9b0c5d14d7f97ba9cce12924cf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ba36d6278e4c788190394b97a5789f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b44576d32f3f48068f5c8286344e5ef8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7636b6d6c3574bebb12ac4987211c942"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/312M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5056c729d3cc429baacd794277799017"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d6de9929db4dc4a073b0c1e06ec167"}},"metadata":{}}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_name = \"Helsinki-NLP/opus-mt-ko-en\" # machine translation\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"]},{"cell_type":"markdown","id":"1d16c583","metadata":{"id":"1d16c583"},"source":["불러온 모델이 Encoder와 Decoder 모듈을 가지고 있는지 확인하는 2가지 방법이 있습니다.\n","\n","1. `print(model)`을 사용하여 모델의 구조를 확인합니다. 시각적으로 잘 정돈된 모델 구조를 확인할 수 있습니다.\n","2. `model.named_parameters()`를 사용하여 실제 클래스를 확인할 수 있습니다."]},{"cell_type":"code","execution_count":27,"id":"f818e2ea","metadata":{"id":"f818e2ea","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760532871822,"user_tz":-540,"elapsed":58,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"0b2a1c37-8541-4eb5-af93-ea9e2384e96c"},"outputs":[{"output_type":"stream","name":"stdout","text":["MarianMTModel(\n","  (model): MarianModel(\n","    (shared): Embedding(65001, 512, padding_idx=65000)\n","    (encoder): MarianEncoder(\n","      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianEncoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): SiLU()\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decoder): MarianDecoder(\n","      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianDecoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (activation_fn): SiLU()\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":28,"id":"bbaf7975","metadata":{"id":"bbaf7975","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760532871831,"user_tz":-540,"elapsed":7,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"17366b73-6eb6-475a-fc1b-b32faf8f0359"},"outputs":[{"output_type":"stream","name":"stdout","text":["model.shared.weight\n","model.encoder.embed_positions.weight\n","model.encoder.layers.0.self_attn.k_proj.weight\n","model.encoder.layers.0.self_attn.k_proj.bias\n","model.encoder.layers.0.self_attn.v_proj.weight\n","model.encoder.layers.0.self_attn.v_proj.bias\n","model.encoder.layers.0.self_attn.q_proj.weight\n","model.encoder.layers.0.self_attn.q_proj.bias\n","model.encoder.layers.0.self_attn.out_proj.weight\n","model.encoder.layers.0.self_attn.out_proj.bias\n","model.encoder.layers.0.self_attn_layer_norm.weight\n","model.encoder.layers.0.self_attn_layer_norm.bias\n","model.encoder.layers.0.fc1.weight\n","model.encoder.layers.0.fc1.bias\n","model.encoder.layers.0.fc2.weight\n","model.encoder.layers.0.fc2.bias\n","model.encoder.layers.0.final_layer_norm.weight\n","model.encoder.layers.0.final_layer_norm.bias\n","model.encoder.layers.1.self_attn.k_proj.weight\n","model.encoder.layers.1.self_attn.k_proj.bias\n","model.encoder.layers.1.self_attn.v_proj.weight\n","model.encoder.layers.1.self_attn.v_proj.bias\n","model.encoder.layers.1.self_attn.q_proj.weight\n","model.encoder.layers.1.self_attn.q_proj.bias\n","model.encoder.layers.1.self_attn.out_proj.weight\n","model.encoder.layers.1.self_attn.out_proj.bias\n","model.encoder.layers.1.self_attn_layer_norm.weight\n","model.encoder.layers.1.self_attn_layer_norm.bias\n","model.encoder.layers.1.fc1.weight\n","model.encoder.layers.1.fc1.bias\n","model.encoder.layers.1.fc2.weight\n","model.encoder.layers.1.fc2.bias\n","model.encoder.layers.1.final_layer_norm.weight\n","model.encoder.layers.1.final_layer_norm.bias\n","model.encoder.layers.2.self_attn.k_proj.weight\n","model.encoder.layers.2.self_attn.k_proj.bias\n","model.encoder.layers.2.self_attn.v_proj.weight\n","model.encoder.layers.2.self_attn.v_proj.bias\n","model.encoder.layers.2.self_attn.q_proj.weight\n","model.encoder.layers.2.self_attn.q_proj.bias\n","model.encoder.layers.2.self_attn.out_proj.weight\n","model.encoder.layers.2.self_attn.out_proj.bias\n","model.encoder.layers.2.self_attn_layer_norm.weight\n","model.encoder.layers.2.self_attn_layer_norm.bias\n","model.encoder.layers.2.fc1.weight\n","model.encoder.layers.2.fc1.bias\n","model.encoder.layers.2.fc2.weight\n","model.encoder.layers.2.fc2.bias\n","model.encoder.layers.2.final_layer_norm.weight\n","model.encoder.layers.2.final_layer_norm.bias\n","model.encoder.layers.3.self_attn.k_proj.weight\n","model.encoder.layers.3.self_attn.k_proj.bias\n","model.encoder.layers.3.self_attn.v_proj.weight\n","model.encoder.layers.3.self_attn.v_proj.bias\n","model.encoder.layers.3.self_attn.q_proj.weight\n","model.encoder.layers.3.self_attn.q_proj.bias\n","model.encoder.layers.3.self_attn.out_proj.weight\n","model.encoder.layers.3.self_attn.out_proj.bias\n","model.encoder.layers.3.self_attn_layer_norm.weight\n","model.encoder.layers.3.self_attn_layer_norm.bias\n","model.encoder.layers.3.fc1.weight\n","model.encoder.layers.3.fc1.bias\n","model.encoder.layers.3.fc2.weight\n","model.encoder.layers.3.fc2.bias\n","model.encoder.layers.3.final_layer_norm.weight\n","model.encoder.layers.3.final_layer_norm.bias\n","model.encoder.layers.4.self_attn.k_proj.weight\n","model.encoder.layers.4.self_attn.k_proj.bias\n","model.encoder.layers.4.self_attn.v_proj.weight\n","model.encoder.layers.4.self_attn.v_proj.bias\n","model.encoder.layers.4.self_attn.q_proj.weight\n","model.encoder.layers.4.self_attn.q_proj.bias\n","model.encoder.layers.4.self_attn.out_proj.weight\n","model.encoder.layers.4.self_attn.out_proj.bias\n","model.encoder.layers.4.self_attn_layer_norm.weight\n","model.encoder.layers.4.self_attn_layer_norm.bias\n","model.encoder.layers.4.fc1.weight\n","model.encoder.layers.4.fc1.bias\n","model.encoder.layers.4.fc2.weight\n","model.encoder.layers.4.fc2.bias\n","model.encoder.layers.4.final_layer_norm.weight\n","model.encoder.layers.4.final_layer_norm.bias\n","model.encoder.layers.5.self_attn.k_proj.weight\n","model.encoder.layers.5.self_attn.k_proj.bias\n","model.encoder.layers.5.self_attn.v_proj.weight\n","model.encoder.layers.5.self_attn.v_proj.bias\n","model.encoder.layers.5.self_attn.q_proj.weight\n","model.encoder.layers.5.self_attn.q_proj.bias\n","model.encoder.layers.5.self_attn.out_proj.weight\n","model.encoder.layers.5.self_attn.out_proj.bias\n","model.encoder.layers.5.self_attn_layer_norm.weight\n","model.encoder.layers.5.self_attn_layer_norm.bias\n","model.encoder.layers.5.fc1.weight\n","model.encoder.layers.5.fc1.bias\n","model.encoder.layers.5.fc2.weight\n","model.encoder.layers.5.fc2.bias\n","model.encoder.layers.5.final_layer_norm.weight\n","model.encoder.layers.5.final_layer_norm.bias\n","model.decoder.embed_positions.weight\n","model.decoder.layers.0.self_attn.k_proj.weight\n","model.decoder.layers.0.self_attn.k_proj.bias\n","model.decoder.layers.0.self_attn.v_proj.weight\n","model.decoder.layers.0.self_attn.v_proj.bias\n","model.decoder.layers.0.self_attn.q_proj.weight\n","model.decoder.layers.0.self_attn.q_proj.bias\n","model.decoder.layers.0.self_attn.out_proj.weight\n","model.decoder.layers.0.self_attn.out_proj.bias\n","model.decoder.layers.0.self_attn_layer_norm.weight\n","model.decoder.layers.0.self_attn_layer_norm.bias\n","model.decoder.layers.0.encoder_attn.k_proj.weight\n","model.decoder.layers.0.encoder_attn.k_proj.bias\n","model.decoder.layers.0.encoder_attn.v_proj.weight\n","model.decoder.layers.0.encoder_attn.v_proj.bias\n","model.decoder.layers.0.encoder_attn.q_proj.weight\n","model.decoder.layers.0.encoder_attn.q_proj.bias\n","model.decoder.layers.0.encoder_attn.out_proj.weight\n","model.decoder.layers.0.encoder_attn.out_proj.bias\n","model.decoder.layers.0.encoder_attn_layer_norm.weight\n","model.decoder.layers.0.encoder_attn_layer_norm.bias\n","model.decoder.layers.0.fc1.weight\n","model.decoder.layers.0.fc1.bias\n","model.decoder.layers.0.fc2.weight\n","model.decoder.layers.0.fc2.bias\n","model.decoder.layers.0.final_layer_norm.weight\n","model.decoder.layers.0.final_layer_norm.bias\n","model.decoder.layers.1.self_attn.k_proj.weight\n","model.decoder.layers.1.self_attn.k_proj.bias\n","model.decoder.layers.1.self_attn.v_proj.weight\n","model.decoder.layers.1.self_attn.v_proj.bias\n","model.decoder.layers.1.self_attn.q_proj.weight\n","model.decoder.layers.1.self_attn.q_proj.bias\n","model.decoder.layers.1.self_attn.out_proj.weight\n","model.decoder.layers.1.self_attn.out_proj.bias\n","model.decoder.layers.1.self_attn_layer_norm.weight\n","model.decoder.layers.1.self_attn_layer_norm.bias\n","model.decoder.layers.1.encoder_attn.k_proj.weight\n","model.decoder.layers.1.encoder_attn.k_proj.bias\n","model.decoder.layers.1.encoder_attn.v_proj.weight\n","model.decoder.layers.1.encoder_attn.v_proj.bias\n","model.decoder.layers.1.encoder_attn.q_proj.weight\n","model.decoder.layers.1.encoder_attn.q_proj.bias\n","model.decoder.layers.1.encoder_attn.out_proj.weight\n","model.decoder.layers.1.encoder_attn.out_proj.bias\n","model.decoder.layers.1.encoder_attn_layer_norm.weight\n","model.decoder.layers.1.encoder_attn_layer_norm.bias\n","model.decoder.layers.1.fc1.weight\n","model.decoder.layers.1.fc1.bias\n","model.decoder.layers.1.fc2.weight\n","model.decoder.layers.1.fc2.bias\n","model.decoder.layers.1.final_layer_norm.weight\n","model.decoder.layers.1.final_layer_norm.bias\n","model.decoder.layers.2.self_attn.k_proj.weight\n","model.decoder.layers.2.self_attn.k_proj.bias\n","model.decoder.layers.2.self_attn.v_proj.weight\n","model.decoder.layers.2.self_attn.v_proj.bias\n","model.decoder.layers.2.self_attn.q_proj.weight\n","model.decoder.layers.2.self_attn.q_proj.bias\n","model.decoder.layers.2.self_attn.out_proj.weight\n","model.decoder.layers.2.self_attn.out_proj.bias\n","model.decoder.layers.2.self_attn_layer_norm.weight\n","model.decoder.layers.2.self_attn_layer_norm.bias\n","model.decoder.layers.2.encoder_attn.k_proj.weight\n","model.decoder.layers.2.encoder_attn.k_proj.bias\n","model.decoder.layers.2.encoder_attn.v_proj.weight\n","model.decoder.layers.2.encoder_attn.v_proj.bias\n","model.decoder.layers.2.encoder_attn.q_proj.weight\n","model.decoder.layers.2.encoder_attn.q_proj.bias\n","model.decoder.layers.2.encoder_attn.out_proj.weight\n","model.decoder.layers.2.encoder_attn.out_proj.bias\n","model.decoder.layers.2.encoder_attn_layer_norm.weight\n","model.decoder.layers.2.encoder_attn_layer_norm.bias\n","model.decoder.layers.2.fc1.weight\n","model.decoder.layers.2.fc1.bias\n","model.decoder.layers.2.fc2.weight\n","model.decoder.layers.2.fc2.bias\n","model.decoder.layers.2.final_layer_norm.weight\n","model.decoder.layers.2.final_layer_norm.bias\n","model.decoder.layers.3.self_attn.k_proj.weight\n","model.decoder.layers.3.self_attn.k_proj.bias\n","model.decoder.layers.3.self_attn.v_proj.weight\n","model.decoder.layers.3.self_attn.v_proj.bias\n","model.decoder.layers.3.self_attn.q_proj.weight\n","model.decoder.layers.3.self_attn.q_proj.bias\n","model.decoder.layers.3.self_attn.out_proj.weight\n","model.decoder.layers.3.self_attn.out_proj.bias\n","model.decoder.layers.3.self_attn_layer_norm.weight\n","model.decoder.layers.3.self_attn_layer_norm.bias\n","model.decoder.layers.3.encoder_attn.k_proj.weight\n","model.decoder.layers.3.encoder_attn.k_proj.bias\n","model.decoder.layers.3.encoder_attn.v_proj.weight\n","model.decoder.layers.3.encoder_attn.v_proj.bias\n","model.decoder.layers.3.encoder_attn.q_proj.weight\n","model.decoder.layers.3.encoder_attn.q_proj.bias\n","model.decoder.layers.3.encoder_attn.out_proj.weight\n","model.decoder.layers.3.encoder_attn.out_proj.bias\n","model.decoder.layers.3.encoder_attn_layer_norm.weight\n","model.decoder.layers.3.encoder_attn_layer_norm.bias\n","model.decoder.layers.3.fc1.weight\n","model.decoder.layers.3.fc1.bias\n","model.decoder.layers.3.fc2.weight\n","model.decoder.layers.3.fc2.bias\n","model.decoder.layers.3.final_layer_norm.weight\n","model.decoder.layers.3.final_layer_norm.bias\n","model.decoder.layers.4.self_attn.k_proj.weight\n","model.decoder.layers.4.self_attn.k_proj.bias\n","model.decoder.layers.4.self_attn.v_proj.weight\n","model.decoder.layers.4.self_attn.v_proj.bias\n","model.decoder.layers.4.self_attn.q_proj.weight\n","model.decoder.layers.4.self_attn.q_proj.bias\n","model.decoder.layers.4.self_attn.out_proj.weight\n","model.decoder.layers.4.self_attn.out_proj.bias\n","model.decoder.layers.4.self_attn_layer_norm.weight\n","model.decoder.layers.4.self_attn_layer_norm.bias\n","model.decoder.layers.4.encoder_attn.k_proj.weight\n","model.decoder.layers.4.encoder_attn.k_proj.bias\n","model.decoder.layers.4.encoder_attn.v_proj.weight\n","model.decoder.layers.4.encoder_attn.v_proj.bias\n","model.decoder.layers.4.encoder_attn.q_proj.weight\n","model.decoder.layers.4.encoder_attn.q_proj.bias\n","model.decoder.layers.4.encoder_attn.out_proj.weight\n","model.decoder.layers.4.encoder_attn.out_proj.bias\n","model.decoder.layers.4.encoder_attn_layer_norm.weight\n","model.decoder.layers.4.encoder_attn_layer_norm.bias\n","model.decoder.layers.4.fc1.weight\n","model.decoder.layers.4.fc1.bias\n","model.decoder.layers.4.fc2.weight\n","model.decoder.layers.4.fc2.bias\n","model.decoder.layers.4.final_layer_norm.weight\n","model.decoder.layers.4.final_layer_norm.bias\n","model.decoder.layers.5.self_attn.k_proj.weight\n","model.decoder.layers.5.self_attn.k_proj.bias\n","model.decoder.layers.5.self_attn.v_proj.weight\n","model.decoder.layers.5.self_attn.v_proj.bias\n","model.decoder.layers.5.self_attn.q_proj.weight\n","model.decoder.layers.5.self_attn.q_proj.bias\n","model.decoder.layers.5.self_attn.out_proj.weight\n","model.decoder.layers.5.self_attn.out_proj.bias\n","model.decoder.layers.5.self_attn_layer_norm.weight\n","model.decoder.layers.5.self_attn_layer_norm.bias\n","model.decoder.layers.5.encoder_attn.k_proj.weight\n","model.decoder.layers.5.encoder_attn.k_proj.bias\n","model.decoder.layers.5.encoder_attn.v_proj.weight\n","model.decoder.layers.5.encoder_attn.v_proj.bias\n","model.decoder.layers.5.encoder_attn.q_proj.weight\n","model.decoder.layers.5.encoder_attn.q_proj.bias\n","model.decoder.layers.5.encoder_attn.out_proj.weight\n","model.decoder.layers.5.encoder_attn.out_proj.bias\n","model.decoder.layers.5.encoder_attn_layer_norm.weight\n","model.decoder.layers.5.encoder_attn_layer_norm.bias\n","model.decoder.layers.5.fc1.weight\n","model.decoder.layers.5.fc1.bias\n","model.decoder.layers.5.fc2.weight\n","model.decoder.layers.5.fc2.bias\n","model.decoder.layers.5.final_layer_norm.weight\n","model.decoder.layers.5.final_layer_norm.bias\n"]}],"source":["for name, param in model.named_parameters():\n","    print(name)"]},{"cell_type":"markdown","id":"167a381f","metadata":{"id":"167a381f"},"source":["이미 학습된 모델을 통해 추론을 진행합니다.\n","위의 실습에서 추론했던 것과는 다르게 학습된 모델이므로 성능이 더 높게 나타납니다."]},{"cell_type":"code","execution_count":29,"id":"7f0ec813","metadata":{"id":"7f0ec813","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1760532874942,"user_tz":-540,"elapsed":2215,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"033794c5-0809-4f2c-a21a-bee0c45bc253"},"outputs":[{"output_type":"stream","name":"stdout","text":["SRC: 나는 학교에 간다.\n","MT : I'm going to school.\n"]}],"source":["text = \"나는 학교에 간다.\"\n","\"\"\"여기서는 batch로 입력을 처리하여 차원이 [seq_len]이 아닌 [batch_size, seq_len]입니다. 여기서는 입력이 한개이므로 [1, seq_len]입니다.\"\"\"\n","encoded = tokenizer(text, return_tensors=\"pt\")\n","\n","generated_ids = model.generate(\n","    **encoded,\n","    max_new_tokens=64,\n",")\n","\n","translation = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n","print(\"SRC:\", text)\n","print(\"MT :\", translation)"]},{"cell_type":"markdown","id":"0383cf9c","metadata":{"id":"0383cf9c"},"source":["# 5. 아키텍처별 모델 다뤄보기(Encoder model, Decoder model)\n","\n","- 학습 목표\n","  1. huggingface 라이브러리를 이용하여 다양한 모델 구조의 모델을 다룰 수 있다.\n","- 학습 개념\n","  1. huggingface\n","- 학습 내용\n","  1. 문맥을 양방향으로 이해하는 데 강점이 있는 BERT 모델을 사용하여 문장의 빈칸([MASK])에 가장 적절한 단어를 추론\n","  2. 이전 텍스트를 바탕으로 다음 텍스트를 생성하는 데 특화된 GPT-2 모델을 사용하여 이야기의 뒷부분을 창작\n","\n","지금까지는 Seq2Seq(Encoder - Decoder) 모델 구조를 다뤘습니다. 하지만, 현재 가장 많이 사용되는 모델은 Only Decoder 모델입니다.\n","\n","1. Only Encoder 모델 : BERT 같은 모델. RAG등 문서 검색에 주로 사용\n","2. Only Decoder 모델 : Chat-GPT 같은 모델. 대화, 번역, 챗봇 등 현재 가장 많이 사용\n","3. Encoder - Decoder 모델 : 최근에는 잘 사용하지 않음\n","\n","그러면 Only Encoder 모델과 Only Decoder 모델을 이용해 모델 추론을 해보겠습니다."]},{"cell_type":"markdown","id":"8039a153","metadata":{"id":"8039a153"},"source":["Encoder의 대표 모델인 BERT 모델을 불러옵니다."]},{"cell_type":"code","execution_count":30,"id":"3ddc1fad","metadata":{"id":"3ddc1fad","colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["d5b18844622148e78dd00a8f025b5fc2","af5afd804da74772ba9a8f75cdc879af","3bbe8a27f6d6487887d75b60da3320d7","c004bd67b34a4ca491efe85a9b137689","86f8b88a929045359ad6bf27490f86b0","9ead9aa6017d42978409cc1a94a18ecf","07e934662e3e47be9005422fd6915c03","1e900646ce51404ea880c62bc07fdfa1","78b1beb8c5324024b83ea63761852900","271f16a9ca8342359e43882643781d6d","eb4bad56e3824c8c9525ff405d2edcfc","90dcce39c37c48f8820b3daf443cebd5","92693923a4314964b9674a33144e5100","8d61a70fbd2f42f8a9d3d583ed335294","354bd0745b6e475b978a908cfc8a711b","aba4af147ddd4101addb79c9a544f17b","1ca7aa59eead42349444b428d0802a3b","c66b1bb1274c467ca78302cfa728ac0f","1930df2a06c745349ce1db67d9611f41","eaa5055f154d43c49660f07d4e23bb03","0c9732d20d8442c89e7442d13bfab34e","4864bb65f76d459ea4e71f4f257e2873","9adcf46bcd6d43a793f951b746b6e67b","8c2e1c66ee9d46d7862c886a7ea24112","6b2902ad815c40ceb8c9021b7a56d126","da752ddd17e348049f46a0daab25b4f3","b36543446d0645eabe2a54d4e443dce4","ecd3e73d52ff4953b324761b41f2b3f9","eb7fbab1c7d7489ca2d0143fa88f1e27","0a5e7a40dafa4c439b6e75f324eb64f1","7bb5d4c8685b406b8e743b0d65d384a4","ac8c929134144a1a84ab171521dbae73","9ed2fc6ce1ed4a65bdbf204a34fb7786","e62997bb51284053ad55b500b459cb42","b92c9d93f85846cfa29b48b64daea024","cfc8a409a18a47d58a8cd10a8fb08a1d","8602986aba3546a6b03cbb824ea4c6be","4a1046d44069471d8e4c78db67675aa8","b635521d70da48069bfa02f7a20ca3cf","b0b6004dd3a545e2aab402c3a5cb4428","467a0cdd781744fa9e23c6d8035d9eb2","d40fffcf48ed4897a08036bda071b918","926c8c10a76b48bdb7071b871b05ba20","4a572c1e4eea41fe85cfaefa0e2f6a78","80058dcffad0434f9b1c3962d7a2d4ac","4211ccfa627c4e29a2a25a59d49651d6","4d9e0b6a34bd4d18b6733412e042b01e","d89cbddf1a91457b952f8ab214a42c65","ad6ad18082fe485da2cd222b906abba1","270e5717225e42529c1a0b6de47b3ee1","49cba2bfee7c4facb8cda8212bc49e60","596483064cab42c898db1df8b89e30fc","6b7994c13d99481ea85d209872392814","207794a399754fcb939f19ca890dad79","07b561b4e63c49598ac254d1ca8457af"]},"executionInfo":{"status":"ok","timestamp":1760532905416,"user_tz":-540,"elapsed":25769,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"22fc5663-dcd0-48fc-a61b-7cfe11aadc85"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b18844622148e78dd00a8f025b5fc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90dcce39c37c48f8820b3daf443cebd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9adcf46bcd6d43a793f951b746b6e67b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e62997bb51284053ad55b500b459cb42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80058dcffad0434f9b1c3962d7a2d4ac"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForMaskedLM\n","\n","model_name = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForMaskedLM.from_pretrained(model_name)"]},{"cell_type":"markdown","id":"4665108b","metadata":{"id":"4665108b"},"source":["BERT 모델을 이용하여 빈칸 맞추기(Masked Language Modeling)를 추론해봅니다.\n","\n","\n","예를 들어, I [MASK] to school. 이라는 문장에서 [MASK]에 들어갈 단어를 맞춘다고 하면 I go to school. 이 문장이 정답이 됩니다.\n","\n","하지만, I went to school도 정답이 될 수 있습니다.\n","\n","이처럼 [MASK]에 들어갈 단어는 여러가지가 될 수 있고, 모델의 학습에 따라 어떤 단어가 [MASK]에 들어갈지 결정됩니다.\n","\n","이러한 특성을 이용하여 BERT 모델을 이용하여 빈칸 맞추기(`[MASK]`)를 추론해봅니다.\n","\n","\n","실제로 BERT는 MLM(Masked Language Model)로 불리며 입력 문장 내의 무작위로 선택된 토큰을 [MASK]토큰으로 대체하여 이를 예측하도록 학습하는 방식을 사용합니다."]},{"cell_type":"code","execution_count":31,"id":"4ce98fb7","metadata":{"id":"4ce98fb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760533508037,"user_tz":-540,"elapsed":461,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"e18dc132-9718-4d03-a35e-65cbf4f91617"},"outputs":[{"output_type":"stream","name":"stdout","text":["원본 문장: I [MASK] to school.\n","BERT가 예측한 문장들:\n","1순위: I went to school.\n","2순위: I go to school.\n","3순위: I walked to school.\n","4순위: I ran to school.\n","5순위: I got to school.\n"]}],"source":["# 4. 우리가 맞출 문장 만들기. tokenizer.mask_token = \"[MASK]\" 이 부분이 빈칸이 됨\n","sentence = f\"I {tokenizer.mask_token} to school.\"\n","\n","top_k = 5  # 상위 5개 후보 단어를 보고 싶다\n","\n","# 5. 문장을 숫자로 바꿔서 BERT가 읽을 수 있게 준비\n","encoded = tokenizer(sentence, return_tensors=\"pt\", return_attention_mask=True) # pt는 파이토치 텐서라는 뜻\n","\n","# 6. 숫자로 된 문장 정보에서 '입력 토큰 ID' 꺼내기\n","input_ids = encoded.input_ids\n","\n","# 7. [MASK]의 숫자 아이디 가져오기\n","mask_token_id = tokenizer.mask_token_id\n","\n","# 8. 문장에서 [MASK]가 있는 위치(인덱스) 찾기 mask_positions는 (배치 번호, 문장 속 위치) 형태로 저장됨\n","# TODO: 직접 구현해보세요!\n","mask_positions = (input_ids == mask_token_id).nonzero(as_tuple=False)\n","\n","# 9. BERT 모델에 문장(숫자형태)을 넣어서 예측 결과(logits) 얻기\n","outputs = model(**encoded)\n","\n","# 10. logits: 각 단어 위치마다 '다음 단어일 가능성'을 모든 단어 사전 크기만큼 기록한 값\n","logits = outputs.logits.squeeze(0)  # (seq_len, vocab_size)\n","\n","# 11. 모든 [MASK] 위치에 대해 예측하기\n","all_token_candidates: List[List[Tuple[str, float]]] = []\n","for _, pos in mask_positions:\n","    pos = pos.item()  # 위치 숫자 꺼내기\n","    logits_at_pos = logits[pos]  # 해당 위치의 예측 점수\n","    probs = torch.softmax(logits_at_pos, dim=-1)  # 점수를 확률로 변환\n","    topk = torch.topk(probs, k=top_k)  # 확률이 높은 상위 5개 선택\n","\n","    ids = topk.indices.tolist()   # 단어 ID\n","    scores = topk.values.tolist() # 확률 값\n","\n","    # 단어 ID를 실제 단어(토큰)로 변환\n","    tokens = [tokenizer.convert_ids_to_tokens(tid) for tid in ids]\n","\n","    # (단어, 확률) 형태로 묶어서 저장\n","    candidates = list(zip(tokens, scores))\n","    all_token_candidates.append(candidates)\n","\n","# 12. [MASK]에 들어갈 단어로 완성된 문장들을 저장할 리스트\n","restored_sentences: List[str] = []\n","\n","# 13. 첫 번째 [MASK] 위치의 후보 단어들\n","token_candidates: List[Tuple[str, float]] = all_token_candidates[0]\n","\n","# 14. 후보 단어들을 하나씩 넣어서 문장을 만들어 보기\n","for tok, _ in token_candidates:\n","    new_ids = input_ids.clone()  # 원래 문장의 숫자 복사\n","    tok_id = tokenizer.convert_tokens_to_ids(tok)  # 후보 단어를 숫자로 변환\n","    new_ids[0, mask_positions[0, 1]] = tok_id      # [MASK] 위치에 후보 단어 ID 넣기\n","    text = tokenizer.decode(new_ids[0], skip_special_tokens=True)  # 다시 글자로 변환\n","    restored_sentences.append(text.strip())  # 앞뒤 공백 제거 후 저장\n","\n","# 15. 결과 출력\n","print(\"원본 문장:\", sentence)\n","print(\"BERT가 예측한 문장들:\")\n","for idx, sent in enumerate(restored_sentences, start=1):\n","    print(\"{}순위: {}\".format(idx, sent))"]},{"cell_type":"markdown","id":"be9e04c7","metadata":{"id":"be9e04c7"},"source":["Only Decoder 모델의 대표인 GPT 모델을 이용하여 추론을 해보겠습니다.\n","\n","GPT-2 모델을 불러옵니다."]},{"cell_type":"code","execution_count":32,"id":"6a49ab04","metadata":{"id":"6a49ab04","colab":{"base_uri":"https://localhost:8080/","height":241,"referenced_widgets":["eea22bac8df240419a2d343dec66c698","2a1fbc66b5fc4354a4e27b66d506534d","ae1685ef0a2d40c3943a1e05aaba89c4","24b21d2837b647d1b00689a5c89f5fb3","b32d25fa0b68473b89d661dea1a04a09","48be4d0f40bc4aa3a6f169bf7a59e0fd","320ca1a2e9144d59b82c06789596e5e9","38568370b1064e29bf8fa2765fb168df","27ca0db1fd0140228cf86653396e3ebe","8191645497d542d8b56830ba8e50956c","462a28c7fd4e48128476f1dcd17f5e9d","1c7513d9fd8b47b19da2b093c76f26d8","053b2b57351d4550b080a8fcfb170daf","3ff283715eb64228bf0809f7a8d15034","2214c58d4bfe42e4851f52f6354998c5","209ce18b4a3342b18fb2a900c2ef325e","e80034f7b26b423697b78e509bc7bdad","e382eece93824f91b040d2f6fa0cc798","16426d21932a46d5a4ea65dc29b4a128","e4a904a8e7524c029437437bde717dcf","9ded2a71fb5c4dbd8cab3900219a7754","bcea15ab6aca4a8bb4131b677347d871","31ba0041ecb3440a86b350a2a17bfcf7","fc6bf231c9564e7abd001ae761fd644d","181371787f4a4551b28bdb0f693d06eb","c2e645f7547d4247be59d8f83de68c5e","70d75baec5924ee3bb43739e4f053c2a","c40d10d01ff44f91bf206da1670b3033","df32c53288064f4eba6e3294db7ee4bd","02cc9f1501f5400599f112b7cc5abf08","9e93e2da77ea453bb41e39e5c1ff7f07","75898b193658439cae4cea0701876655","3ecee9fadd304a5898d4a6c4f6da1e51","851a4f3a7f8f4176aec6ce47f4d931e3","7e0551f38b12450ebc89bf488273ca6f","cb6f9c8cfc314c3180a5484f7dc202ed","c722aaa8a3ef4625a7b45b37b79dfa44","32d52583bb444e09bc61692099f319fd","d4c7f9f8da204f4ba0ef795087ae164a","e745df1299f14078b5b2d74f7368da11","594c044102fa4e78a51a48aa094c4e84","79f9c8f5c016442eb5e4ee4537ef0a18","85271956be5440a882a8d5fb9da9950a","b99ec3d3884446b281c7875f0f322e69","9a5010141475458788e9c3acd5e1de45","26dfd79155d74b4daa217f7e65d99687","de0f25142e5e499487f5cbdc89133700","93132b07417b46e7b60179096668c586","408f230d459740c68027c0798f2de4b3","448ba17a6df24985ab5ecf77d73f37e2","ca3c333433ef47d3abb71cddfef6bd2b","e97f07b065ca4b498023f2a108e62517","8ceef4c746ef4edd98be2921878c7c00","5a8bb93c597c41288956ebfef0458640","508a4aaf6299410a834235ba554d62bb","8767bb1c63fd401dbdc0ac4ce112b54e","93b0bf23dac24ebfa39001d234aed7cb","58b53c4aad4a45eca0b48358e6633d9b","0951d1fa182f459b8c615184917ac94c","1384d5791abf4b7b93d0cefe941c3567","aa4b3ad5b8d2436ca882b50aaaa07ba2","f7fb1de7dc1c464cb06cb703ddc3b52f","278b782f643a406db19f99a5e00ac07f","7397e95a8e1344fbb771622e01c9ddee","9fc0809b76c54426b89ee43a6f3c883e","c328ccfa2e9c4d9dbe76c241cb172537","8f03984f1ec34136be2b82d76d7fca28","b58e47f770124a9ca011aefd0b0ffd86","0ba82b3cad15447c9603d017fcfc5d50","8fddb1e3ac4c4c0e9a29e339be83c88a","d39db9d13c384a199ba603f1f86f3813","ed6f89872e0445748dcb1f4260541799","35b7ea688ac749249ed70407ca9ed96a","016565a21d8e48fd8062f05fdc0bf123","da4355358a2a400eba6b3cf4741f69a1","63e0dbd2462b439b9901a95bdce3f76a","a1b1709b5b94423d8b77d5bc46785941"]},"executionInfo":{"status":"ok","timestamp":1760533530181,"user_tz":-540,"elapsed":21671,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"cbc1fe4b-73eb-4753-d819-27772ca53a53"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea22bac8df240419a2d343dec66c698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c7513d9fd8b47b19da2b093c76f26d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31ba0041ecb3440a86b350a2a17bfcf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851a4f3a7f8f4176aec6ce47f4d931e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a5010141475458788e9c3acd5e1de45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8767bb1c63fd401dbdc0ac4ce112b54e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f03984f1ec34136be2b82d76d7fca28"}},"metadata":{}}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","model_name = \"gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)"]},{"cell_type":"markdown","id":"0feb32c0","metadata":{"id":"0feb32c0"},"source":["GPT-2 모델은 입력으로 토큰화된 텍스트를 받고, 그 뒤에 올 단어들을 예측(Next token Prediction)하는 것이 목표입니다.\n","\n","아래 코드를 이용하여 스토리(입력 텍스트)의 뒷 내용을 생성해보겠습니다."]},{"cell_type":"code","execution_count":33,"id":"33182f00","metadata":{"id":"33182f00","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760533535078,"user_tz":-540,"elapsed":4948,"user":{"displayName":"S H","userId":"07486973781233731858"}},"outputId":"be4ee570-0922-4edb-c1be-00440aab737e"},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["Once upon a time in a small village, a curious child found a mysterious key. The child was a boy named Kiyoshi. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice.\n"]}],"source":["prompt = \"Once upon a time in a small village, a curious child found a mysterious key.\"\n","inputs = tokenizer(prompt, return_tensors=\"pt\")\n","\n","with torch.no_grad():\n","    generated_ids = model.generate(\n","        **inputs,\n","        max_new_tokens=64,\n","    )\n","\n","output_tokens = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n","print(output_tokens)"]},{"cell_type":"code","source":[],"metadata":{"id":"lgu2CdZr-XUz","executionInfo":{"status":"ok","timestamp":1760533535080,"user_tz":-540,"elapsed":1,"user":{"displayName":"S H","userId":"07486973781233731858"}}},"id":"lgu2CdZr-XUz","execution_count":33,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"c10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"2d91177077c74da6b47a8fd00582be36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86290d993a724801b9a22f489173fa1d","IPY_MODEL_c7e63bdc13d548eb855b9795f881ee07","IPY_MODEL_84544fc0c3ef4bb18323b99cc989732f"],"layout":"IPY_MODEL_822fa46a63c444bd8c886ed62e36e19b"}},"86290d993a724801b9a22f489173fa1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb8c9fc8adbf41c28d212906ecbecbc9","placeholder":"​","style":"IPY_MODEL_8b76c673cea94aada833909e8443eccb","value":"tokenizer_config.json: 100%"}},"c7e63bdc13d548eb855b9795f881ee07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_725e290ed24f458188c320cfb366cf06","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13b1c68a8705448689a2a3c1de64246d","value":44}},"84544fc0c3ef4bb18323b99cc989732f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ab81c180fef4118a893aed55d74aed2","placeholder":"​","style":"IPY_MODEL_cdc619ad0823409a94dbeaca0fb219ff","value":" 44.0/44.0 [00:00&lt;00:00, 2.52kB/s]"}},"822fa46a63c444bd8c886ed62e36e19b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb8c9fc8adbf41c28d212906ecbecbc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b76c673cea94aada833909e8443eccb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"725e290ed24f458188c320cfb366cf06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13b1c68a8705448689a2a3c1de64246d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ab81c180fef4118a893aed55d74aed2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdc619ad0823409a94dbeaca0fb219ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b039adefb63d4113bd6319df72c72188":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e92bd0fbe8a4fb6ae2d1a362017cf0f","IPY_MODEL_3196835aeb7f4840873da61f1f0997ac","IPY_MODEL_7ff9fcfeac9e47b7a76c9cf462ba9c54"],"layout":"IPY_MODEL_225a7253c8424ef7b57b1110a34bfaad"}},"7e92bd0fbe8a4fb6ae2d1a362017cf0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae86a732a3764512abbb74d260593774","placeholder":"​","style":"IPY_MODEL_4c0fbfb7a2b84cc4be4504d256e0fe2b","value":"config.json: "}},"3196835aeb7f4840873da61f1f0997ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c50231ef40424046ad469840665c83ee","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82dd73810ab94a4e97b6bd0dc4f79a25","value":1}},"7ff9fcfeac9e47b7a76c9cf462ba9c54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11d40298f4624c488d0fa23aa17efa0f","placeholder":"​","style":"IPY_MODEL_0f4f9a3e103441fb8034329ceb7e6172","value":" 1.39k/? [00:00&lt;00:00, 96.0kB/s]"}},"225a7253c8424ef7b57b1110a34bfaad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae86a732a3764512abbb74d260593774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c0fbfb7a2b84cc4be4504d256e0fe2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c50231ef40424046ad469840665c83ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"82dd73810ab94a4e97b6bd0dc4f79a25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11d40298f4624c488d0fa23aa17efa0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f4f9a3e103441fb8034329ceb7e6172":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b938c9b0c5d14d7f97ba9cce12924cf6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9738484887794ab9850b0b8ab1d49339","IPY_MODEL_71ae5874716547b281cdbcaa131efc62","IPY_MODEL_704754f41f38429fab42a938d4bf621d"],"layout":"IPY_MODEL_85e5d7d8756547278f9153d9b184e20b"}},"9738484887794ab9850b0b8ab1d49339":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce75ce06ed8b4d47ada0027d76062f74","placeholder":"​","style":"IPY_MODEL_4bfb3b71f3f540d6839045ebd7fcce1e","value":"source.spm: 100%"}},"71ae5874716547b281cdbcaa131efc62":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d4529c92844ce7b062fef04cc457c3","max":841805,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9317bae597d74afd800408705c752092","value":841805}},"704754f41f38429fab42a938d4bf621d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58fd8ea2630d418485f9caed46445225","placeholder":"​","style":"IPY_MODEL_7c997357da654e9d9ac1e37906f3cc51","value":" 842k/842k [00:00&lt;00:00, 9.64MB/s]"}},"85e5d7d8756547278f9153d9b184e20b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce75ce06ed8b4d47ada0027d76062f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bfb3b71f3f540d6839045ebd7fcce1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25d4529c92844ce7b062fef04cc457c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9317bae597d74afd800408705c752092":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58fd8ea2630d418485f9caed46445225":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c997357da654e9d9ac1e37906f3cc51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06ba36d6278e4c788190394b97a5789f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fb42a0b1d084da787f2327667a06823","IPY_MODEL_4d962eb8c34e475199c1e61db0bd6b02","IPY_MODEL_b50cc2fb20c94aa39e3df40cad007e48"],"layout":"IPY_MODEL_147e9d340b454263b1bbe74ef660f7ce"}},"5fb42a0b1d084da787f2327667a06823":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfbdb41b57d54f82bb7183049f900b87","placeholder":"​","style":"IPY_MODEL_b00e72fef8d146daba8ecd8602bbac70","value":"target.spm: 100%"}},"4d962eb8c34e475199c1e61db0bd6b02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5848cdde28d44f7ad6c3fe2e7b4a57d","max":813126,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f13a6226b984d008c466dc9c2e8cd1a","value":813126}},"b50cc2fb20c94aa39e3df40cad007e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab3dbfd35f5842bd8d2379f453d11961","placeholder":"​","style":"IPY_MODEL_13f3f93521414ae38d108a2907b363d0","value":" 813k/813k [00:00&lt;00:00, 46.5MB/s]"}},"147e9d340b454263b1bbe74ef660f7ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfbdb41b57d54f82bb7183049f900b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00e72fef8d146daba8ecd8602bbac70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5848cdde28d44f7ad6c3fe2e7b4a57d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f13a6226b984d008c466dc9c2e8cd1a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab3dbfd35f5842bd8d2379f453d11961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13f3f93521414ae38d108a2907b363d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b44576d32f3f48068f5c8286344e5ef8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23a8d0af827c4ccf99bc6a107db1d1c4","IPY_MODEL_e0c30443d3a849a3ab497087319d3979","IPY_MODEL_713dd3e240a9433ebaff5bc664912ba6"],"layout":"IPY_MODEL_94268a1f7a6f40b4b2b26eafb2d13681"}},"23a8d0af827c4ccf99bc6a107db1d1c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2131eeab6ed4aa9b7f888832e464a6a","placeholder":"​","style":"IPY_MODEL_be692f662a1c4bc7b123f74c242c21b1","value":"vocab.json: "}},"e0c30443d3a849a3ab497087319d3979":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb4ee10c8e344568bb94e1117659fa1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c73afaebd57c4c02baa17d212c93cb92","value":1}},"713dd3e240a9433ebaff5bc664912ba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c31d06024704f60bbdcaba807e98640","placeholder":"​","style":"IPY_MODEL_d97acfac0da14966bc7bdd14f2024f87","value":" 1.72M/? [00:00&lt;00:00, 32.6MB/s]"}},"94268a1f7a6f40b4b2b26eafb2d13681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2131eeab6ed4aa9b7f888832e464a6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be692f662a1c4bc7b123f74c242c21b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afb4ee10c8e344568bb94e1117659fa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c73afaebd57c4c02baa17d212c93cb92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c31d06024704f60bbdcaba807e98640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d97acfac0da14966bc7bdd14f2024f87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7636b6d6c3574bebb12ac4987211c942":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92eeb1d6e2454fdbafc2321b46588d59","IPY_MODEL_d608bb6604444a1ba96088e81c99ec38","IPY_MODEL_39c5c2a4ab394c1da9162f96baf15c55"],"layout":"IPY_MODEL_20f502404666441fa4ff57c3934b0007"}},"92eeb1d6e2454fdbafc2321b46588d59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15cd24fe2031421f900b50417c41323e","placeholder":"​","style":"IPY_MODEL_56f97c1ee12a4e0881a83f08500202fa","value":"pytorch_model.bin: 100%"}},"d608bb6604444a1ba96088e81c99ec38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26602be166594e41b7452c540814727e","max":312087009,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe8a4aa828944726a68e7b23457722b9","value":312087009}},"39c5c2a4ab394c1da9162f96baf15c55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d42d45aa2df842008e2015caf79df645","placeholder":"​","style":"IPY_MODEL_6319b2e3da954ed48debf0ab7a13d11d","value":" 312M/312M [00:10&lt;00:00, 27.8MB/s]"}},"20f502404666441fa4ff57c3934b0007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15cd24fe2031421f900b50417c41323e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56f97c1ee12a4e0881a83f08500202fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26602be166594e41b7452c540814727e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe8a4aa828944726a68e7b23457722b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d42d45aa2df842008e2015caf79df645":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6319b2e3da954ed48debf0ab7a13d11d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5056c729d3cc429baacd794277799017":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_456ca95d99224593b198045a1265215e","IPY_MODEL_d113cfcba729475faa06907924f344e3","IPY_MODEL_c412631fd2544afeb7aac88cb0b5f96b"],"layout":"IPY_MODEL_e1e4b170635240cc88ff3ea6bd7ca675"}},"456ca95d99224593b198045a1265215e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65ae5f9c870e4c4ca1b3884461da1438","placeholder":"​","style":"IPY_MODEL_5083e06dc1fb41b48f0f5d7eb5fe5a7b","value":"model.safetensors: 100%"}},"d113cfcba729475faa06907924f344e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7992d3813b02437ebef2a13a8bd276c8","max":312062580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1aa66451fe347e290729839566731c0","value":312062580}},"c412631fd2544afeb7aac88cb0b5f96b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20112b67eef24e698498315cbe8d25d9","placeholder":"​","style":"IPY_MODEL_e28cfcade16f4124bec1666c2effbb73","value":" 312M/312M [00:09&lt;00:00, 31.5MB/s]"}},"e1e4b170635240cc88ff3ea6bd7ca675":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65ae5f9c870e4c4ca1b3884461da1438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5083e06dc1fb41b48f0f5d7eb5fe5a7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7992d3813b02437ebef2a13a8bd276c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1aa66451fe347e290729839566731c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20112b67eef24e698498315cbe8d25d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e28cfcade16f4124bec1666c2effbb73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29d6de9929db4dc4a073b0c1e06ec167":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fda337d1e91a49e1aabfb92dd23c9506","IPY_MODEL_185d01fce8284757a4ff052c2f749c34","IPY_MODEL_e0db1507177947babe99ba95722efe96"],"layout":"IPY_MODEL_1cd2f2433708400c9770b72bc5448bae"}},"fda337d1e91a49e1aabfb92dd23c9506":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_853f270a87394f5d9e92d725fa0ad75f","placeholder":"​","style":"IPY_MODEL_53432ac4ff964f4fb3079b99d8262bb9","value":"generation_config.json: 100%"}},"185d01fce8284757a4ff052c2f749c34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d819de163bc548eb8ccd0b5470b1312d","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17695ec598a14326abf5ebc60c71afdf","value":293}},"e0db1507177947babe99ba95722efe96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bfea2a25da342d18c2d5c569a343ecf","placeholder":"​","style":"IPY_MODEL_74ac86050aa845c7a3772d0a879483d0","value":" 293/293 [00:00&lt;00:00, 23.5kB/s]"}},"1cd2f2433708400c9770b72bc5448bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853f270a87394f5d9e92d725fa0ad75f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53432ac4ff964f4fb3079b99d8262bb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d819de163bc548eb8ccd0b5470b1312d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17695ec598a14326abf5ebc60c71afdf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bfea2a25da342d18c2d5c569a343ecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ac86050aa845c7a3772d0a879483d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5b18844622148e78dd00a8f025b5fc2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af5afd804da74772ba9a8f75cdc879af","IPY_MODEL_3bbe8a27f6d6487887d75b60da3320d7","IPY_MODEL_c004bd67b34a4ca491efe85a9b137689"],"layout":"IPY_MODEL_86f8b88a929045359ad6bf27490f86b0"}},"af5afd804da74772ba9a8f75cdc879af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ead9aa6017d42978409cc1a94a18ecf","placeholder":"​","style":"IPY_MODEL_07e934662e3e47be9005422fd6915c03","value":"tokenizer_config.json: 100%"}},"3bbe8a27f6d6487887d75b60da3320d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e900646ce51404ea880c62bc07fdfa1","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78b1beb8c5324024b83ea63761852900","value":49}},"c004bd67b34a4ca491efe85a9b137689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_271f16a9ca8342359e43882643781d6d","placeholder":"​","style":"IPY_MODEL_eb4bad56e3824c8c9525ff405d2edcfc","value":" 49.0/49.0 [00:00&lt;00:00, 3.12kB/s]"}},"86f8b88a929045359ad6bf27490f86b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ead9aa6017d42978409cc1a94a18ecf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07e934662e3e47be9005422fd6915c03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e900646ce51404ea880c62bc07fdfa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78b1beb8c5324024b83ea63761852900":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"271f16a9ca8342359e43882643781d6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb4bad56e3824c8c9525ff405d2edcfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90dcce39c37c48f8820b3daf443cebd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92693923a4314964b9674a33144e5100","IPY_MODEL_8d61a70fbd2f42f8a9d3d583ed335294","IPY_MODEL_354bd0745b6e475b978a908cfc8a711b"],"layout":"IPY_MODEL_aba4af147ddd4101addb79c9a544f17b"}},"92693923a4314964b9674a33144e5100":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca7aa59eead42349444b428d0802a3b","placeholder":"​","style":"IPY_MODEL_c66b1bb1274c467ca78302cfa728ac0f","value":"config.json: 100%"}},"8d61a70fbd2f42f8a9d3d583ed335294":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1930df2a06c745349ce1db67d9611f41","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eaa5055f154d43c49660f07d4e23bb03","value":570}},"354bd0745b6e475b978a908cfc8a711b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c9732d20d8442c89e7442d13bfab34e","placeholder":"​","style":"IPY_MODEL_4864bb65f76d459ea4e71f4f257e2873","value":" 570/570 [00:00&lt;00:00, 43.5kB/s]"}},"aba4af147ddd4101addb79c9a544f17b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ca7aa59eead42349444b428d0802a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c66b1bb1274c467ca78302cfa728ac0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1930df2a06c745349ce1db67d9611f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaa5055f154d43c49660f07d4e23bb03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c9732d20d8442c89e7442d13bfab34e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4864bb65f76d459ea4e71f4f257e2873":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9adcf46bcd6d43a793f951b746b6e67b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c2e1c66ee9d46d7862c886a7ea24112","IPY_MODEL_6b2902ad815c40ceb8c9021b7a56d126","IPY_MODEL_da752ddd17e348049f46a0daab25b4f3"],"layout":"IPY_MODEL_b36543446d0645eabe2a54d4e443dce4"}},"8c2e1c66ee9d46d7862c886a7ea24112":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecd3e73d52ff4953b324761b41f2b3f9","placeholder":"​","style":"IPY_MODEL_eb7fbab1c7d7489ca2d0143fa88f1e27","value":"vocab.txt: 100%"}},"6b2902ad815c40ceb8c9021b7a56d126":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a5e7a40dafa4c439b6e75f324eb64f1","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7bb5d4c8685b406b8e743b0d65d384a4","value":213450}},"da752ddd17e348049f46a0daab25b4f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac8c929134144a1a84ab171521dbae73","placeholder":"​","style":"IPY_MODEL_9ed2fc6ce1ed4a65bdbf204a34fb7786","value":" 213k/213k [00:00&lt;00:00, 7.49MB/s]"}},"b36543446d0645eabe2a54d4e443dce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecd3e73d52ff4953b324761b41f2b3f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb7fbab1c7d7489ca2d0143fa88f1e27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a5e7a40dafa4c439b6e75f324eb64f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bb5d4c8685b406b8e743b0d65d384a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac8c929134144a1a84ab171521dbae73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ed2fc6ce1ed4a65bdbf204a34fb7786":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e62997bb51284053ad55b500b459cb42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b92c9d93f85846cfa29b48b64daea024","IPY_MODEL_cfc8a409a18a47d58a8cd10a8fb08a1d","IPY_MODEL_8602986aba3546a6b03cbb824ea4c6be"],"layout":"IPY_MODEL_4a1046d44069471d8e4c78db67675aa8"}},"b92c9d93f85846cfa29b48b64daea024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b635521d70da48069bfa02f7a20ca3cf","placeholder":"​","style":"IPY_MODEL_b0b6004dd3a545e2aab402c3a5cb4428","value":"tokenizer.json: 100%"}},"cfc8a409a18a47d58a8cd10a8fb08a1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_467a0cdd781744fa9e23c6d8035d9eb2","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d40fffcf48ed4897a08036bda071b918","value":435797}},"8602986aba3546a6b03cbb824ea4c6be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926c8c10a76b48bdb7071b871b05ba20","placeholder":"​","style":"IPY_MODEL_4a572c1e4eea41fe85cfaefa0e2f6a78","value":" 436k/436k [00:00&lt;00:00, 1.94MB/s]"}},"4a1046d44069471d8e4c78db67675aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b635521d70da48069bfa02f7a20ca3cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0b6004dd3a545e2aab402c3a5cb4428":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"467a0cdd781744fa9e23c6d8035d9eb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d40fffcf48ed4897a08036bda071b918":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"926c8c10a76b48bdb7071b871b05ba20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a572c1e4eea41fe85cfaefa0e2f6a78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80058dcffad0434f9b1c3962d7a2d4ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4211ccfa627c4e29a2a25a59d49651d6","IPY_MODEL_4d9e0b6a34bd4d18b6733412e042b01e","IPY_MODEL_d89cbddf1a91457b952f8ab214a42c65"],"layout":"IPY_MODEL_ad6ad18082fe485da2cd222b906abba1"}},"4211ccfa627c4e29a2a25a59d49651d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_270e5717225e42529c1a0b6de47b3ee1","placeholder":"​","style":"IPY_MODEL_49cba2bfee7c4facb8cda8212bc49e60","value":"model.safetensors: 100%"}},"4d9e0b6a34bd4d18b6733412e042b01e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_596483064cab42c898db1df8b89e30fc","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b7994c13d99481ea85d209872392814","value":435755784}},"d89cbddf1a91457b952f8ab214a42c65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_207794a399754fcb939f19ca890dad79","placeholder":"​","style":"IPY_MODEL_07b561b4e63c49598ac254d1ca8457af","value":" 436M/436M [00:23&lt;00:00, 21.2MB/s]"}},"ad6ad18082fe485da2cd222b906abba1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"270e5717225e42529c1a0b6de47b3ee1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49cba2bfee7c4facb8cda8212bc49e60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"596483064cab42c898db1df8b89e30fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b7994c13d99481ea85d209872392814":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"207794a399754fcb939f19ca890dad79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07b561b4e63c49598ac254d1ca8457af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eea22bac8df240419a2d343dec66c698":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a1fbc66b5fc4354a4e27b66d506534d","IPY_MODEL_ae1685ef0a2d40c3943a1e05aaba89c4","IPY_MODEL_24b21d2837b647d1b00689a5c89f5fb3"],"layout":"IPY_MODEL_b32d25fa0b68473b89d661dea1a04a09"}},"2a1fbc66b5fc4354a4e27b66d506534d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48be4d0f40bc4aa3a6f169bf7a59e0fd","placeholder":"​","style":"IPY_MODEL_320ca1a2e9144d59b82c06789596e5e9","value":"tokenizer_config.json: 100%"}},"ae1685ef0a2d40c3943a1e05aaba89c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38568370b1064e29bf8fa2765fb168df","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27ca0db1fd0140228cf86653396e3ebe","value":26}},"24b21d2837b647d1b00689a5c89f5fb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8191645497d542d8b56830ba8e50956c","placeholder":"​","style":"IPY_MODEL_462a28c7fd4e48128476f1dcd17f5e9d","value":" 26.0/26.0 [00:00&lt;00:00, 1.81kB/s]"}},"b32d25fa0b68473b89d661dea1a04a09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48be4d0f40bc4aa3a6f169bf7a59e0fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"320ca1a2e9144d59b82c06789596e5e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38568370b1064e29bf8fa2765fb168df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27ca0db1fd0140228cf86653396e3ebe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8191645497d542d8b56830ba8e50956c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462a28c7fd4e48128476f1dcd17f5e9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c7513d9fd8b47b19da2b093c76f26d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_053b2b57351d4550b080a8fcfb170daf","IPY_MODEL_3ff283715eb64228bf0809f7a8d15034","IPY_MODEL_2214c58d4bfe42e4851f52f6354998c5"],"layout":"IPY_MODEL_209ce18b4a3342b18fb2a900c2ef325e"}},"053b2b57351d4550b080a8fcfb170daf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e80034f7b26b423697b78e509bc7bdad","placeholder":"​","style":"IPY_MODEL_e382eece93824f91b040d2f6fa0cc798","value":"config.json: 100%"}},"3ff283715eb64228bf0809f7a8d15034":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16426d21932a46d5a4ea65dc29b4a128","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4a904a8e7524c029437437bde717dcf","value":665}},"2214c58d4bfe42e4851f52f6354998c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ded2a71fb5c4dbd8cab3900219a7754","placeholder":"​","style":"IPY_MODEL_bcea15ab6aca4a8bb4131b677347d871","value":" 665/665 [00:00&lt;00:00, 40.3kB/s]"}},"209ce18b4a3342b18fb2a900c2ef325e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e80034f7b26b423697b78e509bc7bdad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e382eece93824f91b040d2f6fa0cc798":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16426d21932a46d5a4ea65dc29b4a128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4a904a8e7524c029437437bde717dcf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ded2a71fb5c4dbd8cab3900219a7754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcea15ab6aca4a8bb4131b677347d871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31ba0041ecb3440a86b350a2a17bfcf7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc6bf231c9564e7abd001ae761fd644d","IPY_MODEL_181371787f4a4551b28bdb0f693d06eb","IPY_MODEL_c2e645f7547d4247be59d8f83de68c5e"],"layout":"IPY_MODEL_70d75baec5924ee3bb43739e4f053c2a"}},"fc6bf231c9564e7abd001ae761fd644d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c40d10d01ff44f91bf206da1670b3033","placeholder":"​","style":"IPY_MODEL_df32c53288064f4eba6e3294db7ee4bd","value":"vocab.json: 100%"}},"181371787f4a4551b28bdb0f693d06eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02cc9f1501f5400599f112b7cc5abf08","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e93e2da77ea453bb41e39e5c1ff7f07","value":1042301}},"c2e645f7547d4247be59d8f83de68c5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75898b193658439cae4cea0701876655","placeholder":"​","style":"IPY_MODEL_3ecee9fadd304a5898d4a6c4f6da1e51","value":" 1.04M/1.04M [00:00&lt;00:00, 13.3MB/s]"}},"70d75baec5924ee3bb43739e4f053c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c40d10d01ff44f91bf206da1670b3033":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df32c53288064f4eba6e3294db7ee4bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02cc9f1501f5400599f112b7cc5abf08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e93e2da77ea453bb41e39e5c1ff7f07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75898b193658439cae4cea0701876655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ecee9fadd304a5898d4a6c4f6da1e51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"851a4f3a7f8f4176aec6ce47f4d931e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e0551f38b12450ebc89bf488273ca6f","IPY_MODEL_cb6f9c8cfc314c3180a5484f7dc202ed","IPY_MODEL_c722aaa8a3ef4625a7b45b37b79dfa44"],"layout":"IPY_MODEL_32d52583bb444e09bc61692099f319fd"}},"7e0551f38b12450ebc89bf488273ca6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4c7f9f8da204f4ba0ef795087ae164a","placeholder":"​","style":"IPY_MODEL_e745df1299f14078b5b2d74f7368da11","value":"merges.txt: 100%"}},"cb6f9c8cfc314c3180a5484f7dc202ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_594c044102fa4e78a51a48aa094c4e84","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79f9c8f5c016442eb5e4ee4537ef0a18","value":456318}},"c722aaa8a3ef4625a7b45b37b79dfa44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85271956be5440a882a8d5fb9da9950a","placeholder":"​","style":"IPY_MODEL_b99ec3d3884446b281c7875f0f322e69","value":" 456k/456k [00:00&lt;00:00, 13.8MB/s]"}},"32d52583bb444e09bc61692099f319fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4c7f9f8da204f4ba0ef795087ae164a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e745df1299f14078b5b2d74f7368da11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"594c044102fa4e78a51a48aa094c4e84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79f9c8f5c016442eb5e4ee4537ef0a18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85271956be5440a882a8d5fb9da9950a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99ec3d3884446b281c7875f0f322e69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a5010141475458788e9c3acd5e1de45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26dfd79155d74b4daa217f7e65d99687","IPY_MODEL_de0f25142e5e499487f5cbdc89133700","IPY_MODEL_93132b07417b46e7b60179096668c586"],"layout":"IPY_MODEL_408f230d459740c68027c0798f2de4b3"}},"26dfd79155d74b4daa217f7e65d99687":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_448ba17a6df24985ab5ecf77d73f37e2","placeholder":"​","style":"IPY_MODEL_ca3c333433ef47d3abb71cddfef6bd2b","value":"tokenizer.json: 100%"}},"de0f25142e5e499487f5cbdc89133700":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e97f07b065ca4b498023f2a108e62517","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ceef4c746ef4edd98be2921878c7c00","value":1355256}},"93132b07417b46e7b60179096668c586":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a8bb93c597c41288956ebfef0458640","placeholder":"​","style":"IPY_MODEL_508a4aaf6299410a834235ba554d62bb","value":" 1.36M/1.36M [00:00&lt;00:00, 21.3MB/s]"}},"408f230d459740c68027c0798f2de4b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"448ba17a6df24985ab5ecf77d73f37e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca3c333433ef47d3abb71cddfef6bd2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e97f07b065ca4b498023f2a108e62517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ceef4c746ef4edd98be2921878c7c00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a8bb93c597c41288956ebfef0458640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"508a4aaf6299410a834235ba554d62bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8767bb1c63fd401dbdc0ac4ce112b54e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93b0bf23dac24ebfa39001d234aed7cb","IPY_MODEL_58b53c4aad4a45eca0b48358e6633d9b","IPY_MODEL_0951d1fa182f459b8c615184917ac94c"],"layout":"IPY_MODEL_1384d5791abf4b7b93d0cefe941c3567"}},"93b0bf23dac24ebfa39001d234aed7cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa4b3ad5b8d2436ca882b50aaaa07ba2","placeholder":"​","style":"IPY_MODEL_f7fb1de7dc1c464cb06cb703ddc3b52f","value":"model.safetensors: 100%"}},"58b53c4aad4a45eca0b48358e6633d9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_278b782f643a406db19f99a5e00ac07f","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7397e95a8e1344fbb771622e01c9ddee","value":548105171}},"0951d1fa182f459b8c615184917ac94c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fc0809b76c54426b89ee43a6f3c883e","placeholder":"​","style":"IPY_MODEL_c328ccfa2e9c4d9dbe76c241cb172537","value":" 548M/548M [00:19&lt;00:00, 36.5MB/s]"}},"1384d5791abf4b7b93d0cefe941c3567":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa4b3ad5b8d2436ca882b50aaaa07ba2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7fb1de7dc1c464cb06cb703ddc3b52f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"278b782f643a406db19f99a5e00ac07f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7397e95a8e1344fbb771622e01c9ddee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fc0809b76c54426b89ee43a6f3c883e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c328ccfa2e9c4d9dbe76c241cb172537":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f03984f1ec34136be2b82d76d7fca28":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b58e47f770124a9ca011aefd0b0ffd86","IPY_MODEL_0ba82b3cad15447c9603d017fcfc5d50","IPY_MODEL_8fddb1e3ac4c4c0e9a29e339be83c88a"],"layout":"IPY_MODEL_d39db9d13c384a199ba603f1f86f3813"}},"b58e47f770124a9ca011aefd0b0ffd86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed6f89872e0445748dcb1f4260541799","placeholder":"​","style":"IPY_MODEL_35b7ea688ac749249ed70407ca9ed96a","value":"generation_config.json: 100%"}},"0ba82b3cad15447c9603d017fcfc5d50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_016565a21d8e48fd8062f05fdc0bf123","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da4355358a2a400eba6b3cf4741f69a1","value":124}},"8fddb1e3ac4c4c0e9a29e339be83c88a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63e0dbd2462b439b9901a95bdce3f76a","placeholder":"​","style":"IPY_MODEL_a1b1709b5b94423d8b77d5bc46785941","value":" 124/124 [00:00&lt;00:00, 8.78kB/s]"}},"d39db9d13c384a199ba603f1f86f3813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed6f89872e0445748dcb1f4260541799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35b7ea688ac749249ed70407ca9ed96a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"016565a21d8e48fd8062f05fdc0bf123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da4355358a2a400eba6b3cf4741f69a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63e0dbd2462b439b9901a95bdce3f76a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1b1709b5b94423d8b77d5bc46785941":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}