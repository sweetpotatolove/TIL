# 머신러닝 개요 및 평가지표
## 인공지능의 기본 개념
### AI (Artificial Intelligence)
인간의 지능을 인공적으로 만든 것

- 지능이란 -> 지적 능력 -> 인간은 어떻게 알까?

- 인공지능 vs 머신러닝 vs 딥러닝

  ![alt text](image.png)
  - 인공지능 AI (Artificial Intelligence)
    - 규칙 기반의 알고리즘
  - 머신러닝 ML (Machine Learning)
    - 데이터 기반의 학습
    - 결정 트리, 선형회귀, 퍼셉트론, SVM, ...
  - 딥러닝 DL (Deep Learning)
    - CNN, RNN, GAN, 트랜스포머 ...

- 머신러닝과 딥러닝
  - Perceoptron과 Deep Neural Network

    ![alt text](image-1.png)
    - Perceoptron: 사람의 뉴런..본뜬 상태?
    - 입력값에 가중치를 곱해 합쳐서 일정 임계값(활성화 함수)을 넣으면 어떤 ouput을 내보낼지
    - 근데 많은 한계가 있음
    - 복잡한 패턴을 인식하기엔 활성화 함수 한개로는 한계가 있음
    - 그래서 굉장히 많은 퍼셉트론을 합쳐서? 사용하는게 MLP (Multi Layer Perceoptron)
    - 입력층, 여러 은닉층, 출력층?으로 구성되어 있고 은닉층이 많을수록 딥하다 


## 머신러닝과 딥러닝 소개
### 머신러닝
- Arthur Samuel(1959)
  - "기계 학습은 컴퓨터가 **명시적으로 프로그래밍되지 않아도 스스로 학습할 수 있**는 능력을 부여하는 학문 분야이다.""

- Tom Mitchell(1998)
  - "컴퓨터 프로그램이 어떤 작업 집합 T와 성능 척도 P에 대해 경험 E로부터 학습한다고 할 때, 경험 E를 통해 T 작업에 대한 성능이 P로 측정한 결과 향상되는 경우를 말한다."
    - 경험 (E): 데이터, 과거의 사례
    - 작업 (T): 해결하려는 문제, 과제
    - 성능 척도 (P): 얼마나 잘했는지 평가 기준
  - 머신러닝은 데이터(E)를 통해 과제(T)를 더 잘 수행하도록, 성능(P)이 향상되는 과정

### Feature Engineering
모델이 더 좋은 예측을 할 수 있도록 데이터를 가공하는 과정
    
-> 데이터를 단순히 수집하는 것보다 적절한 피처(Feature, 변수)를 만드는 것이 성능 향상에 중요

- 피처 엔지니어링 필요성
  - 원본 데이터는 모델이 바로 이해하기 어려운 형태일 수 있음
  - 좋은 피처를 만들면 복잡한 모델 없이도 높은 성능을 낼 수 있음
  - 불필요한 변수를 제거하면 연산 속도가 빨라지고 해석력이 향상됨

- 피처 엔지니어링 주요 기법
  - 피처 선택 (Feature Selection)
    - 모델 성능에 중요한 변수만 선택하고 불필요한 변수 제거
    - 방법:
      - 상관계수 분석 -> 상관관계가 높은 변수 제거
      - 분산 기반 선택 -> 변화가 거의 없는 변수 제거
      - Recursive Feature Elimination(RFE) -> 모델 성능에 가장 중요한 변수 선택

  - 피처 생성 (Feature Creation)
    - 기존 데이터를 활용하여 새로운 변수를 만드는 과정
    - 예시:
      - 날짜 데이터 -> "요일", "주말 여부", "계절" 변수 추가
      - 판매 데이터 -> "가격 * 판매량" 으로 매출 변수 생성

  - 피처 변환 (Feature Transformation)
    - 모델이 데이터를 더 잘 학습할 수 있도록 변형
    - 방법:
      - 정규화 (Normalization): 값의 범위를 [0,1]로 조정
      - 표준화 (Standardization): 평균 0, 표준편차 1로 조정
      - 로그 변환 (Log Transformation): 데이터 분포를 정규분포에 가깝게 변형

  - 범주형 데이터 인코딩 (Categorical Encoding)
    - 문자 데이터를 숫자로 변환하여 모델이 이해할 수 있도록 함
    - 방법:
      - 원-핫 인코딩(One-Hot Encoding): 카테고리를 0과 1로 변환
      - 라벨 인코딩(Label Encoding): 카테고리를 숫자로 변환 (예:"Red"->1, "Blue"->2)

  - 결측값 처리 (Handling Missing Values)
    - 데이터에서 비어있는 값(결측치)을 처리하는 과정
    - 방법:
      - 삭제: 결측치가 적으면 해당 행 제거
      - 대체: 평균, 중앙값, 최빈값으로 채우기
      - 예측 모델 사용: 머신러닝을 활용하여 결측값 예측

  - 이상치 처리 (Outlier Handling)
    - 극단적인 값을 감지하고 처리하는 과정
    - 방법:
      - Z-score, IQR(사분위 범위) 기반 이상치 제거
      - 로그 변환으로 이상치 영향을 줄이기

### 머신러닝의 분류
1. Supervised Learning (지도학습)
2. Unsupervised Learning (비지도학습)
3. Reinforcement Learning (강화학습)

### Supervised Learning
정답(label)을 기반으로 학습을 하는 과정

- 집 가격 예측
  - n개의 샘플을 포함한 데이터셋이 주어졌을 때,

    ![alt text](image-3.png)
  - Task: 주거지가 x 평방피트일 때, 그 가격을 예측하라

    ![alt text](image-2.png)
  - 추가 정보: 대지 크기를 알고 있다고 가정
  - Task: (면적, 대지 크기) -> 가격으로 매핑하는 함수를

    ![alt text](image-4.png)
  - 만약 우리가 많은 데이터를 가지고 있다면?

    ![alt text](image-5.png)

- 컴퓨터 비전에서의 Supervised Learning
  - 이미지 분류
    - `x = raw pixels of the image`
    - `y = the main object`
    - https://arxiv.org/abs/1409.0575

      ![alt text](image-6.png)

  - 객체 위치 지정 및 탐지
    - `x = raw pixels of the image`
    - `y = the bounding boxes`

      ![alt text](image-7.png)

- 자연어 처리에서의 Supervised Learning
  - 기계 번역

    ![alt text](image-8.png)

### Unsupervised Learning
정답(label)이 데이터 셋에 없음

-> 데이터 구조, 패턴을 스스로 찾아가는 것

![alt text](image-9.png)

- 목표
  - 모호하게 제시됨
  - 데이터에서 흥미로운 구조를 발견하는 것

- 유전자 클러스터링

  ![alt text](image-10.png)

### Self-Supervised Learning
자기지도학습

-> 자기가 스스로 ..

- Large Language Model (LLM)
  - 대규모 언어 데이터셋을 통해 학습된 기계 학습 모델
  - 다양한 목적으로 활용 가능
  - https://arxiv.org/pdf/2005.14165

    ![alt text](image-11.png)
    ![alt text](image-12.png)

  - 자기 지도 학습
    - 지도 학습의 단점인 정답 데이터에 대한 한계를 극복 - 정답이 없는 데이터도 자체 데이터로 학습
    - 사전 학습 (Pre-training)과 미세 조정(Fine-tuning) 단계로 진행

      ![alt text](image-13.png)

### Reinforcement Learning
순차적인 결정을 내리는 학습 (강화학습)

![alt text](image-15.png)

-> 알고리즘은 데이터를 상호작용적으로 수집할 수 있음

![alt text](image-14.png)

### 모델 성능 평가
- `Overfitting` vs `Underfitting`
  - Overfitting (과적합)
    - 모델이 학습 데이터에 지나치게 적합하여, 복잡한 패턴까지 모두 학습
    - 학습 데이터에서는 높은 성능, 하지만 새로운 데이터에서는 성능이 저하
  - Underfitting (과소적합)
    - 모델이 충분히 학습되지 않아 중요한 패턴조차 학습하지 못함
    - 학습 데이터와 테스트 데이터 모두에서 성능 저조
    
    ![alt text](image-16.png)

- 평가(Evaluation)
  - 실제값과 모델에 의해 예측된 값을 비교하여 두 값의 차리(오차)를 구하는것
  - `(실제값 - 예측값) = 0` 이면, 오차가 없는 것으로 모델이 100% 성능을 보임
  - But, 성능이 100%인 모델은 현실적으로 힘들기 때문에 오차를 구하여 어느 정도까지 오차를 허용할지 결정
    - 과적합(Overfitting)을 방지하고 최적의 모델을 찾기 위해 실시
  - 모델링의 목적 또는 목표 변수의 유형에 따라 다른 평가지표 사용

    ![alt text](image-17.png)

### 회귀 모델 평가 방법
- 하나의 목표를 가지고 다양한 회귀 모델을 만들어 테스트
- 그 중 어떤 모델이 가장 나은 모델인지 판단할 때 모델 평가지표 사용
- 실제 데이터와 예측 결과 데이터가 얼마나 비슷한 지에 기반하지만, 단순하게 이것만 가지고 판단하기에는 무리가 있음
- 주요 지표
  1. 평균 절대 오차 (MAE, Mean Absolute Error)
  2. 평균 절대 백분율 오차 (MAPE, Mean Absolute Percentage Error)
  3. 평균 제곱 오차 (MSE, Mean Squared Error)
  4. 평균 제곱근 오차(RMSE, Root Mean Squared Error)
  5. 결정 계수 (R² Score)

- MAE(Mean Absolute Error)
  - 실제 정답 값과 예측 값의 차이를 절댓값으로 변환한 뒤 합산하여 평균을 구함
  - 이상치를 고려하지 않는 경우에 주로 사용
  - 값이 낮을수록 좋은 모델

    ![alt text](image-18.png)
  - 실제 정답보다 낮게 예측했는지, 높게 했는지를 파악이 어려움
  - 스케일에 의존적이기 때문에 모델마다 에러 크기가 동일해도 에러율은 동일하지 않음

- MAPE(Mean Absolute Percentage Error)
  - MAE를 상대적 오차로 변환하여 데이터의 스케일에 영향을 덜 받도록 함
  - 이상치를 고려하지 않는 경우에 주로 사용
  - 값이 낮을수록 좋은 모델

    ![alt text](image-19.png)
  - 실제 정답보다 낮게 예측했는지, 높게 했는지를 파악하기 어려움
  - 실제 정답이 0에 가까운 경우 값이 발산할 수 있으므로 주의

- MSE(Mean Squared Error)
  - 실제 정답 값과 예측 값의 차이를 제곱한 뒤 평균을 구함
  - 시계열 데이터에서, 미분이 연속적이어야 할 때 주로 사용
  - 값이 낮을수록 좋은 모델

    ![alt text](image-20.png)
  - 이상치(outlier)에 매우 민감 (큰 오차에 큰 패널티)
  - 데이터에 이상치가 많다면 MSE 대신 MAE를 고려
  - 스케일 의존적이므로 모델 비교 시 주의 필요

- RMSE(Root Mean Squared Error)
  - MSE에 루트를 씌워서 에러를 제공해 값의 왜곡을 줄임
  - 시계열 데이터에서, 미분이 연속적인 순간이 필요할 때 주로 사용
  - 값이 낮을수록 좋은 모델

    ![alt text](image-21.png)
  - 이상치에 대한 패널티가 여전히 존재 (MSE보다는 덜 민감)
  - 데이터의 크기가 다르면 RMSE 값도 다르게 나와 서로 다른 스케일의 모델 비교 어려움
  - 데이터에 이상치가 많다면 MSE 대신 MAE 계열 사용

- R2 score (R squared)
  - 모델이 실제 데이터의 변동성을 얼마나 잘 설명하는지를 나타내는 지표
  - 실제 값의 전체 변동성(SST) 중에서 모델이 설명할 수 있는 비율
  - 1에 가까울수록 좋은 모델

    ![alt text](image-22.png)

### 분류 모델 평가 방법
- 하나의 목표를 가지고 다양한 분류 모델을 만들어 테스트
- 그 중 어떤 모델이 가장 나은 모델인지 판단할 때 모델 평가 지표 사용
- 회귀모형과 비슷하게 실제 데이터와 예측 결과 데이터가 얼마나 비슷한지에 기반하지만, 단순히 이것만 가지고 판단하기에는 무리가 있음
- 주요 지표
  1. 정확도(Accuracy)
  2. 오차행렬(Confusion Matrix)
  3. 정밀도(Precision)
  4. 재현율(Recall)
  5. F1-스코어
  6. ROC AUC

- 오차행렬(Confusion Matrix)
  - 분류 모델이 예측한 결과와 실제 정답을 비교하여 성능을 평가하는 방법
  - 특히 **이진 분류(binary classification)** 문제에서 모델이 얼마나 정확하게 예측했는지를 분석하는 데 유용
  - 구성 요소

    ![alt text](image-23.png)
    - TP (True Positive): 실제로 참인 데이터를 모델이 참으로 예측한 경우
    - TN (True Negative): 실제로 거짓인 데이터를 모델이 거짓으로 예측한 경우
    - FP (False Positive): 실제로 거짓인데 모델이 참으로 예측한 경우
    - FN (False Negative): 실제로 참인데 모델이 거짓으로 예측한 경우

- 정확도(Accuracy)
  - 전체 샘플 중에서 모델이 맞춘 비율
  - 하지만 데이터가 불균형한 경우에는 부적절할 수 있음 (예: 99% 건강한 데이터, 1% 암 환자)

    ![alt text](image-24.png)

- 정밀도(Precision)
  - 모델이 "참(Positive)"이라고 예측한 것 중 실제로 참인 비율
  - FP(거짓을 참으로 예측하는 경우)를 줄이는 데 초점
  - ex. 스팸 필터에서 중요 (스팸 아닌 메일을 스팸으로 분류하면 안 됨)

    ![alt text](image-25.png)

- 재현율(Recall)
  - 실제 참(Positive) 중에서 모델이 맞춘 비율
  - FN(참을 거짓으로 예측하는 경우)을 줄이는 데 초점
  - ex. 암 진단 모델에서 중요 (암 환자를 놓치면 안 됨)

    ![alt text](image-26.png)

- Precision과 Recall의 Trade off
  - 재현율(Recall)이 중요한 경우 -> 실제 Positive(양성)을 놓치면 안 되는 상황
    - ex. 암 진단: 암 환자를 놓치면 치명적
    - ex. 금융 사기 탐지: 사기 거래를 놓치면 피해 발생

  - 정밀도(Precision)이 중요한 경우 -> 실제 Negative(음성)을 잘못 Positive(양성)으로 예측하면 문제가 되는 상황
    - ex. 스팸 필터: 중요한 이메일을 스팸으로 분류하면 안 됨
    - ex. 의료 검사: 불필요한 추가 검사(비용 증가)
  
  - 정밀도와 재현율은 반비례 관계
  - 임계값(Threshold)을 조정하면 정밀도(Precision) 또는 재현율(Recall)을 조절할 수 있음
    - 하지만 정밀도를 높이면 재현율이 낮아지고, 재현율을 높이면 정밀도가 낮아지는 관계

    ![alt text](image-27.png)
    - 재현율을 높이면 (모든 Positive를 잡으려 함) -> 정밀도가 낮아짐 (False Positive 증가)
    - 정밀도를 높이면 (정확한 Positive만 잡으려 함) -> 재현율이 낮아짐 (False Negative 증가)

- 정밀도를 100%로 만드는 방법
  - 확실한 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측
  - ex. 1000명 중 단 1명만 확실한 양성이라 판단하고 나머지는 모두 음성으로 처리
  - 결과
    - FP(거짓 양성) = 0 -> 정밀도 100%
  - 문제
    - 대부분의 양성을 놓칠 위험 (재현율이 극도로 낮아짐)

- 재현율을 100%로 만드는 방법
  - 모든 데이터를 Positive(양성)으로 예측
  - ex. 1000명 모두 양성이라 가정하면 실제 양성 30명은 모두 검출됨
  - 결과
    - FN(거짓 음성) = 0 -> 재현율 100%
  - 문제
    - 너무 많은 FP(거짓 양성) 발생 -> 정밀도 급락

※ 정밀도와 재현율을 극단적으로 높이면 성능이 왜곡됨

※ 업무에 따라 적절한 균형이 필요 (F1-score 활용)

- F1-score
  - 정밀도와 재현율의 조화 평균

    ![alt text](image-28.png)
  - 데이터가 불균형할 때 유용
  - 정밀도와 재현율 사이에서 균형을 맞춘 지표
  - 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 높은 값을 가짐

- ROC 곡선(Receiver Operating Characteristic Curve)
  - False Positive Rate(FPR) 변화에 따른 True Positive Rate(TPR) 변화를 나타내는 그래프
  - X축: False Positive Rate (FPR, 잘못 양성으로 예측한 비율)
  - Y축: True Positive Rate (TPR, 실제 양성을 맞춘 비율)
  - 곡선이 왼쪽 위로 올라갈수록 좋은 모델

- AUC (Area Under Curve)
  - ROC 곡선 아래 면적을 의미하며 1에 가까울수록 좋은 성능
  - 일반적으로 의학 및 머신러닝의 이진 분류 평가 지표로 활용됨

    ![alt text](image-29.png)

- ROC 곡선과 AUC

  ![alt text](image-30.png)
  - TPR (True Positive Rate, 재현율)
    - 실제 양성(Positive) 중에서 모델이 맞게 예측한 비율
    - 값이 클수록 좋은 모델 (양성을 잘 찾아냄)
  - FPR (False Positive Rate)
    - 실제 음성(Negative) 중에서 모델이 잘못 예측한 비율
    - 값이 작을수록 좋은 모델 (불필요한 오답을 줄임)
  - ROC 곡선의 의미
    - X축: `FPR` (False Positive Rate)
    - Y축: `TPR` (True Positive Rate)
    - 곡선이 왼쪽 위로 갈수록 좋은 모델
    - 임계값(Threshold)에 따라 FPR과 TPR이 변화
  - 결론
    - 좋은 모델일수록 ROC 곡선이 좌상단에 위치
    - **AUC (ROC 아래 면적)가 1에 가까울수록 성능이 우수함**



## 벡터의 정의와 개념
### 벡터
벡터는 선형대수학의 기본 요소로, 크기와 방향을 가짐

![alt text](image-31.png)

-> 좌표 평면에서 점을 나타낼 때 (x, y)와 같은 형태로 표현

-> 벡터는 머신러닝과 데이터 분석 등에서 데이터를 표현하는 기본 단위로 사용

-> 파이썬에서는 숫자로 이루어진 배열(리스트) 형태로 표현

- 벡터의 좌표
  - 벡터는 좌표로 표현되며, 두 숫자가 원점에서의 이동을 나타냄
  - 첫 번째 숫자는 x축 방향 이동, 두 번째 숫자는 y축 방향 이동
  - 3차원에서는 z축이 추가됨

    ![alt text](image-32.png)

- 데이터를 표현하는 방법
  - 스칼라: 하나의 숫자 (0차원)
  - 벡터: 여러 개의 숫자가 나열된 1차원 배열
  - 행렬: 숫자의 행과 열로 구성된 2차원 배열
  - 텐서: 3차원 이상을 포함하는 행렬보다 높은 다차원 배열

    ![alt text](image-33.png)

- 텐서의 활용
  - 텐서는 공간을 수치적으로 표현하는 도구
  - 데이터 분석에서는 벡터를 사용하여 여러 특성을 표현함
  - 벡터를 이용해 공간 내 객체를 표현하고 조작하는데 활용
  - 텐서를 활용하여 딥러닝, 머신러닝에 적용하여 데이터를 표현함
  - 이를 활용해 복잡한 데이터와 패턴을 학습하고 분석하는 데 사용

    ![alt text](image-34.png)

