{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee000af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c56af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 교통량 데이터 로드\n",
    "# 예시 파일 경로를 사용하여 엑셀 데이터를 불러옵니다.\n",
    "weekdays_data = pd.read_excel('../data/weekday_traffic.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d22a3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 독립 변수: 각 날의 8시, 9시, 10시 교통량 데이터를 사용\n",
    "# '8시', '9시', '10시' 열을 독립 변수로 선택하여 교통량 변수를 구성합니다.\n",
    "X = weekdays_data[['8시', '9시', '10시']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09edaf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 종속 변수: 혼잡 여부 (True/False -> 1/0 변환)\n",
    "# '혼잡' 열을 종속 변수로 사용하며, 이 값이 True이면 1, False이면 0으로 변환합니다.\n",
    "y = weekdays_data['혼잡'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a22fb004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 데이터 분리 (훈련 데이터 80%, 테스트 데이터 20%)\n",
    "# 데이터를 학습용과 테스트용으로 나눕니다.\n",
    "# 참고: Scikit-learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "908c8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 데이터 스케일링 (로지스틱 회귀에 반드시 필요)\n",
    "# 데이터의 스케일에 민감한 로지스틱 회귀 모델에 적용하기 때문에 표준화를 진행합니다. (상대적으로 트리 기반 모델에서는 덜 민감하다는거지 하면 안되는 것은 아닙니다.)\n",
    "# 앙상블 모델은 스케일링 없이 원본 데이터를 사용합니다.\n",
    "# 참고: Scikit-learn - StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decec99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 랜덤 포레스트 - 배깅 방식\n",
    "# 배깅(bagging) 방식의 랜덤 포레스트 모델을 생성합니다. \n",
    "# - n_estimators=10: 트리의 개수를 10개로 설정\n",
    "# - random_state=42: 결과 재현을 위해 고정된 난수 시드를 설정\n",
    "# 참고: Scikit-learn - RandomForestClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b4d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Gradient Boosting - 부스팅 방식\n",
    "# 부스팅 방식의 Gradient Boosting 모델을 생성합니다.\n",
    "# - n_estimators=10: 트리 개수를 10개로 설정\n",
    "# - learning_rate=0.1: 학습률을 0.1로 설정하여 학습 속도 조절\n",
    "# - max_depth=3: 각 트리의 최대 깊이를 3으로 설정하여 과적합 방지\n",
    "# 참고: Scikit-learn - GradientBoostingClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "gb_model = GradientBoostingClassifier(n_estimators=10, learning_rate=0.1, max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ef4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Logistic Regression - 로지스틱 회귀 모델\n",
    "# Logistic Regression 모델을 생성하며 L2 정규화를 사용합니다.\n",
    "# - penalty='l2': L2 정규화(릿지 회귀)를 사용\n",
    "# - C=1.0: 정규화 강도 조절, C 값이 클수록 약한 정규화, 작을수록 강한 정규화\n",
    "# 참고: Scikit-learn - LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "lr_model = LogisticRegression(C=1.0, penalty='l2', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16200068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 모델 학습 및 성능 평가\n",
    "# 설정한 세 가지 모델에 대해 학습을 수행하고, 테스트 데이터에 대한 성능을 평가합니다.\n",
    "models = {\n",
    "    'Random Forest': rf_model,\n",
    "    'Gradient Boosting': gb_model,\n",
    "    'Logistic Regression': lr_model\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4b1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Random Forest ====\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92         6\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.93      0.83      0.86         9\n",
      "weighted avg       0.90      0.89      0.88         9\n",
      "\n",
      "\n",
      "==== Gradient Boosting ====\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.75      0.75      0.75         9\n",
      "weighted avg       0.78      0.78      0.78         9\n",
      "\n",
      "\n",
      "==== Logistic Regression ====\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.75      0.75      0.75         9\n",
      "weighted avg       0.78      0.78      0.78         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Logistic Regression':\n",
    "        # Logistic Regression은 스케일링된 데이터를 사용합니다.\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        # 앙상블 모델들은 원본 데이터를 사용해 학습합니다.\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 모델의 정확도와 분류 리포트를 출력합니다.\n",
    "    # 참고: Scikit-learn - classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n==== {model_name} ====\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report:\\n{report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
